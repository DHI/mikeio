{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset\n",
        "\n",
        "``` python\n",
        "Dataset(\n",
        "    self\n",
        "    data\n",
        "    time=None\n",
        "    items=None\n",
        "    geometry=None\n",
        "    zn=None\n",
        "    dims=None\n",
        "    validate=True\n",
        "    dt=1.0\n",
        ")\n",
        "```\n",
        "\n",
        "Dataset containing one or more DataArrays with common geometry and time.\n",
        "\n",
        "Most often obtained by reading a dfs file. But can also be created a\n",
        "sequence or dictonary of DataArrays. The mikeio.Dataset is inspired by\n",
        "and similar to the xarray.Dataset.\n",
        "\n",
        "The Dataset is primarily a container for one or more DataArrays all\n",
        "having the same time and geometry (and shape, dims, etc). For\n",
        "convenience, the Dataset provides access to these common properties:\n",
        "\n",
        "-   time - a pandas.DatetimeIndex with the time instances of the data\n",
        "-   geometry - a geometry object e.g. Grid2D or GeometryFM\n",
        "-   shape - a tuple of array dimensions (for each DataArray)\n",
        "-   dims - a tuple of dimension labels\n",
        "\n",
        "## Selecting items\n",
        "\n",
        "Selecting a specific item “itemA” (at position 0) from a Dataset ds can\n",
        "be done with:\n",
        "\n",
        "-   ds\\[\\[“itemA”\\]\\] - returns a new Dataset with “itemA”\n",
        "-   ds\\[“itemA”\\] - returns the “itemA” DataArray\n",
        "-   ds\\[\\[0\\]\\] - returns a new Dataset with “itemA”\n",
        "-   ds\\[0\\] - returns the “itemA” DataArray\n",
        "-   ds.itemA - returns the “itemA” DataArray\n",
        "\n",
        "## Examples"
      ],
      "id": "33cc83e5-c9e8-4e04-b70f-e7988606ec7d"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "<mikeio.Dataset>\n",
              "dims: (time:1, y:101, x:221)\n",
              "time: 2012-01-01 00:00:00 (time-invariant)\n",
              "geometry: Grid2D (ny=101, nx=221)\n",
              "items:\n",
              "  0:  Mean Sea Level Pressure <Air Pressure> (hectopascal)\n",
              "  1:  Wind x-comp (10m) <Wind Velocity> (meter per sec)\n",
              "  2:  Wind y-comp (10m) <Wind Velocity> (meter per sec)"
            ]
          }
        }
      ],
      "source": [
        "import mikeio\n",
        "mikeio.read(\"../data/europe_wind_long_lat.dfs2\")"
      ],
      "id": "9a1c3415"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attributes\n",
        "\n",
        "| Name | Description |\n",
        "|------------------------------------|------------------------------------|\n",
        "| [deletevalue](#mikeio.Dataset.deletevalue) | File delete value. |\n",
        "| [dims](#mikeio.Dataset.dims) | Named array dimensions of each DataArray. |\n",
        "| [end_time](#mikeio.Dataset.end_time) | Last time instance (as datetime). |\n",
        "| [geometry](#mikeio.Dataset.geometry) | Geometry of each DataArray. |\n",
        "| [is_equidistant](#mikeio.Dataset.is_equidistant) | Is Dataset equidistant in time? |\n",
        "| [items](#mikeio.Dataset.items) | ItemInfo for each of the DataArrays as a list. |\n",
        "| [n_elements](#mikeio.Dataset.n_elements) | Number of spatial elements/points. |\n",
        "| [n_items](#mikeio.Dataset.n_items) | Number of items/DataArrays, equivalent to len(). |\n",
        "| [n_timesteps](#mikeio.Dataset.n_timesteps) | Number of time steps. |\n",
        "| [names](#mikeio.Dataset.names) | Name of each of the DataArrays as a list. |\n",
        "| [ndim](#mikeio.Dataset.ndim) | Number of array dimensions of each DataArray. |\n",
        "| [shape](#mikeio.Dataset.shape) | Shape of each DataArray. |\n",
        "| [start_time](#mikeio.Dataset.start_time) | First time instance (as datetime). |\n",
        "| [time](#mikeio.Dataset.time) | Time axis. |\n",
        "| [timestep](#mikeio.Dataset.timestep) | Time step in seconds if equidistant (and at |\n",
        "\n",
        "## Methods\n",
        "\n",
        "| Name | Description |\n",
        "|------------------------------------|------------------------------------|\n",
        "| [aggregate](#mikeio.Dataset.aggregate) | Aggregate along an axis. |\n",
        "| [average](#mikeio.Dataset.average) | Compute the weighted average along the specified axis. |\n",
        "| [concat](#mikeio.Dataset.concat) | Concatenate Datasets along the time axis. |\n",
        "| [copy](#mikeio.Dataset.copy) | Returns a copy of this dataset. |\n",
        "| [create_data_array](#mikeio.Dataset.create_data_array) | Create a new DataArray with the same time and geometry as the dataset. |\n",
        "| [describe](#mikeio.Dataset.describe) | Generate descriptive statistics by wrapping :py:meth:`pandas.DataFrame.describe`. |\n",
        "| [dropna](#mikeio.Dataset.dropna) | Remove time steps where all items are NaN. |\n",
        "| [extract_track](#mikeio.Dataset.extract_track) | Extract data along a moving track. |\n",
        "| [flipud](#mikeio.Dataset.flipud) | Flip data upside down (on first non-time axis). |\n",
        "| [insert](#mikeio.Dataset.insert) | Insert DataArray in a specific position. |\n",
        "| [interp](#mikeio.Dataset.interp) | Interpolate data in time and space. |\n",
        "| [interp_like](#mikeio.Dataset.interp_like) | Interpolate in space (and in time) to other geometry (and time axis). |\n",
        "| [interp_time](#mikeio.Dataset.interp_time) | Temporal interpolation. |\n",
        "| [isel](#mikeio.Dataset.isel) | Return a new Dataset whose data is given by |\n",
        "| [max](#mikeio.Dataset.max) | Max value along an axis. |\n",
        "| [mean](#mikeio.Dataset.mean) | Mean value along an axis. |\n",
        "| [merge](#mikeio.Dataset.merge) | Merge Datasets along the item dimension. |\n",
        "| [min](#mikeio.Dataset.min) | Min value along an axis. |\n",
        "| [nanmax](#mikeio.Dataset.nanmax) | Max value along an axis (NaN removed). |\n",
        "| [nanmean](#mikeio.Dataset.nanmean) | Mean value along an axis (NaN removed). |\n",
        "| [nanmin](#mikeio.Dataset.nanmin) | Min value along an axis (NaN removed). |\n",
        "| [nanquantile](#mikeio.Dataset.nanquantile) | Compute the q-th quantile of the data along the specified axis, while ignoring nan values. |\n",
        "| [nanstd](#mikeio.Dataset.nanstd) | Standard deviation along an axis (NaN removed). |\n",
        "| [ptp](#mikeio.Dataset.ptp) | Range (max - min) a.k.a Peak to Peak along an axis |\n",
        "| [quantile](#mikeio.Dataset.quantile) | Compute the q-th quantile of the data along the specified axis. |\n",
        "| [remove](#mikeio.Dataset.remove) | Remove DataArray from Dataset. |\n",
        "| [rename](#mikeio.Dataset.rename) | Rename items (DataArrays) in Dataset. |\n",
        "| [sel](#mikeio.Dataset.sel) | Return a new Dataset whose data is given by |\n",
        "| [squeeze](#mikeio.Dataset.squeeze) | Remove axes of length 1. |\n",
        "| [std](#mikeio.Dataset.std) | Standard deviation along an axis. |\n",
        "| [to_dataframe](#mikeio.Dataset.to_dataframe) | Convert Dataset to a Pandas DataFrame. |\n",
        "| [to_dfs](#mikeio.Dataset.to_dfs) | Write dataset to a new dfs file. |\n",
        "| [to_numpy](#mikeio.Dataset.to_numpy) | Stack data to a single ndarray with shape (n_items, n_timesteps, …). |\n",
        "| [to_pandas](#mikeio.Dataset.to_pandas) | Convert Dataset to a Pandas DataFrame. |\n",
        "| [to_xarray](#mikeio.Dataset.to_xarray) | Export to xarray.Dataset. |\n",
        "\n",
        "### aggregate\n",
        "\n",
        "``` python\n",
        "Dataset.aggregate(axis=0, func=np.nanmean, **kwargs)\n",
        "```\n",
        "\n",
        "Aggregate along an axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|--------------------------------------------|-----------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| func | Callable | default np.nanmean | `np.nanmean` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                    |\n",
        "|------|---------|--------------------------------|\n",
        "|      | Dataset | dataset with aggregated values |\n",
        "\n",
        "### average\n",
        "\n",
        "``` python\n",
        "Dataset.average(weights, axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Compute the weighted average along the specified axis.\n",
        "\n",
        "Wraps :py:meth:`numpy.average`\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---------|-------|-----------------------------------------------|----------|\n",
        "| weights |  | weights to average over | *required* |\n",
        "| axis |  | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs |  | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                          |\n",
        "|------|---------|--------------------------------------|\n",
        "|      | Dataset | dataset with weighted average values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    nanmean : Mean values with NaN values removed\n",
        "    aggregate : Weighted average\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> dfs = Dfsu(\"HD2D.dfsu\")\n",
        ">>> ds = dfs.read([\"Current speed\"])\n",
        ">>> area = dfs.get_element_area()\n",
        ">>> ds2 = ds.average(axis=\"space\", weights=area)\n",
        "```\n",
        "\n",
        "### concat\n",
        "\n",
        "``` python\n",
        "Dataset.concat(datasets, keep='last')\n",
        "```\n",
        "\n",
        "Concatenate Datasets along the time axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-------|--------------------|-------------------------------------|--------|\n",
        "| datasets | Sequence\\['Dataset'\\] | list of Datasets to concatenate | *required* |\n",
        "| keep | Literal\\['last', 'first'\\] | which values to keep in case of overlap, by default 'last' | `'last'` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description          |\n",
        "|------|---------|----------------------|\n",
        "|      | Dataset | concatenated dataset |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> import mikeio\n",
        ">>> ds1 = mikeio.read(\"HD2D.dfsu\", time=[0,1])\n",
        ">>> ds2 = mikeio.read(\"HD2D.dfsu\", time=[2,3])\n",
        ">>> ds1.n_timesteps\n",
        "2\n",
        ">>> ds3 = Dataset.concat([ds1,ds2])\n",
        ">>> ds3.n_timesteps\n",
        "4\n",
        "```\n",
        "\n",
        "### copy\n",
        "\n",
        "``` python\n",
        "Dataset.copy()\n",
        "```\n",
        "\n",
        "Returns a copy of this dataset.\n",
        "\n",
        "### create_data_array\n",
        "\n",
        "``` python\n",
        "Dataset.create_data_array(data, item=None)\n",
        "```\n",
        "\n",
        "Create a new DataArray with the same time and geometry as the dataset.\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"file.dfsu\")\n",
        ">>> values = np.zeros(ds.Temperature.shape)\n",
        ">>> da = ds.create_data_array(values)\n",
        ">>> da_name = ds.create_data_array(values,\"Foo\")\n",
        ">>> da_eum = ds.create_data_array(values, item=mikeio.ItemInfo(\"TS\", mikeio.EUMType.Temperature))\n",
        "```\n",
        "\n",
        "### describe\n",
        "\n",
        "``` python\n",
        "Dataset.describe(**kwargs)\n",
        "```\n",
        "\n",
        "Generate descriptive statistics by wrapping\n",
        ":py:meth:`pandas.DataFrame.describe`.\n",
        "\n",
        "### dropna\n",
        "\n",
        "``` python\n",
        "Dataset.dropna()\n",
        "```\n",
        "\n",
        "Remove time steps where all items are NaN.\n",
        "\n",
        "### extract_track\n",
        "\n",
        "``` python\n",
        "Dataset.extract_track(track, method='nearest', dtype=np.float32)\n",
        "```\n",
        "\n",
        "Extract data along a moving track.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|----|-----------------|---------------------------------------------|------|\n",
        "| track | pd.DataFrame | with DatetimeIndex and (x, y) of track points as first two columns x,y coordinates must be in same coordinate system as dfsu | *required* |\n",
        "| track | pd.DataFrame | filename of csv or dfs0 file containing t,x,y | *required* |\n",
        "| method | Literal\\['nearest', 'inverse_distance'\\] | Spatial interpolation method ('nearest' or 'inverse_distance') default='nearest' | `'nearest'` |\n",
        "| dtype | Any | Data type of the returned data, default=np.float32 | `np.float32` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type | Description |\n",
        "|------|-------|-----------------------------------------------------------|\n",
        "|  | Dataset | A dataset with data dimension t The first two items will be x- and y- coordinates of track |\n",
        "\n",
        "### flipud\n",
        "\n",
        "``` python\n",
        "Dataset.flipud()\n",
        "```\n",
        "\n",
        "Flip data upside down (on first non-time axis).\n",
        "\n",
        "### insert\n",
        "\n",
        "``` python\n",
        "Dataset.insert(key, value)\n",
        "```\n",
        "\n",
        "Insert DataArray in a specific position.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|-------|-----------------------------------------------------|--------|\n",
        "| key | int | index in Dataset where DataArray should be inserted | *required* |\n",
        "| value | DataArray | DataArray to be inserted, must comform with with existing DataArrays and must have a unique item name | *required* |\n",
        "\n",
        "### interp\n",
        "\n",
        "``` python\n",
        "Dataset.interp(time=None, x=None, y=None, z=None, n_nearest=3, **kwargs)\n",
        "```\n",
        "\n",
        "Interpolate data in time and space.\n",
        "\n",
        "This method currently has limited functionality for spatial\n",
        "interpolation. It will be extended in the future.\n",
        "\n",
        "The spatial parameters available depend on the geometry of the Dataset:\n",
        "\n",
        "-   Grid1D: x\n",
        "-   Grid2D: x, y\n",
        "-   Grid3D: \\[not yet implemented!\\]\n",
        "-   GeometryFM: (x,y)\n",
        "-   GeometryFMLayered: (x,y) \\[surface point will be returned!\\]\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-----|-------------|--------------------------------------------------|-----|\n",
        "| time | (float, pd.DatetimeIndex or Dataset) | timestep in seconds or discrete time instances given by pd.DatetimeIndex (typically from another Dataset da2.time), by default None (=don't interp in time) | `None` |\n",
        "| x | float | x-coordinate of point to be interpolated to, by default None | `None` |\n",
        "| y | float | y-coordinate of point to be interpolated to, by default None | `None` |\n",
        "| z | float | z-coordinate of point to be interpolated to, by default None | `None` |\n",
        "| n_nearest | int | When using IDW interpolation, how many nearest points should be used, by default: 3 | `3` |\n",
        "| \\*\\*kwargs | Any | Additional keyword arguments are passed to the interpolant | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                    |\n",
        "|------|---------|--------------------------------|\n",
        "|      | Dataset | new Dataset with interped data |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "sel : Select data using label indexing interp_like : Interp to another\n",
        "time/space of another DataSet interp_time : Interp in the time direction\n",
        "only\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"random.dfs1\")\n",
        ">>> ds.interp(time=3600)\n",
        ">>> ds.interp(x=110)\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"HD2D.dfsu\")\n",
        ">>> ds.interp(x=340000, y=6160000)\n",
        "```\n",
        "\n",
        "### interp_like\n",
        "\n",
        "``` python\n",
        "Dataset.interp_like(other, **kwargs)\n",
        "```\n",
        "\n",
        "Interpolate in space (and in time) to other geometry (and time axis).\n",
        "\n",
        "Note: currently only supports interpolation from dfsu-2d to dfs2 or\n",
        "other dfsu-2d Datasets\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|--------------------------------|----------------------------|-------|\n",
        "| other | 'Dataset' \\| DataArray \\| Grid2D \\| GeometryFM2D \\| pd.DatetimeIndex | Dataset, DataArray, Grid2D or GeometryFM2D to interpolate to | *required* |\n",
        "| \\*\\*kwargs | Any | additional kwargs are passed to interpolation method | `{}` |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"HD.dfsu\")\n",
        ">>> ds2 = mikeio.read(\"wind.dfs2\")\n",
        ">>> dsi = ds.interp_like(ds2)\n",
        ">>> dsi.to_dfs(\"HD_gridded.dfs2\")\n",
        ">>> dse = ds.interp_like(ds2, extrapolate=True)\n",
        ">>> dst = ds.interp_like(ds2.time)\n",
        "```\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description          |\n",
        "|------|---------|----------------------|\n",
        "|      | Dataset | Interpolated Dataset |\n",
        "\n",
        "### interp_time\n",
        "\n",
        "``` python\n",
        "Dataset.interp_time(\n",
        "    dt=None\n",
        "    *\n",
        "    freq=None\n",
        "    method='linear'\n",
        "    extrapolate=True\n",
        "    fill_value=np.nan\n",
        ")\n",
        "```\n",
        "\n",
        "Temporal interpolation.\n",
        "\n",
        "Wrapper of :py:class:`scipy.interpolate.interp1d`\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---|---------|----------------------------------------------------------|---|\n",
        "| dt | float \\| pd.DatetimeIndex \\| 'Dataset' \\| DataArray \\| None | output timestep in seconds or discrete time instances given as a pd.DatetimeIndex (typically from another Dataset ds2.time) | `None` |\n",
        "| freq | str \\| None | pandas frequency | `None` |\n",
        "| method | str | Specifies the kind of interpolation as a string ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'previous', 'next', where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline interpolation of zeroth, first, second or third order; 'previous' and 'next' simply return the previous or next value of the point) or as an integer specifying the order of the spline interpolator to use. Default is 'linear'. | `'linear'` |\n",
        "| extrapolate | bool | Default True. If False, a ValueError is raised any time interpolation is attempted on a value outside of the range of x (where extrapolation is necessary). If True, out of bounds values are assigned fill_value | `True` |\n",
        "| fill_value | float | Default NaN. this value will be used to fill in for points outside of the time range. | `np.nan` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description |\n",
        "|------|---------|-------------|\n",
        "|      | Dataset |             |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"tests/testdata/HD2D.dfsu\")\n",
        ">>> ds\n",
        "<mikeio.Dataset>\n",
        "Dimensions: (9, 884)\n",
        "Time: 1985-08-06 07:00:00 - 1985-08-07 03:00:00\n",
        "Items:\n",
        "0:  Surface elevation <Surface Elevation> (meter)\n",
        "1:  U velocity <u velocity component> (meter per sec)\n",
        "2:  V velocity <v velocity component> (meter per sec)\n",
        "3:  Current speed <Current Speed> (meter per sec)\n",
        ">>> dsi = ds.interp_time(dt=1800)\n",
        ">>> dsi\n",
        "<mikeio.Dataset>\n",
        "Dimensions: (41, 884)\n",
        "Time: 1985-08-06 07:00:00 - 1985-08-07 03:00:00\n",
        "Items:\n",
        "0:  Surface elevation <Surface Elevation> (meter)\n",
        "1:  U velocity <u velocity component> (meter per sec)\n",
        "2:  V velocity <v velocity component> (meter per sec)\n",
        "3:  Current speed <Current Speed> (meter per sec)\n",
        ">>> dsi = ds.interp_time(freq='2H')\n",
        "```\n",
        "\n",
        "### isel\n",
        "\n",
        "``` python\n",
        "Dataset.isel(idx=None, axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Return a new Dataset whose data is given by integer indexing along the\n",
        "specified dimension(s).\n",
        "\n",
        "The spatial parameters available depend on the dims (i.e. geometry) of\n",
        "the Dataset:\n",
        "\n",
        "-   Grid1D: x\n",
        "-   Grid2D: x, y\n",
        "-   Grid3D: x, y, z\n",
        "-   GeometryFM: element\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|-------------------|-----------------------------------------|-------|\n",
        "| idx | int \\| Sequence\\[int\\] \\| slice \\| None | Index, or indices, along the specified dimension(s) | `None` |\n",
        "| axis | int \\| str | axis number or \"time\", by default 0 | `0` |\n",
        "| time | int | time index,by default None | *required* |\n",
        "| x | int | x index, by default None | *required* |\n",
        "| y | int | y index, by default None | *required* |\n",
        "| z | int | z index, by default None | *required* |\n",
        "| element | int | Bounding box of coordinates (left lower and right upper) to be selected, by default None | *required* |\n",
        "| \\*\\*kwargs | Any | Not used | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description         |\n",
        "|------|---------|---------------------|\n",
        "|      | Dataset | dataset with subset |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"europe_wind_long_lat.dfs2\")\n",
        ">>> ds.isel(time=-1)\n",
        ">>> ds.isel(x=slice(10,20), y=slice(40,60))\n",
        ">>> ds.isel(y=34)\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"tests/testdata/HD2D.dfsu\")\n",
        ">>> ds2 = ds.isel(time=[0,1,2])\n",
        ">>> ds3 = ds2.isel(elements=[100,200])\n",
        "```\n",
        "\n",
        "### max\n",
        "\n",
        "``` python\n",
        "Dataset.max(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Max value along an axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description             |\n",
        "|------|---------|-------------------------|\n",
        "|      | Dataset | dataset with max values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    nanmax : Max values with NaN values removed\n",
        "\n",
        "### mean\n",
        "\n",
        "``` python\n",
        "Dataset.mean(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Mean value along an axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description              |\n",
        "|------|---------|--------------------------|\n",
        "|      | Dataset | dataset with mean values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    nanmean : Mean values with NaN values removed\n",
        "    average : Weighted average\n",
        "\n",
        "### merge\n",
        "\n",
        "``` python\n",
        "Dataset.merge(datasets)\n",
        "```\n",
        "\n",
        "Merge Datasets along the item dimension.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name     | Type                  | Description               | Default    |\n",
        "|----------|-----------------------|---------------------------|------------|\n",
        "| datasets | Sequence\\['Dataset'\\] | list of Datasets to merge | *required* |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description    |\n",
        "|------|---------|----------------|\n",
        "|      | Dataset | merged dataset |\n",
        "\n",
        "### min\n",
        "\n",
        "``` python\n",
        "Dataset.min(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Min value along an axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description             |\n",
        "|------|---------|-------------------------|\n",
        "|      | Dataset | dataset with min values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    nanmin : Min values with NaN values removed\n",
        "\n",
        "### nanmax\n",
        "\n",
        "``` python\n",
        "Dataset.nanmax(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Max value along an axis (NaN removed).\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    max : Mean values\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description             |\n",
        "|------|---------|-------------------------|\n",
        "|      | Dataset | dataset with max values |\n",
        "\n",
        "### nanmean\n",
        "\n",
        "``` python\n",
        "Dataset.nanmean(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Mean value along an axis (NaN removed).\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description              |\n",
        "|------|---------|--------------------------|\n",
        "|      | Dataset | dataset with mean values |\n",
        "\n",
        "### nanmin\n",
        "\n",
        "``` python\n",
        "Dataset.nanmin(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Min value along an axis (NaN removed).\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description             |\n",
        "|------|---------|-------------------------|\n",
        "|      | Dataset | dataset with min values |\n",
        "\n",
        "### nanquantile\n",
        "\n",
        "``` python\n",
        "Dataset.nanquantile(q, *, axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Compute the q-th quantile of the data along the specified axis, while\n",
        "ignoring nan values.\n",
        "\n",
        "Wrapping np.nanquantile\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|---------------|--------------------------------------------|-------|\n",
        "| q | float \\| Sequence\\[float\\] | Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive. | *required* |\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds.nanquantile(q=[0.25,0.75])\n",
        ">>> ds.nanquantile(q=0.5)\n",
        ">>> ds.nanquantile(q=[0.01,0.5,0.99], axis=\"space\")\n",
        "```\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                  |\n",
        "|------|---------|------------------------------|\n",
        "|      | Dataset | dataset with quantile values |\n",
        "\n",
        "### nanstd\n",
        "\n",
        "``` python\n",
        "Dataset.nanstd(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Standard deviation along an axis (NaN removed).\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                            |\n",
        "|------|---------|----------------------------------------|\n",
        "|      | Dataset | dataset with standard deviation values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    std : Standard deviation\n",
        "\n",
        "### ptp\n",
        "\n",
        "``` python\n",
        "Dataset.ptp(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Range (max - min) a.k.a Peak to Peak along an axis\n",
        "\n",
        "#### Parameters.\n",
        "\n",
        "axis: (int, str, None), optional axis number or “time”, “space” or\n",
        "“items”, by default 0\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                      |\n",
        "|------|---------|----------------------------------|\n",
        "|      | Dataset | dataset with peak to peak values |\n",
        "\n",
        "### quantile\n",
        "\n",
        "``` python\n",
        "Dataset.quantile(q, *, axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Compute the q-th quantile of the data along the specified axis.\n",
        "\n",
        "Wrapping np.quantile\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|---------------|--------------------------------------------|-------|\n",
        "| q | float \\| Sequence\\[float\\] | Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive. | *required* |\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                  |\n",
        "|------|---------|------------------------------|\n",
        "|      | Dataset | dataset with quantile values |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds.quantile(q=[0.25,0.75])\n",
        ">>> ds.quantile(q=0.5)\n",
        ">>> ds.quantile(q=[0.01,0.5,0.99], axis=\"space\")\n",
        "```\n",
        "\n",
        "#### See Also\n",
        "\n",
        "nanquantile : quantile with NaN values ignored\n",
        "\n",
        "### remove\n",
        "\n",
        "``` python\n",
        "Dataset.remove(key)\n",
        "```\n",
        "\n",
        "Remove DataArray from Dataset.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|-----------|--------------------------------------------|-----------|\n",
        "| key | (int, str) | index or name of DataArray to be remove from Dataset | *required* |\n",
        "\n",
        "#### See also\n",
        "\n",
        "pop\n",
        "\n",
        "### rename\n",
        "\n",
        "``` python\n",
        "Dataset.rename(mapper, inplace=False)\n",
        "```\n",
        "\n",
        "Rename items (DataArrays) in Dataset.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|------|-----------|-------------------------------------------------|-------|\n",
        "| mapper | Mapping\\[str, str\\] | dictionary (or similar) mapping from old to new names | *required* |\n",
        "| inplace | bool | Should the renaming be done in the original dataset(=True) or return a new(=False)?, by default False | `False` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description |\n",
        "|------|---------|-------------|\n",
        "|      | Dataset |             |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"tide1.dfs1\")\n",
        ">>> newds = ds.rename({\"Level\":\"Surface Elevation\"})\n",
        ">>> ds.rename({\"Level\":\"Surface Elevation\"}, inplace=True)\n",
        "```\n",
        "\n",
        "### sel\n",
        "\n",
        "``` python\n",
        "Dataset.sel(**kwargs)\n",
        "```\n",
        "\n",
        "Return a new Dataset whose data is given by selecting index labels along\n",
        "the specified dimension(s).\n",
        "\n",
        "In contrast to Dataset.isel, indexers for this method should use labels\n",
        "instead of integers.\n",
        "\n",
        "The spatial parameters available depend on the geometry of the Dataset:\n",
        "\n",
        "-   Grid1D: x\n",
        "-   Grid2D: x, y, coords, area\n",
        "-   Grid3D: \\[not yet implemented! use isel instead\\]\n",
        "-   GeometryFM: (x,y), coords, area\n",
        "-   GeometryFMLayered: (x,y,z), coords, area, layers\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|----|------------|---------------------------------------------------|-----|\n",
        "| time | (str, pd.DatetimeIndex or Dataset) | time labels e.g. \"2018-01\" or slice(\"2018-1-1\",\"2019-1-1\"), by default None | *required* |\n",
        "| x | float | x-coordinate of point to be selected, by default None | *required* |\n",
        "| y | float | y-coordinate of point to be selected, by default None | *required* |\n",
        "| z | float | z-coordinate of point to be selected, by default None | *required* |\n",
        "| coords | np.array(float, float) | As an alternative to specifying x, y and z individually, the argument coords can be used instead. (x,y)- or (x,y,z)-coordinates of point to be selected, by default None | *required* |\n",
        "| area | (float, float, float, float) | Bounding box of coordinates (left lower and right upper) to be selected, by default None | *required* |\n",
        "| layers | int or str or list | layer(s) to be selected: \"top\", \"bottom\" or layer number from bottom 0,1,2,… or from the top -1,-2,… or as list of these; only for layered dfsu, by default None | *required* |\n",
        "| \\*\\*kwargs | Any | Not used | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                    |\n",
        "|------|---------|--------------------------------|\n",
        "|      | Dataset | new Dataset with selected data |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "isel : Select data using integer indexing\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"random.dfs1\")\n",
        ">>> ds.sel(time=slice(None, \"2012-1-1 00:02\"))\n",
        ">>> ds.sel(x=100)\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> ds = mikeio.read(\"oresund_sigma_z.dfsu\")\n",
        ">>> ds.sel(time=\"1997-09-15\")\n",
        ">>> ds.sel(x=340000, y=6160000, z=-3)\n",
        ">>> ds.sel(area=(340000, 6160000, 350000, 6170000))\n",
        ">>> ds.sel(layers=\"bottom\")\n",
        "```\n",
        "\n",
        "### squeeze\n",
        "\n",
        "``` python\n",
        "Dataset.squeeze()\n",
        "```\n",
        "\n",
        "Remove axes of length 1.\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description |\n",
        "|------|---------|-------------|\n",
        "|      | Dataset |             |\n",
        "\n",
        "### std\n",
        "\n",
        "``` python\n",
        "Dataset.std(axis=0, **kwargs)\n",
        "```\n",
        "\n",
        "Standard deviation along an axis.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|----------|---------------------------------------------|---------|\n",
        "| axis | int \\| str | axis number or \"time\", \"space\" or \"items\", by default 0 | `0` |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the function | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type    | Description                            |\n",
        "|------|---------|----------------------------------------|\n",
        "|      | Dataset | dataset with standard deviation values |\n",
        "\n",
        "#### See Also\n",
        "\n",
        "    nanstd : Standard deviation with NaN values removed\n",
        "\n",
        "### to_dataframe\n",
        "\n",
        "``` python\n",
        "Dataset.to_dataframe(unit_in_name=False, round_time='ms')\n",
        "```\n",
        "\n",
        "Convert Dataset to a Pandas DataFrame.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-----------|----------|-------------------------------------------|---------|\n",
        "| unit_in_name | bool | include unit in column name, default False, | `False` |\n",
        "| round_time | str \\| bool | round time to, by default \"ms\", use False to avoid rounding | `'ms'` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type         | Description |\n",
        "|------|--------------|-------------|\n",
        "|      | pd.DataFrame |             |\n",
        "\n",
        "### to_dfs\n",
        "\n",
        "``` python\n",
        "Dataset.to_dfs(filename, **kwargs)\n",
        "```\n",
        "\n",
        "Write dataset to a new dfs file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|---------|-----------------------------------------------|---------|\n",
        "| filename | str \\| Path | full path to the new dfs file | *required* |\n",
        "| \\*\\*kwargs | Any | additional arguments passed to the writing function, e.g. dtype for dfs0 | `{}` |\n",
        "\n",
        "### to_numpy\n",
        "\n",
        "``` python\n",
        "Dataset.to_numpy()\n",
        "```\n",
        "\n",
        "Stack data to a single ndarray with shape (n_items, n_timesteps, …).\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type       | Description |\n",
        "|------|------------|-------------|\n",
        "|      | np.ndarray |             |\n",
        "\n",
        "### to_pandas\n",
        "\n",
        "``` python\n",
        "Dataset.to_pandas(**kwargs)\n",
        "```\n",
        "\n",
        "Convert Dataset to a Pandas DataFrame.\n",
        "\n",
        "### to_xarray\n",
        "\n",
        "``` python\n",
        "Dataset.to_xarray()\n",
        "```\n",
        "\n",
        "Export to xarray.Dataset."
      ],
      "id": "35486841-9b6b-4909-bdc5-91d44f11cf31"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/opt/hostedtoolcache/Python/3.12.7/x64/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  }
}