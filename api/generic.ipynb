{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "# generic\n",
        "\n",
        "`generic`\n",
        "\n",
        "Generic functions for working with all types of dfs files.\n",
        "\n",
        "## Functions\n",
        "\n",
        "| Name | Description |\n",
        "|------------------------------------|------------------------------------|\n",
        "| [avg_time](#mikeio.generic.avg_time) | Create a temporally averaged dfs file. |\n",
        "| [concat](#mikeio.generic.concat) | Concatenates files along the time axis. |\n",
        "| [diff](#mikeio.generic.diff) | Calculate difference between two dfs files (a-b). |\n",
        "| [extract](#mikeio.generic.extract) | Extract timesteps and/or items to a new dfs file. |\n",
        "| [fill_corrupt](#mikeio.generic.fill_corrupt) | Replace corrupt (unreadable) data with fill_value, default delete value. |\n",
        "| [quantile](#mikeio.generic.quantile) | Create temporal quantiles of all items in dfs file. |\n",
        "| [scale](#mikeio.generic.scale) | Apply scaling to any dfs file. |\n",
        "| [sum](#mikeio.generic.sum) | Sum two dfs files (a+b). |\n",
        "\n",
        "### avg_time\n",
        "\n",
        "``` python\n",
        "generic.avg_time(infilename, outfilename, skipna=True)\n",
        "```\n",
        "\n",
        "Create a temporally averaged dfs file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---------|--------------|-----------------------------------------|---------|\n",
        "| infilename | str \\| pathlib.Path | input filename | *required* |\n",
        "| outfilename | str \\| pathlib.Path | output filename | *required* |\n",
        "| skipna | bool | exclude NaN/delete values when computing the result, default True | `True` |\n",
        "\n",
        "### concat\n",
        "\n",
        "``` python\n",
        "generic.concat(infilenames, outfilename, keep='last')\n",
        "```\n",
        "\n",
        "Concatenates files along the time axis.\n",
        "\n",
        "Overlap handling is defined by the `keep` argument, by default the last\n",
        "one will be used.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-------|----------------|--------------------------------------------|-------|\n",
        "| infilenames | Sequence\\[str \\| pathlib.Path\\] | filenames to concatenate | *required* |\n",
        "| outfilename | str \\| pathlib.Path | filename of output | *required* |\n",
        "| keep | str | either ‘first’ (keep older), ‘last’ (keep newer) or ‘average’ can be selected. By default ‘last’ | `'last'` |\n",
        "\n",
        "#### Notes\n",
        "\n",
        "The list of input files have to be sorted, i.e. in chronological order\n",
        "\n",
        "### diff\n",
        "\n",
        "``` python\n",
        "generic.diff(infilename_a, infilename_b, outfilename)\n",
        "```\n",
        "\n",
        "Calculate difference between two dfs files (a-b).\n",
        "\n",
        "### extract\n",
        "\n",
        "``` python\n",
        "generic.extract(infilename, outfilename, start=0, end=-1, step=1, items=None)\n",
        "```\n",
        "\n",
        "Extract timesteps and/or items to a new dfs file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-------|----------------|--------------------------------------------|-------|\n",
        "| infilename | str \\| pathlib.Path | path to input dfs file | *required* |\n",
        "| outfilename | str \\| pathlib.Path | path to output dfs file | *required* |\n",
        "| start | (int, float, str or datetime) | start of extraction as either step, relative seconds or datetime/str, by default 0 (start of file) | `0` |\n",
        "| end | (int, float, str or datetime) | end of extraction as either step, relative seconds or datetime/str, by default -1 (end of file) | `-1` |\n",
        "| step | int | jump this many step, by default 1 (every step between start and end) | `1` |\n",
        "| items | (int, list(int), str, list(str)) | items to be extracted to new file | `None` |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> extract('f_in.dfs0', 'f_out.dfs0', start='2018-1-1')\n",
        ">>> extract('f_in.dfs2', 'f_out.dfs2', end=-3)\n",
        ">>> extract('f_in.dfsu', 'f_out.dfsu', start=1800.0, end=3600.0)\n",
        ">>> extract('f_hourly.dfsu', 'f_daily.dfsu', step=24)\n",
        ">>> extract('f_in.dfsu', 'f_out.dfsu', items=[2, 0])\n",
        ">>> extract('f_in.dfsu', 'f_out.dfsu', items=\"Salinity\")\n",
        ">>> extract('f_in.dfsu', 'f_out.dfsu', end='2018-2-1 00:00', items=\"Salinity\")\n",
        "```\n",
        "\n",
        "### fill_corrupt\n",
        "\n",
        "``` python\n",
        "generic.fill_corrupt(infilename, outfilename, fill_value=np.nan, items=None)\n",
        "```\n",
        "\n",
        "Replace corrupt (unreadable) data with fill_value, default delete value.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|------------------|----------------------------------------|--------|\n",
        "| infilename | str \\| pathlib.Path | full path to the input file | *required* |\n",
        "| outfilename | str \\| pathlib.Path | full path to the output file | *required* |\n",
        "| fill_value | float | value to use where data is corrupt, default delete value | `np.nan` |\n",
        "| items | Sequence\\[str \\| int\\] \\| None | Process only selected items, by number (0-based) or name, by default: all | `None` |\n",
        "\n",
        "### quantile\n",
        "\n",
        "``` python\n",
        "generic.quantile(\n",
        "    infilename,\n",
        "    outfilename,\n",
        "    q,\n",
        "    *,\n",
        "    items=None,\n",
        "    skipna=True,\n",
        "    buffer_size=1000000000.0,\n",
        ")\n",
        "```\n",
        "\n",
        "Create temporal quantiles of all items in dfs file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|-----|----------|----------------------------------------------------|------|\n",
        "| infilename | str \\| pathlib.Path | input filename | *required* |\n",
        "| outfilename | str \\| pathlib.Path | output filename | *required* |\n",
        "| q | float \\| Sequence\\[float\\] | Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive. | *required* |\n",
        "| items | Sequence\\[int \\| str\\] \\| None | Process only selected items, by number (0-based) or name, by default: all | `None` |\n",
        "| skipna | bool | exclude NaN/delete values when computing the result, default True | `True` |\n",
        "| buffer_size | float | for huge files the quantiles need to be calculated for chunks of elements. buffer_size gives the maximum amount of memory available for the computation in bytes, by default 1e9 (=1GB) | `1000000000.0` |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> quantile(\"in.dfsu\", \"IQR.dfsu\", q=[0.25,0.75])\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> quantile(\"huge.dfsu\", \"Q01.dfsu\", q=0.1, buffer_size=5.0e9)\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> quantile(\"with_nans.dfsu\", \"Q05.dfsu\", q=0.5, skipna=False)\n",
        "```\n",
        "\n",
        "### scale\n",
        "\n",
        "``` python\n",
        "generic.scale(infilename, outfilename, offset=0.0, factor=1.0, items=None)\n",
        "```\n",
        "\n",
        "Apply scaling to any dfs file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|--------|------------------|----------------------------------------|--------|\n",
        "| infilename | str \\| pathlib.Path | full path to the input file | *required* |\n",
        "| outfilename | str \\| pathlib.Path | full path to the output file | *required* |\n",
        "| offset | float | value to add to all items, default 0.0 | `0.0` |\n",
        "| factor | float | value to multiply to all items, default 1.0 | `1.0` |\n",
        "| items | Sequence\\[int \\| str\\] \\| None | Process only selected items, by number (0-based) or name, by default: all | `None` |\n",
        "\n",
        "### sum\n",
        "\n",
        "``` python\n",
        "generic.sum(infilename_a, infilename_b, outfilename)\n",
        "```\n",
        "\n",
        "Sum two dfs files (a+b)."
      ],
      "id": "217525ab-e31f-4aca-ae84-c04024114fe2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}