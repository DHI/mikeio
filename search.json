[
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "MIKE IO: input/output of MIKE files in Python",
    "section": "Requirements",
    "text": "Requirements\n\nWindows or Linux operating system\nPython x64 3.8 - 3.11\n(Windows) VC++ redistributables (already installed if you have MIKE)"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "MIKE IO: input/output of MIKE files in Python",
    "section": "Installation",
    "text": "Installation\n$ pip install mikeio\n\n\n\n\n\n\nWarning\n\n\n\nDon’t use conda to install MIKE IO!, the version on conda is outdated."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "MIKE IO: input/output of MIKE files in Python",
    "section": "Getting started",
    "text": "Getting started\n\nimport mikeio\n\nds = mikeio.read(\"data/FakeLake.dfsu\")\nds.Bathymetry.plot()\n\n\n\n\n\n\n\n\nRead more in the getting started guide."
  },
  {
    "objectID": "index.html#where-can-i-get-help",
    "href": "index.html#where-can-i-get-help",
    "title": "MIKE IO: input/output of MIKE files in Python",
    "section": "Where can I get help?",
    "text": "Where can I get help?\n\nNew ideas and feature requests - GitHub Discussions\nBugs - GitHub Issues"
  },
  {
    "objectID": "api/read.html",
    "href": "api/read.html",
    "title": "read",
    "section": "",
    "text": "read(filename, *, items=None, time=None, keepdims=False, **kwargs)\nRead all or a subset of the data from a dfs file\nAll dfs files can be subsetted with the items and time arguments. But the following file types also have the shown additional arguments:\n\nDfs2: area\nDfs3: layers\nDfsu-2d: (x,y), elements, area\nDfsu-layered: (xy,z), elements, area, layers\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path and file name to the dfs file.\nrequired\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name, by default None (=all)\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\nx\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\ny\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\nz\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\narea\n\nDfs2/Dfsu: read only data within an area given by a bounding box of coordinates (left, lower, right, upper), by default None (=all)\nrequired\n\n\nlayers\n\nDfs3/Dfsu-layered: read only data from specific layers, by default None (=all layers)\nrequired\n\n\nerror_bad_data\n\nraise error if data is corrupt, by default True,\nrequired\n\n\nfill_bad_data_value\n\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with specification according to the file type\n\n\n\n\n\n\nmikeio.open - open a Dfs file and only read the header\n\n\n\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\")\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=0)\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=\"Temperature\")\n&gt;&gt;&gt; ds = mikeio.read(\"sw_points.dfs0, items=\"*Buoy 4*\")\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=[\"u\",\"v\"], time=\"2016\")\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=\"2018-5\")\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=slice(\"2018-5-1\",\"2018-6-1\"))\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", items=[0,3,6], time=-1)\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=-1, keepdims=True)\n&gt;&gt;&gt; ds = mikeio.read(\"era5.dfs2\", area=(10,50,16,58))\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", x=2.2, y=54.2)\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", elements=183)\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", elements=range(0,2000))\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", area=(10,50,16,58))\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", x=11.4, y=56.2)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", x=11.4, y=56.2, z=-1.1)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", elements=lst_of_elems)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", layers=\"bottom\")\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", layers=[-2,-1])\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", error_bad_data=False) # replace corrupt data with np.nan\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", error_bad_data=False, fill_bad_data_value=0.0) # replace corrupt data with 0.0"
  },
  {
    "objectID": "api/read.html#parameters",
    "href": "api/read.html#parameters",
    "title": "read",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path and file name to the dfs file.\nrequired\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name, by default None (=all)\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\nx\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\ny\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\nz\n\nDfsu: Read only data for elements containing the (x,y) or (x,y,z) points(s), by default None\nrequired\n\n\narea\n\nDfs2/Dfsu: read only data within an area given by a bounding box of coordinates (left, lower, right, upper), by default None (=all)\nrequired\n\n\nlayers\n\nDfs3/Dfsu-layered: read only data from specific layers, by default None (=all layers)\nrequired\n\n\nerror_bad_data\n\nraise error if data is corrupt, by default True,\nrequired\n\n\nfill_bad_data_value\n\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nrequired"
  },
  {
    "objectID": "api/read.html#returns",
    "href": "api/read.html#returns",
    "title": "read",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with specification according to the file type"
  },
  {
    "objectID": "api/read.html#see-also",
    "href": "api/read.html#see-also",
    "title": "read",
    "section": "",
    "text": "mikeio.open - open a Dfs file and only read the header"
  },
  {
    "objectID": "api/read.html#examples",
    "href": "api/read.html#examples",
    "title": "read",
    "section": "",
    "text": "&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\")\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=0)\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=\"Temperature\")\n&gt;&gt;&gt; ds = mikeio.read(\"sw_points.dfs0, items=\"*Buoy 4*\")\n&gt;&gt;&gt; ds = mikeio.read(\"ts.dfs0\", items=[\"u\",\"v\"], time=\"2016\")\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=\"2018-5\")\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=slice(\"2018-5-1\",\"2018-6-1\"))\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", items=[0,3,6], time=-1)\n&gt;&gt;&gt; ds = mikeio.read(\"tide.dfs1\", time=-1, keepdims=True)\n&gt;&gt;&gt; ds = mikeio.read(\"era5.dfs2\", area=(10,50,16,58))\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", x=2.2, y=54.2)\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", elements=183)\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", elements=range(0,2000))\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", area=(10,50,16,58))\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", x=11.4, y=56.2)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", x=11.4, y=56.2, z=-1.1)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", elements=lst_of_elems)\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", layers=\"bottom\")\n&gt;&gt;&gt; ds = mikeio.read(\"MT3D_sigma_z.dfsu\", layers=[-2,-1])\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", error_bad_data=False) # replace corrupt data with np.nan\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\", error_bad_data=False, fill_bad_data_value=0.0) # replace corrupt data with 0.0"
  },
  {
    "objectID": "api/Dataset.html",
    "href": "api/Dataset.html",
    "title": "Dataset",
    "section": "",
    "text": "Dataset(self, data, time=None, items=None, geometry=None, zn=None, dims=None, validate=True)\nDataset containing one or more DataArrays with common geometry and time\nMost often obtained by reading a dfs file. But can also be created a sequence or dictonary of DataArrays. The mikeio.Dataset is inspired by and similar to the xarray.Dataset.\nThe Dataset is primarily a container for one or more DataArrays all having the same time and geometry (and shape, dims, etc). For convenience, the Dataset provides access to these common properties:"
  },
  {
    "objectID": "api/Dataset.html#selecting-items",
    "href": "api/Dataset.html#selecting-items",
    "title": "Dataset",
    "section": "Selecting Items",
    "text": "Selecting Items\nSelecting a specific item “itemA” (at position 0) from a Dataset ds can be done with:\n\nds[[“itemA”]] - returns a new Dataset with “itemA”\nds[“itemA”] - returns the “itemA” DataArray\nds[[0]] - returns a new Dataset with “itemA”\nds[0] - returns the “itemA” DataArray\nds.itemA - returns the “itemA” DataArray"
  },
  {
    "objectID": "api/Dataset.html#examples",
    "href": "api/Dataset.html#examples",
    "title": "Dataset",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.read(\"../data/europe_wind_long_lat.dfs2\")\n\n&lt;mikeio.Dataset&gt;\ndims: (time:1, y:101, x:221)\ntime: 2012-01-01 00:00:00 (time-invariant)\ngeometry: Grid2D (ny=101, nx=221)\nitems:\n  0:  Mean Sea Level Pressure &lt;Air Pressure&gt; (hectopascal)\n  1:  Wind x-comp (10m) &lt;Wind Velocity&gt; (meter per sec)\n  2:  Wind y-comp (10m) &lt;Wind Velocity&gt; (meter per sec)"
  },
  {
    "objectID": "api/Dataset.html#attributes",
    "href": "api/Dataset.html#attributes",
    "title": "Dataset",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndims\nNamed array dimensions of each DataArray\n\n\nend_time\nLast time instance (as datetime)\n\n\ngeometry\nGeometry of each DataArray\n\n\nis_equidistant\nIs Dataset equidistant in time?\n\n\nitems\nItemInfo for each of the DataArrays as a list\n\n\nn_elements\nNumber of spatial elements/points\n\n\nn_items\nNumber of items/DataArrays, equivalent to len()\n\n\nn_timesteps\nNumber of time steps\n\n\nnames\nName of each of the DataArrays as a list\n\n\nndim\nNumber of array dimensions of each DataArray\n\n\nshape\nShape of each DataArray\n\n\nstart_time\nFirst time instance (as datetime)\n\n\ntime\nTime axis\n\n\ntimestep\nTime step in seconds if equidistant (and at"
  },
  {
    "objectID": "api/Dataset.html#methods",
    "href": "api/Dataset.html#methods",
    "title": "Dataset",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\naggregate\nAggregate along an axis\n\n\naverage\nCompute the weighted average along the specified axis.\n\n\nconcat\nConcatenate Datasets along the time axis\n\n\ncopy\nReturns a copy of this dataset.\n\n\ncreate_data_array\nCreate a new DataArray with the same time and geometry as the dataset\n\n\ndescribe\nGenerate descriptive statistics by wrapping :py:meth:pandas.DataFrame.describe\n\n\ndropna\nRemove time steps where all items are NaN\n\n\nextract_track\nExtract data along a moving track\n\n\nflipud\nFlip data upside down (on first non-time axis)\n\n\ninsert\nInsert DataArray in a specific position\n\n\ninterp\nInterpolate data in time and space\n\n\ninterp_like\nInterpolate in space (and in time) to other geometry (and time axis)\n\n\ninterp_time\nTemporal interpolation\n\n\nisel\nReturn a new Dataset whose data is given by\n\n\nmax\nMax value along an axis\n\n\nmean\nMean value along an axis\n\n\nmerge\nMerge Datasets along the item dimension\n\n\nmin\nMin value along an axis\n\n\nnanmax\nMax value along an axis (NaN removed)\n\n\nnanmean\nMean value along an axis (NaN removed)\n\n\nnanmin\nMin value along an axis (NaN removed)\n\n\nnanquantile\nCompute the q-th quantile of the data along the specified axis, while ignoring nan values.\n\n\nnanstd\nStandard deviation along an axis (NaN removed)\n\n\nptp\nRange (max - min) a.k.a Peak to Peak along an axis\n\n\nquantile\nCompute the q-th quantile of the data along the specified axis.\n\n\nremove\nRemove DataArray from Dataset\n\n\nrename\nRename items (DataArrays) in Dataset\n\n\nsel\nReturn a new Dataset whose data is given by\n\n\nsqueeze\nRemove axes of length 1\n\n\nstd\nStandard deviation along an axis\n\n\nto_dataframe\nConvert Dataset to a Pandas DataFrame\n\n\nto_dfs\nWrite dataset to a new dfs file\n\n\nto_numpy\nStack data to a single ndarray with shape (n_items, n_timesteps, …)\n\n\nto_pandas\nConvert Dataset to a Pandas DataFrame\n\n\nto_xarray\nExport to xarray.Dataset\n\n\n\n\naggregate\nDataset.aggregate(axis=0, func=np.nanmean, **kwargs)\nAggregate along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\nfunc\ntyping.Callable\ndefault np.nanmean\nnp.nanmean\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with aggregated values\n\n\n\n\n\n\naverage\nDataset.average(weights, axis=0, **kwargs)\nCompute the weighted average along the specified axis.\nWraps :py:meth:numpy.average\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nweights\n\nweights to average over\nrequired\n\n\naxis\n\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with weighted average values\n\n\n\n\n\nSee Also\nnanmean : Mean values with NaN values removed\naggregate : Weighted average\n\n\nExamples\n&gt;&gt;&gt; dfs = Dfsu(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds = dfs.read([\"Current speed\"])\n&gt;&gt;&gt; area = dfs.get_element_area()\n&gt;&gt;&gt; ds2 = ds.average(axis=\"space\", weights=area)\n\n\n\nconcat\nDataset.concat(datasets, keep='last')\nConcatenate Datasets along the time axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndatasets\ntyping.Sequence[‘Dataset’]\n\nrequired\n\n\nkeep\ntyping.Literal[‘last’]\nTODO Yet to be implemented, default: last\n'last'\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nconcatenated dataset\n\n\n\n\n\nExamples\n&gt;&gt;&gt; import mikeio\n&gt;&gt;&gt; ds1 = mikeio.read(\"HD2D.dfsu\", time=[0,1])\n&gt;&gt;&gt; ds2 = mikeio.read(\"HD2D.dfsu\", time=[2,3])\n&gt;&gt;&gt; ds1.n_timesteps\n2\n&gt;&gt;&gt; ds3 = Dataset.concat([ds1,ds2])\n&gt;&gt;&gt; ds3.n_timesteps\n4\n\n\n\ncopy\nDataset.copy()\nReturns a copy of this dataset.\n\n\ncreate_data_array\nDataset.create_data_array(data, item=None)\nCreate a new DataArray with the same time and geometry as the dataset\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"file.dfsu\")\n&gt;&gt;&gt; values = np.zeros(ds.Temperature.shape)\n&gt;&gt;&gt; da = ds.create_data_array(values)\n&gt;&gt;&gt; da_name = ds.create_data_array(values,\"Foo\")\n&gt;&gt;&gt; da_eum = ds.create_data_array(values, item=mikeio.ItemInfo(\"TS\", mikeio.EUMType.Temperature))\n\n\n\ndescribe\nDataset.describe(**kwargs)\nGenerate descriptive statistics by wrapping :py:meth:pandas.DataFrame.describe\n\n\ndropna\nDataset.dropna()\nRemove time steps where all items are NaN\n\n\nextract_track\nDataset.extract_track(track, method='nearest', dtype=np.float32)\nExtract data along a moving track\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack\npandas.pandas.DataFrame\nwith DatetimeIndex and (x, y) of track points as first two columns x,y coordinates must be in same coordinate system as dfsu\nrequired\n\n\ntrack\npandas.pandas.DataFrame\nfilename of csv or dfs0 file containing t,x,y\nrequired\n\n\nmethod\ntyping.Literal[‘nearest’, ‘inverse_distance’]\nSpatial interpolation method (‘nearest’ or ‘inverse_distance’) default=‘nearest’\n'nearest'\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nA dataset with data dimension t The first two items will be x- and y- coordinates of track\n\n\n\n\n\n\nflipud\nDataset.flipud()\nFlip data upside down (on first non-time axis)\n\n\ninsert\nDataset.insert(key, value)\nInsert DataArray in a specific position\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkey\nint\nindex in Dataset where DataArray should be inserted\nrequired\n\n\nvalue\nmikeio.dataset._dataarray.DataArray\nDataArray to be inserted, must comform with with existing DataArrays and must have a unique item name\nrequired\n\n\n\n\n\n\ninterp\nDataset.interp(time=None, x=None, y=None, z=None, n_nearest=3, **kwargs)\nInterpolate data in time and space\nThis method currently has limited functionality for spatial interpolation. It will be extended in the future.\nThe spatial parameters available depend on the geometry of the Dataset:\n\nGrid1D: x\nGrid2D: x, y\nGrid3D: [not yet implemented!]\nGeometryFM: (x,y)\nGeometryFMLayered: (x,y) [surface point will be returned!]\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntime\n(float, pandas.pandas.DatetimeIndex or mikeio.dataset._dataset.Dataset)\ntimestep in seconds or discrete time instances given by pd.DatetimeIndex (typically from another Dataset da2.time), by default None (=don’t interp in time)\nNone\n\n\nx\nfloat\nx-coordinate of point to be interpolated to, by default None\nNone\n\n\ny\nfloat\ny-coordinate of point to be interpolated to, by default None\nNone\n\n\nn_nearest\nint\nWhen using IDW interpolation, how many nearest points should be used, by default: 3\n3\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nnew Dataset with interped data\n\n\n\n\n\nSee Also\nsel : Select data using label indexing interp_like : Interp to another time/space of another DataSet interp_time : Interp in the time direction only\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"random.dfs1\")\n&gt;&gt;&gt; ds.interp(time=3600)\n&gt;&gt;&gt; ds.interp(x=110)\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds.interp(x=340000, y=6160000)\n\n\n\ninterp_like\nDataset.interp_like(other, **kwargs)\nInterpolate in space (and in time) to other geometry (and time axis)\nNote: currently only supports interpolation from dfsu-2d to dfs2 or other dfsu-2d Datasets\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nother\n‘Dataset’ | mikeio.dataset._dataarray.DataArray | mikeio.spatial.Grid2D | mikeio.spatial.GeometryFM2D | pandas.pandas.DatetimeIndex\n\nrequired\n\n\nkwargs\ntyping.Any\n\n{}\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"HD.dfsu\")\n&gt;&gt;&gt; ds2 = mikeio.read(\"wind.dfs2\")\n&gt;&gt;&gt; dsi = ds.interp_like(ds2)\n&gt;&gt;&gt; dsi.to_dfs(\"HD_gridded.dfs2\")\n&gt;&gt;&gt; dse = ds.interp_like(ds2, extrapolate=True)\n&gt;&gt;&gt; dst = ds.interp_like(ds2.time)\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nInterpolated Dataset\n\n\n\n\n\n\ninterp_time\nDataset.interp_time(dt=None, *, freq=None, method='linear', extrapolate=True, fill_value=np.nan)\nTemporal interpolation\nWrapper of :py:class:scipy.interpolate.interp1d\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndt\nfloat | pandas.pandas.DatetimeIndex | ‘Dataset’ | mikeio.dataset._dataarray.DataArray | None\noutput timestep in seconds or discrete time instances given as a pd.DatetimeIndex (typically from another Dataset ds2.time)\nNone\n\n\nfreq\nstr | None\npandas frequency\nNone\n\n\nmethod\nstr\nSpecifies the kind of interpolation as a string (‘linear’, ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘previous’, ‘next’, where ‘zero’, ‘slinear’, ‘quadratic’ and ‘cubic’ refer to a spline interpolation of zeroth, first, second or third order; ‘previous’ and ‘next’ simply return the previous or next value of the point) or as an integer specifying the order of the spline interpolator to use. Default is ‘linear’.\n'linear'\n\n\nextrapolate\nbool\nDefault True. If False, a ValueError is raised any time interpolation is attempted on a value outside of the range of x (where extrapolation is necessary). If True, out of bounds values are assigned fill_value\nTrue\n\n\nfill_value\nfloat\nDefault NaN. this value will be used to fill in for points outside of the time range.\nnp.nan\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\n\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"tests/testdata/HD2D.dfsu\")\n&gt;&gt;&gt; ds\n&lt;mikeio.Dataset&gt;\nDimensions: (9, 884)\nTime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00\nItems:\n0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n1:  U velocity &lt;u velocity component&gt; (meter per sec)\n2:  V velocity &lt;v velocity component&gt; (meter per sec)\n3:  Current speed &lt;Current Speed&gt; (meter per sec)\n&gt;&gt;&gt; dsi = ds.interp_time(dt=1800)\n&gt;&gt;&gt; dsi\n&lt;mikeio.Dataset&gt;\nDimensions: (41, 884)\nTime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00\nItems:\n0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n1:  U velocity &lt;u velocity component&gt; (meter per sec)\n2:  V velocity &lt;v velocity component&gt; (meter per sec)\n3:  Current speed &lt;Current Speed&gt; (meter per sec)\n&gt;&gt;&gt; dsi = ds.interp_time(freq='2H')\n\n\n\nisel\nDataset.isel(idx=None, axis=0, **kwargs)\nReturn a new Dataset whose data is given by integer indexing along the specified dimension(s).\nThe spatial parameters available depend on the dims (i.e. geometry) of the Dataset:\n\nGrid1D: x\nGrid2D: x, y\nGrid3D: x, y, z\nGeometryFM: element\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidx\nint | typing.Sequence[int] | slice | None\n\nNone\n\n\naxis\nint | str\naxis number or “time”, by default 0\n0\n\n\ntime\nint\ntime index,by default None\nrequired\n\n\nx\nint\nx index, by default None\nrequired\n\n\ny\nint\ny index, by default None\nrequired\n\n\nz\nint\nz index, by default None\nrequired\n\n\nelement\nint\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nrequired\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with subset\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"europe_wind_long_lat.dfs2\")\n&gt;&gt;&gt; ds.isel(time=-1)\n&gt;&gt;&gt; ds.isel(x=slice(10,20), y=slice(40,60))\n&gt;&gt;&gt; ds.isel(y=34)\n&gt;&gt;&gt; ds = mikeio.read(\"tests/testdata/HD2D.dfsu\")\n&gt;&gt;&gt; ds2 = ds.isel(time=[0,1,2])\n&gt;&gt;&gt; ds3 = ds2.isel(elements=[100,200])\n\n\n\nmax\nDataset.max(axis=0, **kwargs)\nMax value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with max values\n\n\n\n\n\nSee Also\nnanmax : Max values with NaN values removed\n\n\n\nmean\nDataset.mean(axis=0, **kwargs)\nMean value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with mean values\n\n\n\n\n\nSee Also\nnanmean : Mean values with NaN values removed\naverage : Weighted average\n\n\n\nmerge\nDataset.merge(datasets)\nMerge Datasets along the item dimension\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndatasets\ntyping.Sequence[‘Dataset’]\n\nrequired\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nmerged dataset\n\n\n\n\n\n\nmin\nDataset.min(axis=0, **kwargs)\nMin value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with min values\n\n\n\n\n\nSee Also\nnanmin : Min values with NaN values removed\n\n\n\nnanmax\nDataset.nanmax(axis=0, **kwargs)\nMax value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nSee Also\nmax : Mean values\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with max values\n\n\n\n\n\n\nnanmean\nDataset.nanmean(axis=0, **kwargs)\nMean value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with mean values\n\n\n\n\n\n\nnanmin\nDataset.nanmin(axis=0, **kwargs)\nMin value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with min values\n\n\n\n\n\n\nnanquantile\nDataset.nanquantile(q, *, axis=0, **kwargs)\nCompute the q-th quantile of the data along the specified axis, while ignoring nan values.\nWrapping np.nanquantile\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nq\nfloat | typing.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds.nanquantile(q=[0.25,0.75])\n&gt;&gt;&gt; ds.nanquantile(q=0.5)\n&gt;&gt;&gt; ds.nanquantile(q=[0.01,0.5,0.99], axis=\"space\")\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with quantile values\n\n\n\n\n\n\nnanstd\nDataset.nanstd(axis=0, **kwargs)\nStandard deviation along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with standard deviation values\n\n\n\n\n\nSee Also\nstd : Standard deviation\n\n\n\nptp\nDataset.ptp(axis=0, **kwargs)\nRange (max - min) a.k.a Peak to Peak along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with peak to peak values\n\n\n\n\n\n\nquantile\nDataset.quantile(q, *, axis=0, **kwargs)\nCompute the q-th quantile of the data along the specified axis.\nWrapping np.quantile\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nq\nfloat | typing.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with quantile values\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds.quantile(q=[0.25,0.75])\n&gt;&gt;&gt; ds.quantile(q=0.5)\n&gt;&gt;&gt; ds.quantile(q=[0.01,0.5,0.99], axis=\"space\")\n\n\nSee Also\nnanquantile : quantile with NaN values ignored\n\n\n\nremove\nDataset.remove(key)\nRemove DataArray from Dataset\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkey\n(int, str)\nindex or name of DataArray to be remove from Dataset\nrequired\n\n\n\n\n\nSee Also\npop\n\n\n\nrename\nDataset.rename(mapper, inplace=False)\nRename items (DataArrays) in Dataset\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmapper\ntyping.Mapping[str, str]\ndictionary (or similar) mapping from old to new names\nrequired\n\n\ninplace\nbool\nShould the renaming be done in the original dataset(=True) or return a new(=False)?, by default False\nFalse\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\n\n\n\n\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"tide1.dfs1\")\n&gt;&gt;&gt; newds = ds.rename({\"Level\":\"Surface Elevation\"})\n&gt;&gt;&gt; ds.rename({\"Level\":\"Surface Elevation\"}, inplace=True)\n\n\n\nsel\nDataset.sel(**kwargs)\nReturn a new Dataset whose data is given by selecting index labels along the specified dimension(s).\nIn contrast to Dataset.isel, indexers for this method should use labels instead of integers.\nThe spatial parameters available depend on the geometry of the Dataset:\n\nGrid1D: x\nGrid2D: x, y, coords, area\nGrid3D: [not yet implemented! use isel instead]\nGeometryFM: (x,y), coords, area\nGeometryFMLayered: (x,y,z), coords, area, layers\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntime\n(str, pandas.pandas.DatetimeIndex or mikeio.dataset._dataset.Dataset)\ntime labels e.g. “2018-01” or slice(“2018-1-1”,“2019-1-1”), by default None\nrequired\n\n\nx\nfloat\nx-coordinate of point to be selected, by default None\nrequired\n\n\ny\nfloat\ny-coordinate of point to be selected, by default None\nrequired\n\n\nz\nfloat\nz-coordinate of point to be selected, by default None\nrequired\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, y and z individually, the argument coords can be used instead. (x,y)- or (x,y,z)-coordinates of point to be selected, by default None\nrequired\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nrequired\n\n\nlayers\nint or str or list\nlayer(s) to be selected: “top”, “bottom” or layer number from bottom 0,1,2,… or from the top -1,-2,… or as list of these; only for layered dfsu, by default None\nrequired\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nnew Dataset with selected data\n\n\n\n\n\nSee Also\nisel : Select data using integer indexing\n\n\nExamples\n&gt;&gt;&gt; ds = mikeio.read(\"random.dfs1\")\n&gt;&gt;&gt; ds.sel(time=slice(None, \"2012-1-1 00:02\"))\n&gt;&gt;&gt; ds.sel(x=100)\n&gt;&gt;&gt; ds = mikeio.read(\"oresund_sigma_z.dfsu\")\n&gt;&gt;&gt; ds.sel(time=\"1997-09-15\")\n&gt;&gt;&gt; ds.sel(x=340000, y=6160000, z=-3)\n&gt;&gt;&gt; ds.sel(area=(340000, 6160000, 350000, 6170000))\n&gt;&gt;&gt; ds.sel(layers=\"bottom\")\n\n\n\nsqueeze\nDataset.squeeze()\nRemove axes of length 1\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\n\n\n\n\n\n\n\nstd\nDataset.std(axis=0, **kwargs)\nStandard deviation along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time”, “space” or “items”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\ndataset with standard deviation values\n\n\n\n\n\nSee Also\nnanstd : Standard deviation with NaN values removed\n\n\n\nto_dataframe\nDataset.to_dataframe(unit_in_name=False, round_time='ms')\nConvert Dataset to a Pandas DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nunit_in_name\nbool\ninclude unit in column name, default False,\nFalse\n\n\nround_time\nstr | bool\nround time to, by default “ms”, use False to avoid rounding\n'ms'\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame\n\n\n\n\n\n\n\nto_dfs\nDataset.to_dfs(filename, **kwargs)\nWrite dataset to a new dfs file\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path to the new dfs file\nrequired\n\n\ndtype\n\nDfs0 only: set the dfs data type of the written data to e.g. np.float64, by default: DfsSimpleType.Float (=np.float32)\nrequired\n\n\n\n\n\n\nto_numpy\nDataset.to_numpy()\nStack data to a single ndarray with shape (n_items, n_timesteps, …)\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.ndarray\n\n\n\n\n\n\n\nto_pandas\nDataset.to_pandas(**kwargs)\nConvert Dataset to a Pandas DataFrame\n\n\nto_xarray\nDataset.to_xarray()\nExport to xarray.Dataset"
  },
  {
    "objectID": "api/spatial.GeometryFM3D.html",
    "href": "api/spatial.GeometryFM3D.html",
    "title": "spatial.GeometryFM3D",
    "section": "",
    "text": "spatial.GeometryFM3D(self, *, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=DfsuFileType.Dfsu3DSigma, element_ids=None, node_ids=None, n_layers=1, n_sigma=None, validate=True, reindex=False)\n\n\n\n\n\nName\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFM3D.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFM3D.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/spatial.GeometryFM3D.html#attributes",
    "href": "api/spatial.GeometryFM3D.html#attributes",
    "title": "spatial.GeometryFM3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer"
  },
  {
    "objectID": "api/spatial.GeometryFM3D.html#methods",
    "href": "api/spatial.GeometryFM3D.html#methods",
    "title": "spatial.GeometryFM3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFM3D.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFM3D.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/spatial.GeometryFM2D.html",
    "href": "api/spatial.GeometryFM2D.html",
    "title": "spatial.GeometryFM2D",
    "section": "",
    "text": "spatial.GeometryFM2D(self, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=DfsuFileType.Dfsu2D, element_ids=None, node_ids=None, validate=True, reindex=False)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nisel\nexport a selection of elements to a new geometry\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFM2D.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFM2D.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFM2D.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFM2D.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFM2D.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFM2D.isel(idx, keepdims=False, **kwargs)\nexport a selection of elements to a new geometry\nTypically not called directly, but by Dataset/DataArray’s isel() or sel() methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidx\ncollection(int)\ncollection of element indicies\nrequired\n\n\nkeepdims\nbool\nShould the original Geometry type be kept (keepdims=True) or should it be reduced e.g. to a GeometryPoint2D if possible (keepdims=False), by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nGeometry\ngeometry subset\n\n\n\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFM2D.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFM2D.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/spatial.GeometryFM2D.html#attributes",
    "href": "api/spatial.GeometryFM2D.html#attributes",
    "title": "spatial.GeometryFM2D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D"
  },
  {
    "objectID": "api/spatial.GeometryFM2D.html#methods",
    "href": "api/spatial.GeometryFM2D.html#methods",
    "title": "spatial.GeometryFM2D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nisel\nexport a selection of elements to a new geometry\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFM2D.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFM2D.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFM2D.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFM2D.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFM2D.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFM2D.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFM2D.isel(idx, keepdims=False, **kwargs)\nexport a selection of elements to a new geometry\nTypically not called directly, but by Dataset/DataArray’s isel() or sel() methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidx\ncollection(int)\ncollection of element indicies\nrequired\n\n\nkeepdims\nbool\nShould the original Geometry type be kept (keepdims=True) or should it be reduced e.g. to a GeometryPoint2D if possible (keepdims=False), by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nGeometry\ngeometry subset\n\n\n\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFM2D.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFM2D.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/read_pfs.html",
    "href": "api/read_pfs.html",
    "title": "read_pfs",
    "section": "",
    "text": "read_pfs(filename, encoding='cp1252', unique_keywords=False)\nRead a pfs file to a Pfs object for further analysis/manipulation\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path | typing.TextIO | typing.Dict | mikeio.pfs._pfssection.PfsSection\nFile name including full path to the pfs file.\nrequired\n\n\nencoding\nstr\nHow is the pfs file encoded? By default ‘cp1252’\n'cp1252'\n\n\nunique_keywords\nbool\nShould the keywords in a section be unique? Some tools e.g. the MIKE Plot Composer allows non-unique keywords. If True: warnings will be issued if non-unique keywords are present and the first occurence will be used by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.pfs._pfsdocument.PfsDocument\nA PfsDocument object"
  },
  {
    "objectID": "api/read_pfs.html#parameters",
    "href": "api/read_pfs.html#parameters",
    "title": "read_pfs",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path | typing.TextIO | typing.Dict | mikeio.pfs._pfssection.PfsSection\nFile name including full path to the pfs file.\nrequired\n\n\nencoding\nstr\nHow is the pfs file encoded? By default ‘cp1252’\n'cp1252'\n\n\nunique_keywords\nbool\nShould the keywords in a section be unique? Some tools e.g. the MIKE Plot Composer allows non-unique keywords. If True: warnings will be issued if non-unique keywords are present and the first occurence will be used by default False\nFalse"
  },
  {
    "objectID": "api/read_pfs.html#returns",
    "href": "api/read_pfs.html#returns",
    "title": "read_pfs",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nmikeio.pfs._pfsdocument.PfsDocument\nA PfsDocument object"
  },
  {
    "objectID": "api/EUMUnit.html",
    "href": "api/EUMUnit.html",
    "title": "EUMUnit",
    "section": "",
    "text": "EUMUnit(self, code)\nEUM unit"
  },
  {
    "objectID": "api/EUMUnit.html#examples",
    "href": "api/EUMUnit.html#examples",
    "title": "EUMUnit",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.EUMUnit.degree_Kelvin\n\ndegree Kelvin"
  },
  {
    "objectID": "api/EUMUnit.html#attributes",
    "href": "api/EUMUnit.html#attributes",
    "title": "EUMUnit",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\ndisplay_name\nDisplay friendly name"
  },
  {
    "objectID": "api/spatial.GeometryFMLineSpectrum.html",
    "href": "api/spatial.GeometryFMLineSpectrum.html",
    "title": "spatial.GeometryFMLineSpectrum",
    "section": "",
    "text": "spatial.GeometryFMLineSpectrum(self, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=None, element_ids=None, node_ids=None, validate=True, frequencies=None, directions=None, reindex=False)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nfrequencies\nFrequency axis\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFMLineSpectrum.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFMLineSpectrum.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/spatial.GeometryFMLineSpectrum.html#attributes",
    "href": "api/spatial.GeometryFMLineSpectrum.html#attributes",
    "title": "spatial.GeometryFMLineSpectrum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nfrequencies\nFrequency axis\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D"
  },
  {
    "objectID": "api/spatial.GeometryFMLineSpectrum.html#methods",
    "href": "api/spatial.GeometryFMLineSpectrum.html#methods",
    "title": "spatial.GeometryFMLineSpectrum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFMLineSpectrum.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFMLineSpectrum.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFMLineSpectrum.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/spatial._FM_geometry._GeometryFMPlotter.html",
    "href": "api/spatial._FM_geometry._GeometryFMPlotter.html",
    "title": "spatial._FM_geometry._GeometryFMPlotter",
    "section": "",
    "text": "spatial._FM_geometry._GeometryFMPlotter(self, geometry)\nPlot GeometryFM\n\n\n&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\")\n&gt;&gt;&gt; g = ds.geometry\n&gt;&gt;&gt; g.plot()          # bathymetry (as patches)\n&gt;&gt;&gt; g.plot.contour()  # bathymetry contours\n&gt;&gt;&gt; g.plot.contourf() # filled bathymetry contours\n&gt;&gt;&gt; g.plot.mesh()     # mesh only\n&gt;&gt;&gt; g.plot.outline()  # domain outline only\n&gt;&gt;&gt; g.plot.boundary_nodes()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_nodes\nPlot mesh boundary nodes and their code values\n\n\ncontour\nPlot bathymetry as contour lines\n\n\ncontourf\nPlot bathymetry as filled contours\n\n\nmesh\nPlot mesh only\n\n\noutline\nPlot domain outline (using the boundary_polylines property)\n\n\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.boundary_nodes(boundary_names=None, figsize=None, ax=None)\nPlot mesh boundary nodes and their code values\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.contour(ax=None, figsize=None, **kwargs)\nPlot bathymetry as contour lines\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.contourf(ax=None, figsize=None, **kwargs)\nPlot bathymetry as filled contours\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.mesh(title='Mesh', figsize=None, ax=None)\nPlot mesh only\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.outline(title='Outline', figsize=None, ax=None)\nPlot domain outline (using the boundary_polylines property)"
  },
  {
    "objectID": "api/spatial._FM_geometry._GeometryFMPlotter.html#examples",
    "href": "api/spatial._FM_geometry._GeometryFMPlotter.html#examples",
    "title": "spatial._FM_geometry._GeometryFMPlotter",
    "section": "",
    "text": "&gt;&gt;&gt; ds = mikeio.read(\"HD2D.dfsu\")\n&gt;&gt;&gt; g = ds.geometry\n&gt;&gt;&gt; g.plot()          # bathymetry (as patches)\n&gt;&gt;&gt; g.plot.contour()  # bathymetry contours\n&gt;&gt;&gt; g.plot.contourf() # filled bathymetry contours\n&gt;&gt;&gt; g.plot.mesh()     # mesh only\n&gt;&gt;&gt; g.plot.outline()  # domain outline only\n&gt;&gt;&gt; g.plot.boundary_nodes()"
  },
  {
    "objectID": "api/spatial._FM_geometry._GeometryFMPlotter.html#methods",
    "href": "api/spatial._FM_geometry._GeometryFMPlotter.html#methods",
    "title": "spatial._FM_geometry._GeometryFMPlotter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_nodes\nPlot mesh boundary nodes and their code values\n\n\ncontour\nPlot bathymetry as contour lines\n\n\ncontourf\nPlot bathymetry as filled contours\n\n\nmesh\nPlot mesh only\n\n\noutline\nPlot domain outline (using the boundary_polylines property)\n\n\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.boundary_nodes(boundary_names=None, figsize=None, ax=None)\nPlot mesh boundary nodes and their code values\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.contour(ax=None, figsize=None, **kwargs)\nPlot bathymetry as contour lines\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.contourf(ax=None, figsize=None, **kwargs)\nPlot bathymetry as filled contours\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.mesh(title='Mesh', figsize=None, ax=None)\nPlot mesh only\n\n\n\nspatial._FM_geometry._GeometryFMPlotter.outline(title='Outline', figsize=None, ax=None)\nPlot domain outline (using the boundary_polylines property)"
  },
  {
    "objectID": "api/Dfs3.html",
    "href": "api/Dfs3.html",
    "title": "Dfs3",
    "section": "",
    "text": "Dfs3(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\ndy\nStep size in y direction\n\n\ndz\nStep size in y direction\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nread\nRead data from a dfs3 file\n\n\n\n\n\nDfs3.read(items=None, time=None, area=None, layers=None, keepdims=False, dtype=np.float32)\nRead data from a dfs3 file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step or a single layer only, should the singleton dimension be kept in the returned Dataset? by default: False\nFalse\n\n\nlayers\nstr | int | collections.abc.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\ndtype\ntyping.Any\nDefine the dtype of the returned dataset (default = np.float32)\nnp.float32\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/Dfs3.html#attributes",
    "href": "api/Dfs3.html#attributes",
    "title": "Dfs3",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\ndy\nStep size in y direction\n\n\ndz\nStep size in y direction\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds"
  },
  {
    "objectID": "api/Dfs3.html#methods",
    "href": "api/Dfs3.html#methods",
    "title": "Dfs3",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nread\nRead data from a dfs3 file\n\n\n\n\n\nDfs3.read(items=None, time=None, area=None, layers=None, keepdims=False, dtype=np.float32)\nRead data from a dfs3 file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step or a single layer only, should the singleton dimension be kept in the returned Dataset? by default: False\nFalse\n\n\nlayers\nstr | int | collections.abc.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\ndtype\ntyping.Any\nDefine the dtype of the returned dataset (default = np.float32)\nnp.float32\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/dfsu.Dfsu2DV.html",
    "href": "api/dfsu.Dfsu2DV.html",
    "title": "dfsu.Dfsu2DV",
    "section": "",
    "text": "dfsu.Dfsu2DV(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_layers\nMaximum number of layers\n\n\nn_nodes\nNumber of nodes\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_timesteps\nNumber of time steps\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nplot_vertical_profile\nPlot unstructured vertical profile\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu2DV.plot_vertical_profile(values, time_step=None, cmin=None, cmax=None, label='', **kwargs)\nPlot unstructured vertical profile\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalues\n\nvalue for each element to plot\nrequired\n\n\ncmin\n\nlower bound of values to be shown on plot, default:None\nNone\n\n\ncmax\n\nupper bound of values to be shown on plot, default:None\nNone\n\n\ntitle\n\naxes title\nrequired\n\n\nlabel\n\ncolorbar label\n''\n\n\ncmap\n\ncolormap, default viridis\nrequired\n\n\nfigsize\n\nspecify size of figure\nrequired\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndfsu.Dfsu2DV.read(items=None, time=None, elements=None, area=None, x=None, y=None, z=None, layers=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nz\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nlayers\nint | str | typing.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu2DV.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/dfsu.Dfsu2DV.html#attributes",
    "href": "api/dfsu.Dfsu2DV.html#attributes",
    "title": "dfsu.Dfsu2DV",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_layers\nMaximum number of layers\n\n\nn_nodes\nNumber of nodes\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_timesteps\nNumber of time steps\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes"
  },
  {
    "objectID": "api/dfsu.Dfsu2DV.html#methods",
    "href": "api/dfsu.Dfsu2DV.html#methods",
    "title": "dfsu.Dfsu2DV",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nplot_vertical_profile\nPlot unstructured vertical profile\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu2DV.plot_vertical_profile(values, time_step=None, cmin=None, cmax=None, label='', **kwargs)\nPlot unstructured vertical profile\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalues\n\nvalue for each element to plot\nrequired\n\n\ncmin\n\nlower bound of values to be shown on plot, default:None\nNone\n\n\ncmax\n\nupper bound of values to be shown on plot, default:None\nNone\n\n\ntitle\n\naxes title\nrequired\n\n\nlabel\n\ncolorbar label\n''\n\n\ncmap\n\ncolormap, default viridis\nrequired\n\n\nfigsize\n\nspecify size of figure\nrequired\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndfsu.Dfsu2DV.read(items=None, time=None, elements=None, area=None, x=None, y=None, z=None, layers=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nz\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nlayers\nint | str | typing.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu2DV.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/DataArray.html",
    "href": "api/DataArray.html",
    "title": "DataArray",
    "section": "",
    "text": "DataArray(self, data, *, time=None, item=None, geometry=None, zn=None, dims=None)\nDataArray with data and metadata for a single item in a dfs file\nThe DataArray has these main properties:"
  },
  {
    "objectID": "api/DataArray.html#examples",
    "href": "api/DataArray.html#examples",
    "title": "DataArray",
    "section": "Examples",
    "text": "Examples\n\nimport pandas as pd\nimport mikeio\n\nda = mikeio.DataArray([0.0, 1.0],\n    time=pd.date_range(\"2020-01-01\", periods=2),\n    item=mikeio.ItemInfo(\"Water level\", mikeio.EUMType.Water_Level))\nda\n\n&lt;mikeio.DataArray&gt;\nname: Water level\ndims: (time:2)\ntime: 2020-01-01 00:00:00 - 2020-01-02 00:00:00 (2 records)\ngeometry: GeometryUndefined()\nvalues: [0, 1]"
  },
  {
    "objectID": "api/DataArray.html#attributes",
    "href": "api/DataArray.html#attributes",
    "title": "DataArray",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\ndtype\nData-type of the array elements\n\n\nend_time\nLast time instance (as datetime)\n\n\nis_equidistant\nIs DataArray equidistant in time?\n\n\nn_timesteps\nNumber of time steps\n\n\nname\nName of this DataArray (=da.item.name)\n\n\nndim\nNumber of array dimensions\n\n\nshape\nTuple of array dimensions\n\n\nstart_time\nFirst time instance (as datetime)\n\n\ntimestep\nTime step in seconds if equidistant (and at\n\n\ntype\nEUMType\n\n\nunit\nEUMUnit\n\n\nvalues\nValues as a np.ndarray (equivalent to to_numpy())"
  },
  {
    "objectID": "api/DataArray.html#methods",
    "href": "api/DataArray.html#methods",
    "title": "DataArray",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\naggregate\nAggregate along an axis\n\n\naverage\nCompute the weighted average along the specified axis.\n\n\nconcat\nConcatenate DataArrays along the time axis\n\n\ncopy\nMake copy of DataArray\n\n\ndescribe\nGenerate descriptive statistics by wrapping pandas.DataFrame.describe\n\n\ndropna\nRemove time steps where values are NaN\n\n\nextract_track\nExtract data along a moving track\n\n\nflipud\nFlip upside down (on first non-time axis)\n\n\ninterp\nInterpolate data in time and space\n\n\ninterp_like\nInterpolate in space (and in time) to other geometry (and time axis)\n\n\ninterp_na\nFill in NaNs by interpolating according to different methods.\n\n\ninterp_time\nTemporal interpolation\n\n\nisel\nReturn a new DataArray whose data is given by\n\n\nmax\nMax value along an axis\n\n\nmean\nMean value along an axis\n\n\nmin\nMin value along an axis\n\n\nnanmax\nMax value along an axis (NaN removed)\n\n\nnanmean\nMean value along an axis (NaN removed)\n\n\nnanmin\nMin value along an axis (NaN removed)\n\n\nnanquantile\nCompute the q-th quantile of the data along the specified axis, while ignoring nan values.\n\n\nnanstd\nStandard deviation value along an axis (NaN removed)\n\n\nptp\nRange (max - min) a.k.a Peak to Peak along an axis\n\n\nquantile\nCompute the q-th quantile of the data along the specified axis.\n\n\nsel\nReturn a new DataArray whose data is given by\n\n\nsqueeze\nRemove axes of length 1\n\n\nstd\nStandard deviation values along an axis\n\n\nto_dataframe\nConvert to DataFrame\n\n\nto_dfs\nWrite data to a new dfs file\n\n\nto_numpy\nValues as a np.ndarray (equivalent to values)\n\n\nto_pandas\nConvert to Pandas Series\n\n\nto_xarray\nExport to xarray.DataArray\n\n\n\n\naggregate\nDataArray.aggregate(axis=0, func=np.nanmean, **kwargs)\nAggregate along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\nfunc\ntyping.Callable[…, typing.Any]\ndefault np.nanmean\nnp.nanmean\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\ndataarray with aggregated values\n\n\n\n\n\nSee Also\nmax : Max values\nnanmax : Max values with NaN values removed\n\n\n\naverage\nDataArray.average(weights, axis=0, **kwargs)\nCompute the weighted average along the specified axis.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nDataArray with weighted average values\n\n\n\n\n\nSee Also\naggregate : Weighted average\n\n\nExamples\n&gt;&gt;&gt; dfs = Dfsu(\"HD2D.dfsu\")\n&gt;&gt;&gt; da = dfs.read([\"Current speed\"])[0]\n&gt;&gt;&gt; area = dfs.get_element_area()\n&gt;&gt;&gt; da2 = da.average(axis=\"space\", weights=area)\n\n\n\nconcat\nDataArray.concat(dataarrays, keep='last')\nConcatenate DataArrays along the time axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndataarrays\ncollections.abc.Sequence[‘DataArray’]\n\nrequired\n\n\nkeep\ntyping.Literal[‘last’]\nTODO Yet to be implemented, default: last\n'last'\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nThe concatenated DataArray\n\n\n\n\n\nExamples\n\nda1 = mikeio.read(\"../data/HD2D.dfsu\", time=[0,1])[0]\nda2 = mikeio.read(\"../data/HD2D.dfsu\", time=[2,3])[0]\nda1.time\n\nDatetimeIndex(['1985-08-06 07:00:00', '1985-08-06 09:30:00'], dtype='datetime64[ns]', freq=None)\n\n\n\nda3 = mikeio.DataArray.concat([da1,da2])\nda3\n\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:4, element:884)\ntime: 1985-08-06 07:00:00 - 1985-08-06 14:30:00 (4 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\n\n\n\n\n\ncopy\nDataArray.copy()\nMake copy of DataArray\n\n\ndescribe\nDataArray.describe(percentiles=None, include=None, exclude=None)\nGenerate descriptive statistics by wrapping pandas.DataFrame.describe\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nReturns\n\n\nrequired\n\n\npd\n\n\nrequired\n\n\n\n\n\n\ndropna\nDataArray.dropna()\nRemove time steps where values are NaN\n\n\nextract_track\nDataArray.extract_track(track, method='nearest', dtype=np.float32)\nExtract data along a moving track\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack\npandas.pandas.DataFrame\nwith DatetimeIndex and (x, y) of track points as first two columns x,y coordinates must be in same coordinate system as dfsu\nrequired\n\n\ntrack\npandas.pandas.DataFrame\nfilename of csv or dfs0 file containing t,x,y\nrequired\n\n\nmethod\ntyping.Literal[‘nearest’, ‘inverse_distance’]\nSpatial interpolation method (‘nearest’ or ‘inverse_distance’) default=‘nearest’\n'nearest'\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataset.Dataset\nA dataset with data dimension t The first two items will be x- and y- coordinates of track\n\n\n\n\n\n\nflipud\nDataArray.flipud()\nFlip upside down (on first non-time axis)\n\n\ninterp\nDataArray.interp(time=None, x=None, y=None, z=None, n_nearest=3, interpolant=None, **kwargs)\nInterpolate data in time and space\nThis method currently has limited functionality for spatial interpolation. It will be extended in the future.\nThe spatial parameters available depend on the geometry of the Dataset:\n\nGrid1D: x\nGrid2D: x, y\nGrid3D: [not yet implemented!]\nGeometryFM: (x,y)\nGeometryFMLayered: (x,y) [surface point will be returned!]\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntime\n(float, pandas.pandas.DatetimeIndex or mikeio.dataset._dataarray.DataArray)\ntimestep in seconds or discrete time instances given by pd.DatetimeIndex (typically from another DataArray da2.time), by default None (=don’t interp in time)\nNone\n\n\nx\nfloat\nx-coordinate of point to be interpolated to, by default None\nNone\n\n\ny\nfloat\ny-coordinate of point to be interpolated to, by default None\nNone\n\n\nn_nearest\nint\nWhen using IDW interpolation, how many nearest points should be used, by default: 3\n3\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nnew DataArray with interped data\n\n\n\n\n\nSee Also\nsel : Select data using label indexing interp_like : Interp to another time/space of another DataArray interp_time : Interp in the time direction only\n\n\nExamples\n&gt;&gt;&gt; da = mikeio.read(\"random.dfs1\")[0]\n&gt;&gt;&gt; da.interp(time=3600)\n&gt;&gt;&gt; da.interp(x=110)\n&gt;&gt;&gt; da = mikeio.read(\"HD2D.dfsu\").Salinity\n&gt;&gt;&gt; da.interp(x=340000, y=6160000)\n\n\n\ninterp_like\nDataArray.interp_like(other, interpolant=None, **kwargs)\nInterpolate in space (and in time) to other geometry (and time axis)\nNote: currently only supports interpolation from dfsu-2d to dfs2 or other dfsu-2d DataArrays\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nother\n‘DataArray’ | mikeio.spatial.Grid2D | mikeio.spatial.GeometryFM2D | pandas.pandas.DatetimeIndex\n\nrequired\n\n\ninterpolant\ntyping.Tuple[typing.Any, typing.Any] | None\nReuse pre-calculated index and weights\nNone\n\n\noptional\ntyping.Tuple[typing.Any, typing.Any] | None\nReuse pre-calculated index and weights\nNone\n\n\nkwargs\ntyping.Any\n\n{}\n\n\n\n\n\nExamples\n&gt;&gt;&gt; dai = da.interp_like(da2)\n&gt;&gt;&gt; dae = da.interp_like(da2, extrapolate=True)\n&gt;&gt;&gt; dat = da.interp_like(da2.time)\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nInterpolated DataArray\n\n\n\n\n\n\ninterp_na\nDataArray.interp_na(axis='time', **kwargs)\nFill in NaNs by interpolating according to different methods.\nWrapper of xarray.DataArray.interpolate_na\n\nExamples\n\nimport numpy as np\nimport pandas as pd\ntime = pd.date_range(\"2000\", periods=3, freq=\"D\")\nda = mikeio.DataArray(data=np.array([0.0, np.nan, 2.0]), time=time)\nda\n\n&lt;mikeio.DataArray&gt;\nname: NoName\ndims: (time:3)\ntime: 2000-01-01 00:00:00 - 2000-01-03 00:00:00 (3 records)\ngeometry: GeometryUndefined()\nvalues: [0, nan, 2]\n\n\n\nda.interp_na()\n\n&lt;mikeio.DataArray&gt;\nname: NoName\ndims: (time:3)\ntime: 2000-01-01 00:00:00 - 2000-01-03 00:00:00 (3 records)\ngeometry: GeometryUndefined()\nvalues: [0, 1, 2]\n\n\n\n\n\ninterp_time\nDataArray.interp_time(dt, *, method='linear', extrapolate=True, fill_value=np.nan)\nTemporal interpolation\nWrapper of scipy.interpolate.interp1d\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndt\nfloat | pandas.pandas.DatetimeIndex | ‘DataArray’\noutput timestep in seconds or new time axis\nrequired\n\n\nmethod\nstr\nSpecifies the kind of interpolation as a string (‘linear’, ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘previous’, ‘next’, where ‘zero’, ‘slinear’, ‘quadratic’ and ‘cubic’ refer to a spline interpolation of zeroth, first, second or third order; ‘previous’ and ‘next’ simply return the previous or next value of the point) or as an integer specifying the order of the spline interpolator to use. Default is ‘linear’.\n'linear'\n\n\nextrapolate\nbool\nDefault True. If False, a ValueError is raised any time interpolation is attempted on a value outside of the range of x (where extrapolation is necessary). If True, out of bounds values are assigned fill_value\nTrue\n\n\nfill_value\nfloat\nDefault NaN. this value will be used to fill in for points outside of the time range.\nnp.nan\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\n\n\n\n\n\n\n\nisel\nDataArray.isel(idx=None, axis=0, **kwargs)\nReturn a new DataArray whose data is given by integer indexing along the specified dimension(s).\nNote that the data will be a view of the original data if possible (single index or slice), otherwise a copy (fancy indexing) following NumPy convention.\nThe spatial parameters available depend on the dims (i.e. geometry) of the DataArray:\n\nGrid1D: x\nGrid2D: x, y\nGrid3D: x, y, z\nGeometryFM: element\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidx\nint | collections.abc.Sequence[int] | slice | None\n\nNone\n\n\naxis\nint | str\naxis number or “time”, by default 0\n0\n\n\ntime\nint\ntime index,by default None\nrequired\n\n\nx\nint\nx index, by default None\nrequired\n\n\ny\nint\ny index, by default None\nrequired\n\n\nz\nint\nz index, by default None\nrequired\n\n\nelement\nint\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nrequired\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nnew DataArray with selected data\n\n\n\n\n\nSee Also\ndims : Get axis names sel : Select data using labels\n\n\nExamples\n\nda = mikeio.read(\"../data/europe_wind_long_lat.dfs2\")[0]\nda\n\n&lt;mikeio.DataArray&gt;\nname: Mean Sea Level Pressure\ndims: (time:1, y:101, x:221)\ntime: 2012-01-01 00:00:00 (time-invariant)\ngeometry: Grid2D (ny=101, nx=221)\n\n\n\nda.isel(time=-1)\n\n&lt;mikeio.DataArray&gt;\nname: Mean Sea Level Pressure\ndims: (y:101, x:221)\ntime: 2012-01-01 00:00:00 (time-invariant)\ngeometry: Grid2D (ny=101, nx=221)\n\n\n\nda.isel(x=slice(10,20), y=slice(40,60))\n\n&lt;mikeio.DataArray&gt;\nname: Mean Sea Level Pressure\ndims: (time:1, y:20, x:10)\ntime: 2012-01-01 00:00:00 (time-invariant)\ngeometry: Grid2D (ny=20, nx=10)\n\n\n\nda = mikeio.read(\"../data/oresund_sigma_z.dfsu\").Temperature\nda.isel(element=range(200))\n\n&lt;mikeio.DataArray&gt;\nname: Temperature\ndims: (time:3, element:200)\ntime: 1997-09-15 21:00:00 - 1997-09-16 03:00:00 (3 records)\ngeometry: Flexible Mesh Geometry: Dfsu3DSigmaZ\nnumber of nodes: 638\nnumber of elements: 200\nnumber of layers: 6\nnumber of sigma layers: 4\nprojection: UTM-33\n\n\n\n\n\nmax\nDataArray.max(axis=0, **kwargs)\nMax value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with max values\n\n\n\n\n\nSee Also\nnanmax : Max values with NaN values removed\n\n\n\nmean\nDataArray.mean(axis=0, **kwargs)\nMean value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with mean values\n\n\n\n\n\nSee Also\nnanmean : Mean values with NaN values removed\n\n\n\nmin\nDataArray.min(axis=0, **kwargs)\nMin value along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with min values\n\n\n\n\n\nSee Also\nnanmin : Min values with NaN values removed\n\n\n\nnanmax\nDataArray.nanmax(axis=0, **kwargs)\nMax value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with max values\n\n\n\n\n\nSee Also\nnanmax : Max values with NaN values removed\n\n\n\nnanmean\nDataArray.nanmean(axis=0, **kwargs)\nMean value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with mean values\n\n\n\n\n\nSee Also\nmean : Mean values\n\n\n\nnanmin\nDataArray.nanmin(axis=0, **kwargs)\nMin value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with min values\n\n\n\n\n\nSee Also\nnanmin : Min values with NaN values removed\n\n\n\nnanquantile\nDataArray.nanquantile(q, *, axis=0, **kwargs)\nCompute the q-th quantile of the data along the specified axis, while ignoring nan values.\nWrapping np.nanquantile\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nq\nfloat | collections.abc.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\ndata with quantile values\n\n\n\n\n\nExamples\n&gt;&gt;&gt; da.nanquantile(q=[0.25,0.75])\n&gt;&gt;&gt; da.nanquantile(q=0.5)\n&gt;&gt;&gt; da.nanquantile(q=[0.01,0.5,0.99], axis=\"space\")\n\n\nSee Also\nquantile : Quantile with NaN values\n\n\n\nnanstd\nDataArray.nanstd(axis=0, **kwargs)\nStandard deviation value along an axis (NaN removed)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with standard deviation values\n\n\n\n\n\nSee Also\nstd : Standard deviation\n\n\n\nptp\nDataArray.ptp(axis=0, **kwargs)\nRange (max - min) a.k.a Peak to Peak along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with peak to peak values\n\n\n\n\n\n\nquantile\nDataArray.quantile(q, *, axis=0, **kwargs)\nCompute the q-th quantile of the data along the specified axis.\nWrapping np.quantile\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nq\nfloat | collections.abc.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\ndata with quantile values\n\n\n\n\n\nExamples\n&gt;&gt;&gt; da.quantile(q=[0.25,0.75])\n&gt;&gt;&gt; da.quantile(q=0.5)\n&gt;&gt;&gt; da.quantile(q=[0.01,0.5,0.99], axis=\"space\")\n\n\nSee Also\nnanquantile : quantile with NaN values ignored\n\n\n\nsel\nDataArray.sel(time=None, **kwargs)\nReturn a new DataArray whose data is given by selecting index labels along the specified dimension(s).\nIn contrast to DataArray.isel, indexers for this method should use labels instead of integers.\nThe spatial parameters available depend on the geometry of the DataArray:\n\nGrid1D: x\nGrid2D: x, y, coords, area\nGrid3D: [not yet implemented! use isel instead]\nGeometryFM: (x,y), coords, area\nGeometryFMLayered: (x,y,z), coords, area, layers\n\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntime\n(str, pandas.pandas.DatetimeIndex, mikeio.dataset._dataarray.DataArray)\ntime labels e.g. “2018-01” or slice(“2018-1-1”,“2019-1-1”), by default None\nNone\n\n\nx\nfloat\nx-coordinate of point to be selected, by default None\nrequired\n\n\ny\nfloat\ny-coordinate of point to be selected, by default None\nrequired\n\n\nz\nfloat\nz-coordinate of point to be selected, by default None\nrequired\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, y and z individually, the argument coords can be used instead. (x,y)- or (x,y,z)-coordinates of point to be selected, by default None\nrequired\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nrequired\n\n\nlayers\nint or str or list\nlayer(s) to be selected: “top”, “bottom” or layer number from bottom 0,1,2,… or from the top -1,-2,… or as list of these; only for layered dfsu, by default None\nrequired\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\nnew DataArray with selected data\n\n\n\n\n\nSee Also\nisel : Select data using integer indexing interp : Interp data in time and space\n\n\nExamples\n\nda = mikeio.read(\"../data/random.dfs1\")[0]\nda\n\n&lt;mikeio.DataArray&gt;\nname: testing water level\ndims: (time:100, x:3)\ntime: 2012-01-01 00:00:00 - 2012-01-01 00:19:48 (100 records)\ngeometry: Grid1D (n=3, dx=100)\n\n\n\nda.sel(time=slice(None, \"2012-1-1 00:02\"))\n\n&lt;mikeio.DataArray&gt;\nname: testing water level\ndims: (time:15, x:3)\ntime: 2012-01-01 00:00:00 - 2012-01-01 00:02:48 (15 records)\ngeometry: Grid1D (n=3, dx=100)\n\n\n\nda.sel(x=100)\n\n&lt;mikeio.DataArray&gt;\nname: testing water level\ndims: (time:100)\ntime: 2012-01-01 00:00:00 - 2012-01-01 00:19:48 (100 records)\ngeometry: GeometryUndefined()\nvalues: [0.3231, 0.6315, ..., 0.7506]\n\n\n\nda = mikeio.read(\"../data/oresund_sigma_z.dfsu\").Temperature\nda\n\n&lt;mikeio.DataArray&gt;\nname: Temperature\ndims: (time:3, element:17118)\ntime: 1997-09-15 21:00:00 - 1997-09-16 03:00:00 (3 records)\ngeometry: Flexible Mesh Geometry: Dfsu3DSigmaZ\nnumber of nodes: 12042\nnumber of elements: 17118\nnumber of layers: 9\nnumber of sigma layers: 4\nprojection: UTM-33\n\n\n\nda.sel(time=\"1997-09-15\")\n\n&lt;mikeio.DataArray&gt;\nname: Temperature\ndims: (element:17118)\ntime: 1997-09-15 21:00:00 (time-invariant)\ngeometry: Flexible Mesh Geometry: Dfsu3DSigmaZ\nnumber of nodes: 12042\nnumber of elements: 17118\nnumber of layers: 9\nnumber of sigma layers: 4\nprojection: UTM-33\nvalues: [16.31, 16.43, ..., 16.69]\n\n\n\nda.sel(x=340000, y=6160000, z=-3)\n\n&lt;mikeio.DataArray&gt;\nname: Temperature\ndims: (time:3)\ntime: 1997-09-15 21:00:00 - 1997-09-16 03:00:00 (3 records)\ngeometry: GeometryPoint3D(x=340028.1116933554, y=6159980.070243686, z=-3.0)\nvalues: [17.54, 17.31, 17.08]\n\n\n\nda.sel(layers=\"bottom\")\n\n&lt;mikeio.DataArray&gt;\nname: Temperature\ndims: (time:3, element:3700)\ntime: 1997-09-15 21:00:00 - 1997-09-16 03:00:00 (3 records)\ngeometry: Dfsu2D (3700 elements, 2090 nodes)\n\n\n\n\n\nsqueeze\nDataArray.squeeze()\nRemove axes of length 1\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\n\n\n\n\n\n\n\nstd\nDataArray.std(axis=0, **kwargs)\nStandard deviation values along an axis\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naxis\nint | str\naxis number or “time” or “space”, by default 0\n0\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset._dataarray.DataArray\narray with standard deviation values\n\n\n\n\n\nSee Also\nnanstd : Standard deviation values with NaN values removed\n\n\n\nto_dataframe\nDataArray.to_dataframe(unit_in_name=False, round_time='ms')\nConvert to DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nunit_in_name\nbool\ninclude unit in column name, default False,\nFalse\n\n\nround_time\nstr | bool\nround time to, by default “ms”, use False to avoid rounding\n'ms'\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame\n\n\n\n\n\n\n\nto_dfs\nDataArray.to_dfs(filename, **kwargs)\nWrite data to a new dfs file\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path to the new dfs file\nrequired\n\n\ndtype\n\nDfs0 only: set the dfs data type of the written data to e.g. np.float64, by default: DfsSimpleType.Float (=np.float32)\nrequired\n\n\n\n\n\n\nto_numpy\nDataArray.to_numpy()\nValues as a np.ndarray (equivalent to values)\n\n\nto_pandas\nDataArray.to_pandas()\nConvert to Pandas Series\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.Series\n\n\n\n\n\n\n\nto_xarray\nDataArray.to_xarray()\nExport to xarray.DataArray"
  },
  {
    "objectID": "api/Grid3D.html",
    "href": "api/Grid3D.html",
    "title": "Grid3D",
    "section": "",
    "text": "Grid3D(self, *, x=None, x0=0.0, dx=None, nx=None, y=None, y0=0.0, dy=None, ny=None, z=None, z0=0.0, dz=None, nz=None, projection='NON-UTM', origin=(0.0, 0.0), orientation=0.0)\n3D grid Origin in the center of cell in lower-left corner x, y and z axes are increasing and equidistant\n\n\n\n\n\nName\nDescription\n\n\n\n\ndx\nx-axis grid spacing\n\n\ndy\ny-axis grid spacing\n\n\ndz\nz-axis grid spacing\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nnx\nnumber of x grid points\n\n\nny\nnumber of y grid points\n\n\nnz\nnumber of z grid points\n\n\norientation\nGrid orientation\n\n\norigin\nCoordinates of grid origo (in projection)\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\nx\narray of x-axis coordinates (element center)\n\n\ny\narray of y-axis coordinates (element center)\n\n\nz\narray of z-axis node coordinates\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nisel\nGet a subset geometry from this geometry\n\n\n\n\n\nGrid3D.isel(idx, axis)\nGet a subset geometry from this geometry"
  },
  {
    "objectID": "api/Grid3D.html#attributes",
    "href": "api/Grid3D.html#attributes",
    "title": "Grid3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndx\nx-axis grid spacing\n\n\ndy\ny-axis grid spacing\n\n\ndz\nz-axis grid spacing\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nnx\nnumber of x grid points\n\n\nny\nnumber of y grid points\n\n\nnz\nnumber of z grid points\n\n\norientation\nGrid orientation\n\n\norigin\nCoordinates of grid origo (in projection)\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\nx\narray of x-axis coordinates (element center)\n\n\ny\narray of y-axis coordinates (element center)\n\n\nz\narray of z-axis node coordinates"
  },
  {
    "objectID": "api/Grid3D.html#methods",
    "href": "api/Grid3D.html#methods",
    "title": "Grid3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nisel\nGet a subset geometry from this geometry\n\n\n\n\n\nGrid3D.isel(idx, axis)\nGet a subset geometry from this geometry"
  },
  {
    "objectID": "api/spatial.GeometryFMPointSpectrum.html",
    "href": "api/spatial.GeometryFMPointSpectrum.html",
    "title": "spatial.GeometryFMPointSpectrum",
    "section": "",
    "text": "spatial.GeometryFMPointSpectrum(self, frequencies=None, directions=None, x=None, y=None)\n\n\n\n\n\nName\nDescription\n\n\n\n\ndirections\nDirectional axis\n\n\nfrequencies\nFrequency axis\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nn_directions\nNumber of directions\n\n\nn_frequencies\nNumber of frequencies\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string"
  },
  {
    "objectID": "api/spatial.GeometryFMPointSpectrum.html#attributes",
    "href": "api/spatial.GeometryFMPointSpectrum.html#attributes",
    "title": "spatial.GeometryFMPointSpectrum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndirections\nDirectional axis\n\n\nfrequencies\nFrequency axis\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nn_directions\nNumber of directions\n\n\nn_frequencies\nNumber of frequencies\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string"
  },
  {
    "objectID": "api/spatial.GeometryFMAreaSpectrum.html",
    "href": "api/spatial.GeometryFMAreaSpectrum.html",
    "title": "spatial.GeometryFMAreaSpectrum",
    "section": "",
    "text": "spatial.GeometryFMAreaSpectrum(self, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=None, element_ids=None, node_ids=None, validate=True, frequencies=None, directions=None, reindex=False)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nfrequencies\nFrequency axis\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nelements_to_geometry\nexport a selection of elements to new flexible file geometry\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.elements_to_geometry(elements, keepdims=False)\nexport a selection of elements to new flexible file geometry\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nelements\nlist(int)\nlist of element ids\nrequired\n\n\nkeepdims\nbool\nNot used\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.spatial._FM_geometry_spectral.GeometryFMAreaSpectrum or mikeio.spatial._FM_geometry_spectral.GeometryFMPointSpectrum\nwhich can be used for further extraction or saved to file\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFMAreaSpectrum.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFMAreaSpectrum.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/spatial.GeometryFMAreaSpectrum.html#attributes",
    "href": "api/spatial.GeometryFMAreaSpectrum.html#attributes",
    "title": "spatial.GeometryFMAreaSpectrum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nfrequencies\nFrequency axis\n\n\ngeometry2d\nReturn self\n\n\nis_2d\nType is either mesh or Dfsu2D (2 horizontal dimensions)\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_nodes\nNumber of nodes\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D"
  },
  {
    "objectID": "api/spatial.GeometryFMAreaSpectrum.html#methods",
    "href": "api/spatial.GeometryFMAreaSpectrum.html#methods",
    "title": "spatial.GeometryFMAreaSpectrum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncontains\ntest if a list of points are contained by mesh\n\n\nelements_to_geometry\nexport a selection of elements to new flexible file geometry\n\n\nfind_index\nFind a set of element indicies for a number of points or within an area.\n\n\nfind_nearest_elements\nFind index of nearest elements (optionally for a list)\n\n\nget_2d_interpolant\nIDW interpolant for list of coordinates\n\n\nget_element_area\nCalculate the horizontal area of each element.\n\n\nget_node_centered_data\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\ninterp2d\ninterp spatially in data (2d only)\n\n\nto_mesh\nExport geometry to new mesh file\n\n\nto_shapely\nExport mesh as shapely MultiPolygon\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.contains(points)\ntest if a list of points are contained by mesh\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npoints\narray-like n-by-2\nx,y-coordinates of n points to be tested\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.elements_to_geometry(elements, keepdims=False)\nexport a selection of elements to new flexible file geometry\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nelements\nlist(int)\nlist of element ids\nrequired\n\n\nkeepdims\nbool\nNot used\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.spatial._FM_geometry_spectral.GeometryFMAreaSpectrum or mikeio.spatial._FM_geometry_spectral.GeometryFMPointSpectrum\nwhich can be used for further extraction or saved to file\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.find_index(x=None, y=None, coords=None, area=None)\nFind a set of element indicies for a number of points or within an area.\nThe returned indices returned are the unique, unordered set of element indices that contain the points or area.\nThis method will return elements containing the argument points/area, which is not necessarily the same as the nearest.\nTypically not called directly, but by Dataset/DataArray’s sel() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray | None\nX coordinate(s) (easting or longitude)\nNone\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\ncoords\nnumpy.numpy.array(float, float)\nAs an alternative to specifying x, and y individually, the argument coords can be used instead. (x,y)-coordinates of points to be found, by default None\nNone\n\n\narea\n(float, float, float, float)\nBounding box of coordinates (left lower and right upper) to be selected, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nindicies of containing elements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nif any point is outside the domain\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = dfs.find_index(x=3.1, y=4.3)\n\n\n\nisel : get subset geometry for specific indicies find_nearest_elements : find nearest instead of containing elements\n\n\n\n\nspatial.GeometryFMAreaSpectrum.find_nearest_elements(x, y=None, n_nearest=1, return_distances=False)\nFind index of nearest elements (optionally for a list)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat | numpy.numpy.ndarray\nX coordinate(s) (easting or longitude)\nrequired\n\n\ny\nfloat | numpy.numpy.ndarray | None\nY coordinate(s) (northing or latitude)\nNone\n\n\nn_nearest\nint\nreturn this many (horizontally) nearest points for each coordinate set, default=1\n1\n\n\nreturn_distances\nbool\nshould the horizontal distances to each point be returned? default=False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array\nelement ids of nearest element(s)\n\n\n(numpy.numpy.array, optional)\nhorizontal distances\n\n\n\n\n\n\n&gt;&gt;&gt; g = dfs.geometry\n&gt;&gt;&gt; id = g.find_nearest_elements(3, 4)\n&gt;&gt;&gt; ids = g.find_nearest_elements([3, 8], [4, 6])\n&gt;&gt;&gt; ids = g.find_nearest_elements(xy)\n&gt;&gt;&gt; ids = g.find_nearest_elements(3, 4, n_nearest=4)\n&gt;&gt;&gt; ids, d = g.find_nearest_elements(xy, return_distances=True)\n\n\n\nfind_index : find element indicies for points or an area\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_2d_interpolant(xy, n_nearest=5, extrapolate=False, p=2, radius=None)\nIDW interpolant for list of coordinates\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nxy\narray - like\nx,y coordinates of new points\nrequired\n\n\nn_nearest\nint\nnumber of nearest elements used for IDW, by default 5\n5\n\n\nextrapolate\nbool\nallow extrapolation, by default False\nFalse\n\n\np\nfloat\npower of inverse distance weighting, default=2\n2\n\n\nradius\nfloat | None\nan alternative to extrapolate=False, only include elements within radius\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(numpy.numpy.array, numpy.numpy.array)\nelement ids and weights\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_element_area()\nCalculate the horizontal area of each element.\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nareas in m2\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_node_centered_data(data, extrapolate=True)\nconvert cell-centered data to node-centered by pseudo-laplacian method\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nnumpy.numpy.array(float)\ncell-centered data\nrequired\n\n\nextrapolate\nbool\nallow the method to extrapolate, default:True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(float)\nnode-centered data\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat or (float, float)\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None, (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None, (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.interp2d(data, elem_ids, weights=None, shape=None)\ninterp spatially in data (2d only)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nndarray or list(ndarray)\ndfsu data\nrequired\n\n\nelem_ids\nndarray(int)\nn sized array of 1 or more element ids used for interpolation\nrequired\n\n\nweights\nndarray(float)\nweights with same size as elem_ids used for interpolation\nNone\n\n\nshape\ntyping.Tuple[int, …] | None\nreshape output\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nndarray or list(ndarray)\nspatially interped data\n\n\n\n\n\n\n&gt;&gt;&gt; ds = dfsu.read()\n&gt;&gt;&gt; g = dfs.get_overset_grid(shape=(50,40))\n&gt;&gt;&gt; elem_ids, weights = dfs.get_2d_interpolant(g.xy)\n&gt;&gt;&gt; dsi = dfs.interp2d(ds, elem_ids, weights)\n\n\n\n\nspatial.GeometryFMAreaSpectrum.to_mesh(outfilename)\nExport geometry to new mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired\n\n\n\n\n\n\n\nspatial.GeometryFMAreaSpectrum.to_shapely()\nExport mesh as shapely MultiPolygon\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nshapely.shapely.geometry.shapely.geometry.MultiPolygon\npolygons with mesh elements"
  },
  {
    "objectID": "api/open.html",
    "href": "api/open.html",
    "title": "open",
    "section": "",
    "text": "open(filename, **kwargs)\nOpen a dfs/mesh file (and read the header)\nThe typical workflow for small dfs files is to read all data with mikeio.read instead of using this function. For big files, however, it can be convenient to open the file first with dfs=mikeio.open(…) to inspect it’s content (items, time and shape) and then decide what to read using dfs.read(…)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path and file name to the dfs file.\nrequired\n\n\ntype\nstr\nDfs2 only. Additional information about the file, e.g. “spectral” for spectral dfs2 files. By default: None.\nrequired\n\n\n\n\n\n\nmikeio.read - read data from a dfs file\n\n\n\n&gt;&gt;&gt; dfs = mikeio.open(\"wl.dfs1\")\n&gt;&gt;&gt; dfs = mikeio.open(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds = dfs.read(items=\"Salinity\", time=\"2016-01\")\n&gt;&gt;&gt; dfs = mikeio.open(\"pt_spectra.dfs2\", type=\"spectral\")"
  },
  {
    "objectID": "api/open.html#parameters",
    "href": "api/open.html#parameters",
    "title": "open",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nfull path and file name to the dfs file.\nrequired\n\n\ntype\nstr\nDfs2 only. Additional information about the file, e.g. “spectral” for spectral dfs2 files. By default: None.\nrequired"
  },
  {
    "objectID": "api/open.html#see-also",
    "href": "api/open.html#see-also",
    "title": "open",
    "section": "",
    "text": "mikeio.read - read data from a dfs file"
  },
  {
    "objectID": "api/open.html#examples",
    "href": "api/open.html#examples",
    "title": "open",
    "section": "",
    "text": "&gt;&gt;&gt; dfs = mikeio.open(\"wl.dfs1\")\n&gt;&gt;&gt; dfs = mikeio.open(\"HD2D.dfsu\")\n&gt;&gt;&gt; ds = dfs.read(items=\"Salinity\", time=\"2016-01\")\n&gt;&gt;&gt; dfs = mikeio.open(\"pt_spectra.dfs2\", type=\"spectral\")"
  },
  {
    "objectID": "api/dfsu.Dfsu2DH.html",
    "href": "api/dfsu.Dfsu2DH.html",
    "title": "dfsu.Dfsu2DH",
    "section": "",
    "text": "dfsu.Dfsu2DH(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_nodes\nNumber of nodes\n\n\nn_timesteps\nNumber of time steps\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nextract_track\nExtract track data from a dfsu file\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu2DH.extract_track(track, items=None, method='nearest', dtype=np.float32)\nExtract track data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack\n\nwith DatetimeIndex and (x, y) of track points as first two columns x,y coordinates must be in same coordinate system as dfsu\nrequired\n\n\ntrack\n\nfilename of csv or dfs0 file containing t,x,y\nrequired\n\n\nitems\n\nExtract only selected items, by number (0-based), or by name\nNone\n\n\nmethod\n\nSpatial interpolation method (‘nearest’ or ‘inverse_distance’) default=‘nearest’\n'nearest'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA dataset with data dimension t The first two items will be x- and y- coordinates of track\n\n\n\n\n\n\n&gt;&gt;&gt; dfsu = mikeio.open(\"tests/testdata/NorthSea_HD_and_windspeed.dfsu\")\n&gt;&gt;&gt; ds = dfsu.extract_track(\"tests/testdata/altimetry_NorthSea_20171027.csv\")\n&gt;&gt;&gt; ds\n&lt;mikeio.Dataset&gt;\ndims: (time:1115)\ntime: 2017-10-26 04:37:37 - 2017-10-30 20:54:47 (1115 non-equidistant records)\ngeometry: GeometryUndefined()\nitems:\n  0:  Longitude &lt;Undefined&gt; (undefined)\n  1:  Latitude &lt;Undefined&gt; (undefined)\n  2:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  3:  Wind speed &lt;Wind speed&gt; (meter per sec)\n\n\n\n\ndfsu.Dfsu2DH.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\ndfsu.Dfsu2DH.read(items=None, time=None, elements=None, area=None, x=None, y=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu2DH.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/dfsu.Dfsu2DH.html#attributes",
    "href": "api/dfsu.Dfsu2DH.html#attributes",
    "title": "dfsu.Dfsu2DH",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_nodes\nNumber of nodes\n\n\nn_timesteps\nNumber of time steps\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes"
  },
  {
    "objectID": "api/dfsu.Dfsu2DH.html#methods",
    "href": "api/dfsu.Dfsu2DH.html#methods",
    "title": "dfsu.Dfsu2DH",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nextract_track\nExtract track data from a dfsu file\n\n\nget_overset_grid\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu2DH.extract_track(track, items=None, method='nearest', dtype=np.float32)\nExtract track data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack\n\nwith DatetimeIndex and (x, y) of track points as first two columns x,y coordinates must be in same coordinate system as dfsu\nrequired\n\n\ntrack\n\nfilename of csv or dfs0 file containing t,x,y\nrequired\n\n\nitems\n\nExtract only selected items, by number (0-based), or by name\nNone\n\n\nmethod\n\nSpatial interpolation method (‘nearest’ or ‘inverse_distance’) default=‘nearest’\n'nearest'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA dataset with data dimension t The first two items will be x- and y- coordinates of track\n\n\n\n\n\n\n&gt;&gt;&gt; dfsu = mikeio.open(\"tests/testdata/NorthSea_HD_and_windspeed.dfsu\")\n&gt;&gt;&gt; ds = dfsu.extract_track(\"tests/testdata/altimetry_NorthSea_20171027.csv\")\n&gt;&gt;&gt; ds\n&lt;mikeio.Dataset&gt;\ndims: (time:1115)\ntime: 2017-10-26 04:37:37 - 2017-10-30 20:54:47 (1115 non-equidistant records)\ngeometry: GeometryUndefined()\nitems:\n  0:  Longitude &lt;Undefined&gt; (undefined)\n  1:  Latitude &lt;Undefined&gt; (undefined)\n  2:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  3:  Wind speed &lt;Wind speed&gt; (meter per sec)\n\n\n\n\ndfsu.Dfsu2DH.get_overset_grid(dx=None, dy=None, nx=None, ny=None, buffer=0.0)\nget a 2d grid that covers the domain by specifying spacing or shape\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndx\nfloat\ngrid resolution in x-direction (or in x- and y-direction)\nNone\n\n\ndy\nfloat\ngrid resolution in y-direction\nNone\n\n\nnx\nint\nnumber of points in x-direction, by default None (the value will be inferred)\nNone\n\n\nny\nint\nnumber of points in y-direction, by default None (the value will be inferred)\nNone\n\n\nbuffer\nfloat\npositive to make the area larger, default=0 can be set to a small negative value to avoid NaN values all around the domain.\n0.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;mikeio.Grid2D&gt;\n2d grid\n\n\n\n\n\n\n\ndfsu.Dfsu2DH.read(items=None, time=None, elements=None, area=None, x=None, y=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu2DH.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/dfsu.DfsuSpectral.html",
    "href": "api/dfsu.DfsuSpectral.html",
    "title": "dfsu.DfsuSpectral",
    "section": "",
    "text": "dfsu.DfsuSpectral(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nfrequencies\nFrequency axis\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_items\nNumber of items\n\n\nn_nodes\nNumber of nodes\n\n\nn_timesteps\nNumber of time steps\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalc_Hm0_from_spectrum\nCalculate significant wave height (Hm0) from spectrum\n\n\nread\nRead data from a spectral dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.DfsuSpectral.calc_Hm0_from_spectrum(spectrum, tail=True)\nCalculate significant wave height (Hm0) from spectrum\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nspectrum\n(numpy.numpy.ndarray, mikeio.dataset.DataArray)\nfrequency or direction-frequency spectrum\nrequired\n\n\ntail\nbool\nShould a parametric spectral tail be added in the computations? by default True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.ndarray\nsignificant wave height values\n\n\n\n\n\n\n\ndfsu.DfsuSpectral.read(items=None, time=None, elements=None, nodes=None, area=None, x=None, y=None, keepdims=False, dtype=np.float32)\nRead data from a spectral dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\n\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\n\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\n\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\n\nRead only data inside (horizontal) area (spectral area files only) given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\n\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\ny\n\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\nelements\n\nRead only selected element ids (spectral area files only)\nNone\n\n\nnodes\n\nRead only selected node ids (spectral line files only)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with dimensions [t,elements/nodes,frequencies,directions]\n\n\n\n\n\n\n&gt;&gt;&gt; mikeio.read(\"tests/testdata/line_spectra.dfsu\")\n&lt;mikeio.Dataset&gt;\ndims: (time:4, node:10, direction:16, frequency:25)\ntime: 2017-10-27 00:00:00 - 2017-10-27 05:00:00 (4 records)\ngeometry: DfsuSpectral1D (9 elements, 10 nodes)\nitems:\n  0:  Energy density &lt;Wave energy density&gt; (meter pow 2 sec per deg)\n&gt;&gt;&gt; mikeio.read(\"tests/testdata/area_spectra.dfsu\", time=-1)\n&lt;mikeio.Dataset&gt;\ndims: (element:40, direction:16, frequency:25)\ntime: 2017-10-27 05:00:00 (time-invariant)\ngeometry: DfsuSpectral2D (40 elements, 33 nodes)\nitems:\n  0:  Energy density &lt;Wave energy density&gt; (meter pow 2 sec per deg)\n\n\n\n\ndfsu.DfsuSpectral.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/dfsu.DfsuSpectral.html#attributes",
    "href": "api/dfsu.DfsuSpectral.html#attributes",
    "title": "dfsu.DfsuSpectral",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\ndirections\nDirectional axis\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\nfrequencies\nFrequency axis\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_directions\nNumber of directions\n\n\nn_elements\nNumber of elements\n\n\nn_frequencies\nNumber of frequencies\n\n\nn_items\nNumber of items\n\n\nn_nodes\nNumber of nodes\n\n\nn_timesteps\nNumber of time steps\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes"
  },
  {
    "objectID": "api/dfsu.DfsuSpectral.html#methods",
    "href": "api/dfsu.DfsuSpectral.html#methods",
    "title": "dfsu.DfsuSpectral",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalc_Hm0_from_spectrum\nCalculate significant wave height (Hm0) from spectrum\n\n\nread\nRead data from a spectral dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.DfsuSpectral.calc_Hm0_from_spectrum(spectrum, tail=True)\nCalculate significant wave height (Hm0) from spectrum\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nspectrum\n(numpy.numpy.ndarray, mikeio.dataset.DataArray)\nfrequency or direction-frequency spectrum\nrequired\n\n\ntail\nbool\nShould a parametric spectral tail be added in the computations? by default True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.ndarray\nsignificant wave height values\n\n\n\n\n\n\n\ndfsu.DfsuSpectral.read(items=None, time=None, elements=None, nodes=None, area=None, x=None, y=None, keepdims=False, dtype=np.float32)\nRead data from a spectral dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\n\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\n\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\n\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\n\nRead only data inside (horizontal) area (spectral area files only) given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\n\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\ny\n\nRead only data for elements containing the (x,y) points(s), by default None\nNone\n\n\nelements\n\nRead only selected element ids (spectral area files only)\nNone\n\n\nnodes\n\nRead only selected node ids (spectral line files only)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with dimensions [t,elements/nodes,frequencies,directions]\n\n\n\n\n\n\n&gt;&gt;&gt; mikeio.read(\"tests/testdata/line_spectra.dfsu\")\n&lt;mikeio.Dataset&gt;\ndims: (time:4, node:10, direction:16, frequency:25)\ntime: 2017-10-27 00:00:00 - 2017-10-27 05:00:00 (4 records)\ngeometry: DfsuSpectral1D (9 elements, 10 nodes)\nitems:\n  0:  Energy density &lt;Wave energy density&gt; (meter pow 2 sec per deg)\n&gt;&gt;&gt; mikeio.read(\"tests/testdata/area_spectra.dfsu\", time=-1)\n&lt;mikeio.Dataset&gt;\ndims: (element:40, direction:16, frequency:25)\ntime: 2017-10-27 05:00:00 (time-invariant)\ngeometry: DfsuSpectral2D (40 elements, 33 nodes)\nitems:\n  0:  Energy density &lt;Wave energy density&gt; (meter pow 2 sec per deg)\n\n\n\n\ndfsu.DfsuSpectral.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/Dfs0.html",
    "href": "api/Dfs0.html",
    "title": "Dfs0",
    "section": "",
    "text": "Dfs0(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\nitems\nList of items\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nstart_time\nFile start time\n\n\ntime\nFile all datetimes\n\n\ntimestep\nTime step size in seconds\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nfrom_dataframe\nCreate a dfs0 from a pandas Dataframe\n\n\nread\nRead data from a dfs0 file.\n\n\nto_dataframe\nRead data from the dfs0 file and return a Pandas DataFrame.\n\n\n\n\n\nDfs0.from_dataframe(df, filename, itemtype=None, unit=None, items=None)\nCreate a dfs0 from a pandas Dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.pandas.DataFrame\nDataframe with data\nrequired\n\n\nfilename\nstr\nfilename to write output\nrequired\n\n\nitemtype\nmikeio.eum.EUMType | None\nSame type for all items\nNone\n\n\nunit\nmikeio.eum.EUMUnit | None\nSame unit for all items\nNone\n\n\nitems\ntyping.Sequence[mikeio.eum.ItemInfo] | None\nDifferent types, units for each items\nNone\n\n\n\n\n\n\n\nDfs0.read(items=None, time=None, **kwargs)\nRead data from a dfs0 file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t]\n\n\n\n\n\n\n\nDfs0.to_dataframe(unit_in_name=False, round_time='ms')\nRead data from the dfs0 file and return a Pandas DataFrame.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nunit_in_name\nbool\ninclude unit in column name, default False\nFalse\n\n\nround_time\nstr\nround time to avoid problem with floating point inaccurcy, set to False to avoid rounding\n'ms'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame"
  },
  {
    "objectID": "api/Dfs0.html#attributes",
    "href": "api/Dfs0.html#attributes",
    "title": "Dfs0",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nitems\nList of items\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nstart_time\nFile start time\n\n\ntime\nFile all datetimes\n\n\ntimestep\nTime step size in seconds"
  },
  {
    "objectID": "api/Dfs0.html#methods",
    "href": "api/Dfs0.html#methods",
    "title": "Dfs0",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nfrom_dataframe\nCreate a dfs0 from a pandas Dataframe\n\n\nread\nRead data from a dfs0 file.\n\n\nto_dataframe\nRead data from the dfs0 file and return a Pandas DataFrame.\n\n\n\n\n\nDfs0.from_dataframe(df, filename, itemtype=None, unit=None, items=None)\nCreate a dfs0 from a pandas Dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.pandas.DataFrame\nDataframe with data\nrequired\n\n\nfilename\nstr\nfilename to write output\nrequired\n\n\nitemtype\nmikeio.eum.EUMType | None\nSame type for all items\nNone\n\n\nunit\nmikeio.eum.EUMUnit | None\nSame unit for all items\nNone\n\n\nitems\ntyping.Sequence[mikeio.eum.ItemInfo] | None\nDifferent types, units for each items\nNone\n\n\n\n\n\n\n\nDfs0.read(items=None, time=None, **kwargs)\nRead data from a dfs0 file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t]\n\n\n\n\n\n\n\nDfs0.to_dataframe(unit_in_name=False, round_time='ms')\nRead data from the dfs0 file and return a Pandas DataFrame.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nunit_in_name\nbool\ninclude unit in column name, default False\nFalse\n\n\nround_time\nstr\nround time to avoid problem with floating point inaccurcy, set to False to avoid rounding\n'ms'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame"
  },
  {
    "objectID": "api/Mesh.html",
    "href": "api/Mesh.html",
    "title": "Mesh",
    "section": "",
    "text": "Mesh(self, filename)\nThe Mesh class is initialized with a mesh file."
  },
  {
    "objectID": "api/Mesh.html#parameters",
    "href": "api/Mesh.html#parameters",
    "title": "Mesh",
    "section": "Parameters",
    "text": "Parameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | pathlib.Path\nmesh filename\nrequired"
  },
  {
    "objectID": "api/Mesh.html#attributes",
    "href": "api/Mesh.html#attributes",
    "title": "Mesh",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nType\nDescription\n\n\n\n\ngeometry\nmikeio.spatial.GeometryFM2D\nFlexible Mesh geometry"
  },
  {
    "objectID": "api/Mesh.html#examples",
    "href": "api/Mesh.html#examples",
    "title": "Mesh",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.Mesh(\"../data/odense_rough.mesh\")\n\n&lt;Mesh&gt;\nnumber of elements: 654\nnumber of nodes: 399\nprojection: UTM-33"
  },
  {
    "objectID": "api/Mesh.html#methods",
    "href": "api/Mesh.html#methods",
    "title": "Mesh",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nto_shapely\nConvert Mesh geometry to shapely MultiPolygon\n\n\nwrite\nwrite mesh to file\n\n\n\n\nto_shapely\nMesh.to_shapely()\nConvert Mesh geometry to shapely MultiPolygon\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nshapely.geometry.MultiPolygon\nmesh as shapely MultiPolygon\n\n\n\n\n\nExamples\n\nimport mikeio\nmsh = mikeio.open(\"../data/odense_rough.mesh\")\nmsh.to_shapely()\n\n\n\n\n\n\n\n\n\n\n\nwrite\nMesh.write(outfilename)\nwrite mesh to file\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file\nrequired"
  },
  {
    "objectID": "examples/dfs2/index.html",
    "href": "examples/dfs2/index.html",
    "title": "Dfs2 examples",
    "section": "",
    "text": "Bathymetry\nMeteo data",
    "crumbs": [
      "Home",
      "Examples",
      "Dfs2"
    ]
  },
  {
    "objectID": "examples/dfs2/bathy.html",
    "href": "examples/dfs2/bathy.html",
    "title": "Dfs2 - Bathymetric data",
    "section": "",
    "text": "GEBCO Compilation Group (2020) GEBCO 2020 Grid (doi:10.5285/a29c5465-b138-234d-e053-6c86abc040b9)\n\nimport xarray\nimport mikeio\n\n\nds = xarray.open_dataset(\"../../data/gebco_2020_n56.3_s55.2_w12.2_e13.1.nc\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 118kB\nDimensions:    (lat: 264, lon: 216)\nCoordinates: (2)\nData variables:\n    elevation  (lat, lon) int16 114kB ...\nAttributes: (8)xarray.DatasetDimensions:lat: 264lon: 216Coordinates: (2)lat(lat)float6455.2 55.21 55.21 ... 56.29 56.3standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Ysdn_parameter_urn :SDN:P01::ALATZZ01sdn_parameter_name :Latitude northsdn_uom_urn :SDN:P06::DEGNsdn_uom_name :Degrees northarray([55.202083, 55.20625 , 55.210417, ..., 56.289583, 56.29375 , 56.297917])lon(lon)float6412.2 12.21 12.21 ... 13.09 13.1standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xsdn_parameter_urn :SDN:P01::ALONZZ01sdn_parameter_name :Longitude eastsdn_uom_urn :SDN:P06::DEGEsdn_uom_name :Degrees eastarray([12.202083, 12.20625 , 12.210417, ..., 13.089583, 13.09375 , 13.097917])Data variables: (1)elevation(lat, lon)int16...standard_name :height_above_reference_ellipsoidlong_name :Elevation relative to sea levelunits :msdn_parameter_urn :SDN:P01::BATHHGHTsdn_parameter_name :Sea floor height (above mean sea level) {bathymetric height}sdn_uom_urn :SDN:P06::ULAAsdn_uom_name :Metres[57024 values with dtype=int16]Indexes: (2)latPandasIndexPandasIndex(Index([ 55.20208333333332,  55.20625000000001, 55.210416666666674,\n        55.21458333333334,           55.21875,  55.22291666666666,\n       55.227083333333326,  55.23124999999999,  55.23541666666665,\n        55.23958333333334,\n       ...\n        56.26041666666666,  56.26458333333332,  56.26875000000001,\n       56.272916666666674,  56.27708333333334,           56.28125,\n        56.28541666666666, 56.289583333333326,  56.29374999999999,\n        56.29791666666665],\n      dtype='float64', name='lat', length=264))lonPandasIndexPandasIndex(Index([ 12.20208333333332, 12.206250000000011, 12.210416666666674,\n       12.214583333333337,           12.21875, 12.222916666666663,\n       12.227083333333326, 12.231249999999989, 12.235416666666652,\n       12.239583333333343,\n       ...\n       13.060416666666669, 13.064583333333331, 13.068749999999994,\n       13.072916666666657,  13.07708333333332, 13.081250000000011,\n       13.085416666666674, 13.089583333333337,           13.09375,\n       13.097916666666663],\n      dtype='float64', name='lon', length=216))Attributes: (8)Conventions :CF-1.6title :The GEBCO_2020 Grid - a continuous terrain model for oceans and land at 15 arc-second intervalsinstitution :On behalf of the General Bathymetric Chart of the Oceans (GEBCO), the data are held at the British Oceanographic Data Centre (BODC).source :The GEBCO_2020 Grid is the latest global bathymetric product released by the General Bathymetric Chart of the Oceans (GEBCO) and has been developed through the Nippon Foundation-GEBCO Seabed 2030 Project. This is a collaborative project between the Nippon Foundation of Japan and GEBCO. The Seabed 2030 Project aims to bring together all available bathymetric data to produce the definitive map of the world ocean floor and make it available to all.history :Information on the development of the data set and the source data sets included in the grid can be found in the data set documentation available from https://www.gebco.netreferences :DOI: 10.5285/a29c5465-b138-234d-e053-6c86abc040b9comment :The data in the GEBCO_2020 Grid should not be used for navigation or any purpose relating to safety at sea.node_offset :1.0\n\n\n\nds.elevation.plot();\n\n\n\n\n\n\n\n\n\nds.elevation.sel(lon=12.74792, lat=55.865, method=\"nearest\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'elevation' ()&gt; Size: 2B\n[1 values with dtype=int16]\nCoordinates: (2)\nAttributes: (7)xarray.DataArray'elevation'...[1 values with dtype=int16]Coordinates: (2)lat()float6455.86standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Ysdn_parameter_urn :SDN:P01::ALATZZ01sdn_parameter_name :Latitude northsdn_uom_urn :SDN:P06::DEGNsdn_uom_name :Degrees northarray(55.86458333)lon()float6412.75standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xsdn_parameter_urn :SDN:P01::ALONZZ01sdn_parameter_name :Longitude eastsdn_uom_urn :SDN:P06::DEGEsdn_uom_name :Degrees eastarray(12.74791667)Indexes: (0)Attributes: (7)standard_name :height_above_reference_ellipsoidlong_name :Elevation relative to sea levelunits :msdn_parameter_urn :SDN:P01::BATHHGHTsdn_parameter_name :Sea floor height (above mean sea level) {bathymetric height}sdn_uom_urn :SDN:P06::ULAAsdn_uom_name :Metres\n\n\nCheck ordering of dimensions, should be (y,x)\n\nds.elevation.dims\n\n('lat', 'lon')\n\n\n\nel = ds.elevation.values\nel.shape\n\n(264, 216)\n\n\nCheck that axes are increasing, S-&gt;N W-&gt;E\n\nds.lat.values[0],ds.lat.values[-1] \n\n(55.20208333333332, 56.29791666666665)\n\n\n\nds.lat.values[0] &lt; ds.lat.values[-1] \n\nTrue\n\n\n\nds.lon.values[0],ds.lon.values[-1] \n\n(12.20208333333332, 13.097916666666663)\n\n\n\nel[0,0] # Bottom left\n\n-8\n\n\n\nel[-1,0] # Top Left\n\n-31\n\n\n\ngeometry = mikeio.Grid2D(x=ds.lon.values, y=ds.lat.values, projection=\"LONG/LAT\")\ngeometry\n\n&lt;mikeio.Grid2D&gt;\nx: [12.2, 12.21, ..., 13.1] (nx=216, dx=0.004167)\ny: [55.2, 55.21, ..., 56.3] (ny=264, dy=0.004167)\nprojection: LONG/LAT\n\n\n\nda = mikeio.DataArray(data=el,\n               item=mikeio.ItemInfo(\"Elevation\", mikeio.EUMType.Total_Water_Depth),\n               geometry=geometry,\n               dims=(\"y\",\"x\") # No time dimension\n               )\nda\n\n&lt;mikeio.DataArray&gt;\nname: Elevation\ndims: (y:264, x:216)\ntime: 2018-01-01 00:00:00 (time-invariant)\ngeometry: Grid2D (ny=264, nx=216)\n\n\n\nda.plot();\n\n\n\n\n\n\n\n\n\nda.plot(cmap='coolwarm', vmin=-100, vmax=100);\n\n\n\n\n\n\n\n\n\nda.to_dfs(\"gebco.dfs2\")\n\n\nds = mikeio.read(\"gebco.dfs2\")\nds.Elevation.plot()\n\n\n\n\n\n\n\n\n\nClean up\n\nimport os\n\nos.remove(\"gebco.dfs2\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfs2",
      "Dfs2 - Bathymetric data"
    ]
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Examples",
    "section": "",
    "text": "Example data\n\n\n\n\n\nIf you want to try one of the examples you need to first download some data files.\nThe files are stored on GitHub in the MIKE IO repo.\nThe easiest way is to the download the repo as a zip file and extract the files you need.\nIn the zip file you find the files in tests/testdata/ folder\nSome of the files:\ntests/testdata\n├── FakeLake.dfsu\n├── HD2D.dfsu\n├── NorthSea_HD_and_windspeed.dfsu\n├── consistency\n│   ├── oresundHD.dfs2\n│   └── oresundHD.dfsu\n├── gebco_2020_n56.3_s55.2_w12.2_e13.1.nc\n├── gfs_wind.nc\n├── odense_rough.mesh\n├── oresund_sigma_z.dfsu\n├── pfs\n│   ├── concat.mzt\n│   └── t1_t0.mzt\n├── tide1.dfs1\n├── tide2.dfs1\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nDfs2 - Bathymetric data\n\n\nConvert GEBCO 2020 NetCDF to dfs2\n\n\n\n\nDfs2 - Meteo data\n\n\nConversion of NetCDF from Global Forecasting System to Dfs2\n\n\n\n\nDfs2 examples\n\n\n\n\n\n\n\nDfsu - 2D interpolation\n\n\nInterpolate dfsu data to a grid, save as dfs2 and geotiff. Interpolate dfsu data to another mesh.\n\n\n\n\nGeneric dfs processing\n\n\n\n\n\n\n\nTime interpolation\n\n\nInterpolate data to a specific time axis\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Examples"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html",
    "href": "examples/Dfsu-2D-interpolation.html",
    "title": "Dfsu - 2D interpolation",
    "section": "",
    "text": "import mikeio\nds = mikeio.read(\"../data/wind_north_sea.dfsu\", items=\"Wind speed\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:6, element:958)\ntime: 2017-10-27 00:00:00 - 2017-10-27 05:00:00 (6 records)\ngeometry: Dfsu2D (958 elements, 570 nodes)\nitems:\n  0:  Wind speed &lt;Wind speed&gt; (meter per sec)\nda = ds.Wind_speed\nda.plot();",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#interpolate-to-grid",
    "href": "examples/Dfsu-2D-interpolation.html#interpolate-to-grid",
    "title": "Dfsu - 2D interpolation",
    "section": "Interpolate to grid",
    "text": "Interpolate to grid\n\nGet an overset grid covering the domain\nThen interpolate all data to the new grid and plot.\nThe interpolated data is then saved to a dfs2 file.\n\n\ng = da.geometry.get_overset_grid(dx=0.1)\ng\n\n&lt;mikeio.Grid2D&gt;\nx: [-1.563, -1.463, ..., 8.837] (nx=105, dx=0.1)\ny: [49.9, 50, ..., 55.3] (ny=55, dy=0.1)\nprojection: LONG/LAT\n\n\n\nda_grid = da.interp_like(g)\nda_grid\n\n&lt;mikeio.DataArray&gt;\nname: Wind speed\ndims: (time:6, y:55, x:105)\ntime: 2017-10-27 00:00:00 - 2017-10-27 05:00:00 (6 records)\ngeometry: Grid2D (ny=55, nx=105)\n\n\n\nda_grid.plot();",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#save-to-dfs2-file",
    "href": "examples/Dfsu-2D-interpolation.html#save-to-dfs2-file",
    "title": "Dfsu - 2D interpolation",
    "section": "Save to dfs2 file",
    "text": "Save to dfs2 file\n\nda_grid.to_dfs(\"wind_north_sea_interpolated.dfs2\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#save-to-netcdf",
    "href": "examples/Dfsu-2D-interpolation.html#save-to-netcdf",
    "title": "Dfsu - 2D interpolation",
    "section": "Save to NetCDF",
    "text": "Save to NetCDF\n\nxr_da = da_grid.to_xarray()\nxr_da.to_netcdf(\"wind_north_sea_interpolated.nc\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#save-to-geotiff",
    "href": "examples/Dfsu-2D-interpolation.html#save-to-geotiff",
    "title": "Dfsu - 2D interpolation",
    "section": "Save to GeoTiff",
    "text": "Save to GeoTiff\n\n\n\n\n\n\nNote\n\n\n\nThis section requires the rasterio package.\n\n\n\nimport numpy as np\nimport rasterio\nfrom rasterio.transform import from_origin\n# Dcoumentation https://rasterio.readthedocs.io/en/latest/index.html\n\nwith rasterio.open(\n     fp='wind.tif',\n     mode='w',\n     driver='GTiff',\n     height=g.ny,\n     width=g.nx,\n     count=1,\n     dtype=da.dtype,\n     crs='+proj=latlong', # adjust accordingly for projected coordinate systems\n     transform=from_origin(g.bbox.left, g.bbox.top, g.dx, g.dy)\n     ) as dst:\n        dst.write(np.flipud(da_grid[0].to_numpy()), 1) # first time_step",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#interpolate-scatter-data-to-mesh",
    "href": "examples/Dfsu-2D-interpolation.html#interpolate-scatter-data-to-mesh",
    "title": "Dfsu - 2D interpolation",
    "section": "Interpolate scatter data to mesh",
    "text": "Interpolate scatter data to mesh\nWe want to interpolate scatter data onto an existing mesh and create a new dfsu with the interpolated data.\nThis uses lower level private utility methods not part of the public API.\nInterpolating from scatter data will soon be possible in a simpler way.\n\nfrom mikeio.spatial._utils import dist_in_meters\nfrom mikeio._interpolation import get_idw_interpolant\n\n\ndfs = mikeio.open(\"../data/wind_north_sea.dfsu\")\n\n\ndfs.geometry.plot.mesh();\n\n\n\n\n\n\n\n\n\n# scatter data: x,y,value for 4 points\nscatter= np.array([[1,50,1], [4, 52, 3], [8, 55, 2], [-1, 55, 1.5]])\nscatter\n\narray([[ 1. , 50. ,  1. ],\n       [ 4. , 52. ,  3. ],\n       [ 8. , 55. ,  2. ],\n       [-1. , 55. ,  1.5]])\n\n\nLet’s first try the approx for a single element:\n\ncalc distance to all interpolation points\ncalc IDW interpolatant weights\nInterpolate\n\n\ndist = dist_in_meters(scatter[:,:2], dfs.element_coordinates[0,:2])\ndist\n\narray([4.00139539, 3.18881018, 6.58769411, 2.69722991])\n\n\n\nw = get_idw_interpolant(dist, p=2)\nw\n\narray([0.19438779, 0.30607974, 0.07171749, 0.42781498])\n\n\n\nnp.dot(scatter[:,2], w) # interpolated value in element 0\n\n1.8977844597276883\n\n\nLet’s do the same for all points in the mesh and plot in the end\n\ndati = np.zeros((1,dfs.n_elements))\nfor j in range(dfs.n_elements):\n    dist = dist_in_meters(scatter[:,:2], dfs.element_coordinates[j,:2])\n    w = get_idw_interpolant(dist, p=2)\n    dati[0,j] = np.dot(scatter[:,2], w)\n\n\nda = mikeio.DataArray(data=dati, geometry=dfs.geometry, time=dfs.start_time)\nda\n\n&lt;mikeio.DataArray&gt;\nname: NoName\ndims: (time:1, element:958)\ntime: 2017-10-27 00:00:00 (time-invariant)\ngeometry: Dfsu2D (958 elements, 570 nodes)\n\n\n\nda.plot(title=\"Interpolated scatter data\");\n\n\n\n\n\n\n\n\n\nda.to_dfs(\"interpolated_scatter.dfsu\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "examples/Dfsu-2D-interpolation.html#clean-up",
    "href": "examples/Dfsu-2D-interpolation.html#clean-up",
    "title": "Dfsu - 2D interpolation",
    "section": "Clean up",
    "text": "Clean up\n\nimport os\n\nos.remove(\"wind_north_sea_interpolated.dfs2\")\nos.remove(\"wind_north_sea_interpolated.nc\")\nos.remove(\"wind.tif\")\nos.remove(\"interpolated_scatter.dfsu\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfsu - 2D interpolation"
    ]
  },
  {
    "objectID": "user-guide/mesh.html",
    "href": "user-guide/mesh.html",
    "title": "Mesh",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport mikeio",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#read-mesh-file",
    "href": "user-guide/mesh.html#read-mesh-file",
    "title": "Mesh",
    "section": "Read mesh file",
    "text": "Read mesh file\n\nmsh = mikeio.Mesh(\"../data/odense_rough.mesh\")\nmsh\n\n&lt;Mesh&gt;\nnumber of elements: 654\nnumber of nodes: 399\nprojection: UTM-33",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#plot-mesh",
    "href": "user-guide/mesh.html#plot-mesh",
    "title": "Mesh",
    "section": "Plot mesh",
    "text": "Plot mesh\n\nmsh.plot()\n\n\n\n\n\n\n\n\n\nmsh.plot.boundary_nodes(boundary_names=['Land','Open boundary']);",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#convert-mesh-to-shapely",
    "href": "user-guide/mesh.html#convert-mesh-to-shapely",
    "title": "Mesh",
    "section": "Convert mesh to shapely",
    "text": "Convert mesh to shapely\nConvert mesh to shapely MultiPolygon object, requires that the shapely library is installed.\n\nmp = msh.to_shapely()\nmp\n\n\n\n\n\n\n\n\nNow a lot of methods are available\n\nmp.area\n\n68931409.58160606\n\n\n\nmp.bounds\n\n(211068.501175313, 6153077.66681803, 224171.617336507, 6164499.42751662)\n\n\n\ndomain = mp.buffer(0)\ndomain\n\n\n\n\n\n\n\n\n\nopen_water = domain.buffer(-500)\n\ncoastalzone = domain - open_water\ncoastalzone",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#check-if-points-are-inside-the-domain",
    "href": "user-guide/mesh.html#check-if-points-are-inside-the-domain",
    "title": "Mesh",
    "section": "Check if points are inside the domain",
    "text": "Check if points are inside the domain\n\nfrom shapely.geometry import Point\n\np1 = Point(216000, 6162000)\np2 = Point(220000, 6156000)\nprint(mp.contains(p1))\nprint(mp.contains(p2))\n\nTrue\nFalse\n\n\nWe can get similar functionality from the .geometry attribute of the mesh object.\n\np1p2 = [[216000, 6162000], [220000, 6156000]]\nmsh.geometry.contains(p1p2)\n\narray([ True, False])\n\n\n\nax = msh.plot()\nax.scatter(p1.x, p1.y, marker=\"*\", s=200, c=\"red\", label=\"inside\")\nax.scatter(p2.x, p2.y, marker=\"+\", s=200, c=\"green\", label=\"outside\")\nax.legend();",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#change-z-values-and-boundary-code",
    "href": "user-guide/mesh.html#change-z-values-and-boundary-code",
    "title": "Mesh",
    "section": "Change z values and boundary code",
    "text": "Change z values and boundary code\nAssume that we want to have a minimum depth of 2 meters and change the open boundary (code 2) to a closed one (code 1).\n\ng = msh.geometry\nprint(f'max z before: {g.node_coordinates[:,2].max()}')\nzc = g.node_coordinates[:,2]\nzc[zc&gt;-2] = -2\ng.node_coordinates[:,2] = zc\nprint(f'max z after: {g.node_coordinates[:,2].max()}')\n\nmax z before: -0.200000002980232\nmax z after: -2.0\n\n\n\nc = g.codes\nc[c==2] = 1\ng.codes = c",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/mesh.html#save-the-modfied-geometry-to-a-new-mesh-file",
    "href": "user-guide/mesh.html#save-the-modfied-geometry-to-a-new-mesh-file",
    "title": "Mesh",
    "section": "Save the modfied geometry to a new mesh file",
    "text": "Save the modfied geometry to a new mesh file\n\ng.to_mesh(\"new_mesh.mesh\")\n\nCleanup\n\nimport os\n\nos.remove(\"new_mesh.mesh\")",
    "crumbs": [
      "Home",
      "User Guide",
      "Mesh"
    ]
  },
  {
    "objectID": "user-guide/dfsu.html",
    "href": "user-guide/dfsu.html",
    "title": "Dfsu and Mesh Overview",
    "section": "",
    "text": "Dfsu and mesh files are both flexible mesh file formats used by MIKE 21/3 engines. The .mesh file is an ASCII file for storing the flexible mesh geometry. The .dfsu file is a binary dfs file with data on this mesh. The mesh geometry is available in a .dfsu file as static items.\nFor a detailed description of the .mesh and .dfsu file specification see the flexible file format documentation.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfsu and Mesh Overview"
    ]
  },
  {
    "objectID": "user-guide/dfsu.html#the-flexible-mesh",
    "href": "user-guide/dfsu.html#the-flexible-mesh",
    "title": "Dfsu and Mesh Overview",
    "section": "The flexible mesh",
    "text": "The flexible mesh\nThe mesh geometry in a .mesh or a .dfsu file consists of a list of nodes and a list of elements.\nEach node has:\n\nNode id\nx,y,z coordinates\nCode (0 for internal water points, 1 for land, &gt;1 for open boundary)\n\nEach element has:\n\nElement id\nElement table; specifies for each element the nodes that defines the element. (the number of nodes defines the type: triangular, quadrilateral, prism etc.)\n\n\n\n\n\n\n\nNote\n\n\n\nIn MIKE Zero, node ids, element ids and layer ids are 1-based. In MIKE IO, all ids are 0-based following standard Python indexing. That means, as an example, that when finding the element closest to a point its id will be 1 lower in MIKE IO compared to examining the file in MIKE Zero.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfsu and Mesh Overview"
    ]
  },
  {
    "objectID": "user-guide/dfsu.html#mike-io-flexible-mesh-geometry",
    "href": "user-guide/dfsu.html#mike-io-flexible-mesh-geometry",
    "title": "Dfsu and Mesh Overview",
    "section": "MIKE IO Flexible Mesh Geometry",
    "text": "MIKE IO Flexible Mesh Geometry\nMIKE IO has a Flexible Mesh Geometry class, GeometryFM, containing the list of node coordinates and the element table which defines the mesh, as well as a number of derived properties (e.g. element coordinates) and methods making it convenient to work with the mesh.\n\n\n\n\n\n\n\nProperty\nDescription\n\n\n\n\nn_nodes\nNumber of nodes\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\ncodes\nCodes of all nodes (0:water, 1:land, &gt;=2:open boundary)\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\nn_elements\nNumber of elements\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nprojection_string\nThe projection string\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\ntype_name\nType name, e.g. Dfsu2D\n\n\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncontains()\ntest if a list of points are contained by mesh\n\n\nfind_index()\nFind index of elements containing points/area\n\n\nisel()\nGet subset geometry for list of indicies\n\n\nfind_nearest_points()\nFind index of nearest elements (optionally for a list)\n\n\nplot\nPlot the geometry\n\n\nget_overset_grid()\nGet a Grid2D covering the domain\n\n\nto_shapely()\nExport mesh as shapely MultiPolygon\n\n\nget_element_area()\nCalculate the horizontal area of each element\n\n\n\nThese properties and methods are accessible from the geometry, but also from the Mesh/Dfsu object.\nIf a .dfsu file is read with mikeio.read, the returned Dataset ds will contain a Flexible Mesh Geometry geometry. If a .dfsu or a .mesh file is opened with mikeio.open, the returned object will also contain a Flexible Mesh Geometry geometry.\n\nimport mikeio\n\nds = mikeio.read(\"../data/oresundHD_run1.dfsu\")\nds.geometry\n\nFlexible Mesh Geometry: Dfsu2D\nnumber of nodes: 2046\nnumber of elements: 3612\nprojection: UTM-33\n\n\n\ndfs = mikeio.open(\"../data/oresundHD_run1.dfsu\")\ndfs.geometry\n\nFlexible Mesh Geometry: Dfsu2D\nnumber of nodes: 2046\nnumber of elements: 3612\nprojection: UTM-33",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfsu and Mesh Overview"
    ]
  },
  {
    "objectID": "user-guide/dfsu.html#common-dfsu-and-mesh-properties",
    "href": "user-guide/dfsu.html#common-dfsu-and-mesh-properties",
    "title": "Dfsu and Mesh Overview",
    "section": "Common Dfsu and Mesh properties",
    "text": "Common Dfsu and Mesh properties\nMIKE IO has Dfsu classes for .dfsu files and a Mesh class for .mesh files which both have a mikeio.spatial.GeometryFM2D/mikeio.spatial.GeometryFM3D accessible through the ´geometry´ accessor.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfsu and Mesh Overview"
    ]
  },
  {
    "objectID": "user-guide/dfsu.html#dfsu-types",
    "href": "user-guide/dfsu.html#dfsu-types",
    "title": "Dfsu and Mesh Overview",
    "section": "Dfsu types",
    "text": "Dfsu types\nThe following dfsu file types are supported by MIKE IO.\n\n2D horizontal.\n3D layered.\n2D vertical profile - a vertical slice through a 3D layered file.\n1D vertical column - a vertical dfs1 file and is produced by taking out one column of a 3D layered file.\n3D/4D SW, two horizontal dimensions and 1-2 spectral dimensions. Output from MIKE 21 SW.\n\nWhen a dfsu file is opened with mikeio.open() the returned dfs object will be a specialized class Dfsu2DH, Dfsu3D, Dfsu2DV, or DfsuSpectral according to the type of dfsu file.\nThe layered files (3d, 2d/1d vertical) can have both sigma- and z-layers or only sigma-layers.\nIn most cases values are stored in cell centers and vertical (z) information in nodes, but the following values types exists:\n\nStandard value type, storing values on elements and/or nodes. This is the default type.\nFace value type, storing values on element faces. This is used e.g. for HD decoupling files, to store the discharge between elements.\nSpectral value type, for each node or element, storing vales for a number of frequencies and/or directions. This is the file type for spectral output from the MIKE 21 SW.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfsu and Mesh Overview"
    ]
  },
  {
    "objectID": "user-guide/eum.html",
    "href": "user-guide/eum.html",
    "title": "EUM",
    "section": "",
    "text": "The dfs items in MIKE IO are represented by the ItemInfo class. An ItemInfo consists of:\nThe ItemInfo class has some sensible defaults, thus you can specify only a name or a type. If you don’t specify a unit, the default unit for that type will be used.\nfrom mikeio import ItemInfo, EUMType, EUMUnit\n\nitem = ItemInfo(\"Viken\", EUMType.Water_Level)\nitem\n\nViken &lt;Water Level&gt; (meter)\nItemInfo(EUMType.Wind_speed)\n\nWind speed &lt;Wind speed&gt; (meter per sec)\nItemInfo(\"Viken\", EUMType.Water_Level, EUMUnit.feet)\n\nViken &lt;Water Level&gt; (feet)\nMatching units for specific type:\nEUMType.Wind_speed.units\n\n[meter per sec, feet per sec, knot, km per hour, miles per hour]\nDefault unit:\nEUMType.Precipitation_Rate.units[0]\n\nmm per day\nunit = EUMType.Precipitation_Rate.units[0]\nunit\n\nmm per day\ntype(unit)\n\n&lt;enum 'EUMUnit'&gt;\na [](mikeio.EUMUnit)` is encoded as integers, which you can utilize in some MIKE applications.\nint(unit)\n2004\n\n2004",
    "crumbs": [
      "Home",
      "User Guide",
      "EUM"
    ]
  },
  {
    "objectID": "user-guide/eum.html#eum-type-search",
    "href": "user-guide/eum.html#eum-type-search",
    "title": "EUM",
    "section": "EUM type search",
    "text": "EUM type search\nIt is also possible to do a string based search, e.g. to find all EUM types containing the substring ‘period’:\n\nEUMType.search(\"period\")\n\n[Wave period, Return period, Update Period, Threshold period]",
    "crumbs": [
      "Home",
      "User Guide",
      "EUM"
    ]
  },
  {
    "objectID": "user-guide/data-structures.html",
    "href": "user-guide/data-structures.html",
    "title": "Data Structures",
    "section": "",
    "text": "Data Structures\nMIKE IO has these primary data structures:\n\nDataset - a collection of DataArrays corresponding to the contents of a dfs file; typically obtained from {py:meth}mikeio.read\nDataArray - data and metadata corresponding to one “item” in a dfs file.\nGeometry - spatial description of the data in a dfs file; comes in different flavours: Grid1D, Grid2D, Grid3D, GeometryFM2, GeometryFM3D, etc. corresponding to different types of dfs files.\nDfs - an object returned by dfs = mikeio.open() containing the metadata (=header) of a dfs file ready for reading the data (which can be done with dfs.read()); exists in different specialized versions: Dfs0, Dfs1, Dfs2, Dfs3, Dfsu2DH, Dfsu3D, Dfsu2DV, DfsuSpectral.",
    "crumbs": [
      "Home",
      "User Guide",
      "Data Structures"
    ]
  },
  {
    "objectID": "user-guide/pfs.html",
    "href": "user-guide/pfs.html",
    "title": "PFS",
    "section": "",
    "text": "A PFS file is a text file with a tree structure that contains parameters and settings for MIKE tools and engines. MIKE IO can read, modify and create PFS files.",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/pfs.html#the-pfs-file",
    "href": "user-guide/pfs.html#the-pfs-file",
    "title": "PFS",
    "section": "The PFS file",
    "text": "The PFS file\nThe content of the PFS file is similar to a nested dictionary. The root element is often called the target. Some PFS files have multiple root elements. The below sections are called PFS Sections which can be nested and contain key-value pairs called keywords and parameters.\n1[TARGET1]\n   keywordA = parameterA\n   [SECTION1]\n      keywordB = parameterB\n      keywordC = parameterC\n      [SECTION2]\n         keywordD = parameterD\n      EndSect  // SECTION2\n   EndSect  // SECTION1\nEndSect  // TARGET1\n\n2[TARGET2]\n   keywordE = parameterE\n   [SECTION3]\n      keywordF = parameterF\n   EndSect  // SECTION3\nEndSect  // TARGET2\n\n1\n\nFirst target, access this part with pfs.targets[0]\n\n2\n\nSecond target, access this part with pfs.targets[1]\n\n\n\n\n\n\n\n\nNote\n\n\n\nComments // is used to add comments to the PFS file (e.g. // SECTION2), the comments are ignored by MIKE IO.",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/pfs.html#read",
    "href": "user-guide/pfs.html#read",
    "title": "PFS",
    "section": "Read",
    "text": "Read\nWhen a PFS file is read with MIKE IO, a PfsDocument object is created. It will contain one or more PfsSection objects - one for each target. The PfsSections will typically contain other PfsSections together with a number of key-value pairs.\nA PFS file is read using mikeio.read_pfs:\n\nimport mikeio\n\npfs = mikeio.read_pfs(\"../data/pfs/concat.mzt\")\npfs\n\n[txconc]\n   CLSID = 'TxConc.dll'\n   TypeName = 'txconc'\n   CREATEDTIME = '2020-03-11T15:24:45'\n   MODIFIEDTIME = '2020-03-11T15:24:45'\n   NOTES = ''\n   [Setup]\n      Name = 'Setup Name'\n      NumberFiles = 2\n      NumberDimensions = 1\n      NumberItems = 1\n      InsertDelIfGabs = 0\n      UseTimeRange = 1\n      TimeRange = 0, 145, 1\n      FirstFileTimeDef = 0\n      OverwriteWithLatest = 1\n      [File_1]\n         InputFile = |.\\tide1.dfs1|\n         Items = 1\n      EndSect  // File_1\n      [File_2]\n         InputFile = |.\\tide2.dfs1|\n         Items = 1\n      EndSect  // File_2\n      [File_Out]\n         OutputFile = |.\\txconc.dfs1|\n         OutputFileTitle = ''\n      EndSect  // File_Out\n   EndSect  // Setup\nEndSect  // txconc\n\n\n\nPfsDocument\nThe mikeio.PfsDocument is the MIKE IO equivalent to a PFS file. Its targets can be accessed by their name (as properties), like this:\n\npfs.txconc\n\nCLSID = 'TxConc.dll'\nTypeName = 'txconc'\nCREATEDTIME = '2020-03-11T15:24:45'\nMODIFIEDTIME = '2020-03-11T15:24:45'\nNOTES = ''\n[Setup]\n   Name = 'Setup Name'\n   NumberFiles = 2\n   NumberDimensions = 1\n   NumberItems = 1\n   InsertDelIfGabs = 0\n   UseTimeRange = 1\n   TimeRange = 0, 145, 1\n   FirstFileTimeDef = 0\n   OverwriteWithLatest = 1\n   [File_1]\n      InputFile = |.\\tide1.dfs1|\n      Items = 1\n   EndSect  // File_1\n   [File_2]\n      InputFile = |.\\tide2.dfs1|\n      Items = 1\n   EndSect  // File_2\n   [File_Out]\n      OutputFile = |.\\txconc.dfs1|\n      OutputFileTitle = ''\n   EndSect  // File_Out\nEndSect  // Setup\n\n\nOr by the pfs.targets object (which is a list of PfsSections). Each of the targets is a PfsSection object consisting of key-value pairs (keyword-parameter) and other PfsSections.\nThe mikeio.PfsDocument object is similar to a dictionary. You can loop over its contents with items(), keys() and values() like a dictionary.\n\n\nPfsSection\nThe mikeio.PfsSection object is also similar to a dictionary. You can loop over its contents with items(), keys() and values() like a dictionary.\n\npfs.txconc.keys()\n\ndict_keys(['CLSID', 'TypeName', 'CREATEDTIME', 'MODIFIEDTIME', 'NOTES', 'Setup'])\n\n\nYou can access a specific parameter with the get() method:\n\npfs.txconc.get(\"CLSID\")\n\n'TxConc.dll'\n\n\nOr as a property with dot-notation—which is prefered in most cases as it is more readable:\n\npfs.txconc.CLSID\n\n'TxConc.dll'\n\n\nA PfsSection can be converted to a dictionary with the to_dict() method:\n\npfs.txconc.Setup.File_1.to_dict()\n\n{'InputFile': '|.\\\\tide1.dfs1|', 'Items': 1}\n\n\nIf a PfsSection contains enumerated subsections, they can be converted to a pandas DataFrame with the to_dataframe() method:\n\npfs.txconc.Setup.to_dataframe(prefix=\"File_\")\n\n\n\n\n\n\n\n\n\nInputFile\nItems\n\n\n\n\n1\n|.\\tide1.dfs1|\n1\n\n\n2\n|.\\tide2.dfs1|\n1\n\n\n\n\n\n\n\n\n\n\nUnique or non-unique keywords\nDepending on the engine intended for reading the PFS file it may or may not make sense to have multiple identical keywords in the same PfsSection. MIKE 21/3 and the marine tools does not support non-unique keywords—if non-unique keywords are present, only the first will be read and the presence is most likely a mistake made by hand-editing the file. In other tools, e.g. MIKE Plot Composer, non-unique keywords are used a lot. How MIKE IO shall deal with non-unique keywords can be specified using the unique_keywords argument in the mikeio.read_pfs function:\npfs = mikeio.read_pfs(\"myplot.plt\", unique_keywords=False)\nIf a PfsSection contains non-unique PfsSections or keywords and unique_keywords=False, the repeated key will only appear once and the corresponding value will be a list.",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/pfs.html#update",
    "href": "user-guide/pfs.html#update",
    "title": "PFS",
    "section": "Update",
    "text": "Update\nThe PfsSection object can be modified. Existing values can be changed, new key-value pairs can be added, subsections can added or removed.\n\nModify existing keyword\nIt is very simple to modify an existing keyword:\npfs.txconc.Setup.Name = \"new name\"\n\n\nAdd new key-value pair\nA new key-value pair can be added, like in a dictionary, in this way:\npfs.txconc.Setup[\"NewKeyword\"] = 12.0\n\n\nAdd new section as a copy of another section\nOften a PfsSection is added using an existing PfsSection as a template.\ns = pfs.txconc.Setup.File_1.copy()\ns.InputFile = '|.\\tide3.dfs1|'\npfs.txconc.Setup[\"File_3\"] = s\n\n\nAdd new section from a dictionary\nA PfsSection can be created from a dictionary and then added to another PfsSection like any other key-value pair:\n\nd = {'InputFile': '|.\\\\tide4.dfs1|', 'Items': 1}\ns = mikeio.PfsSection(d)\npfs.txconc.Setup[\"File_4\"] = s",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/pfs.html#write-to-file",
    "href": "user-guide/pfs.html#write-to-file",
    "title": "PFS",
    "section": "Write to file",
    "text": "Write to file\nA Pfs document can be written to a file using the write method.\npfs.write(\"new.pfs\")",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/pfs.html#create-new-pfs-files",
    "href": "user-guide/pfs.html#create-new-pfs-files",
    "title": "PFS",
    "section": "Create new Pfs files",
    "text": "Create new Pfs files\nA new PFS file can be created from dictionary in the following way:\n\nd = dict(\n    key1=1,\n    lst=[0.3, 0.7],\n    file_name=r\"|path\\file.dfs0|\",\n    start_time=[2019, 7, 1, 0, 0, 0],\n)\npfs = mikeio.PfsDocument({\"MYTOOL\": d})\npfs\n\n[MYTOOL]\n   key1 = 1\n   lst = 0.3, 0.7\n   file_name = |path\\file.dfs0|\n   start_time = 2019, 7, 1, 0, 0, 0\nEndSect  // MYTOOL\n\n\nMultiple targets can be achieved by providing list of dictionaries, in this way you can create a PFS file with multiple targets for the same tool.\n\nt1 = {\"file_name\": r\"|path\\file1.dfs0|\"}\nt2 = {\"file_name\": r\"|path\\file2.dfs0|\"}\n\npfs = mikeio.PfsDocument([t1, t2], names=[\"ATOOL\", \"ATOOL\"])\npfs\n\n[ATOOL]\n   file_name = |path\\file1.dfs0|\nEndSect  // ATOOL\n[ATOOL]\n   file_name = |path\\file2.dfs0|\nEndSect  // ATOOL",
    "crumbs": [
      "Home",
      "User Guide",
      "PFS"
    ]
  },
  {
    "objectID": "user-guide/dfs1.html",
    "href": "user-guide/dfs1.html",
    "title": "Dfs1",
    "section": "",
    "text": "A dfs1 file contains node-based line series data. Dfs1 files do not contain enough metadata to determine their geographical position, but have a relative distance from the origo.\nimport mikeio\n\nds = mikeio.read(\"../data/tide1.dfs1\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:97, x:10)\ntime: 2019-01-01 00:00:00 - 2019-01-03 00:00:00 (97 records)\ngeometry: Grid1D (n=10, dx=0.06667)\nitems:\n  0:  Level &lt;Water Level&gt; (meter)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs1"
    ]
  },
  {
    "objectID": "user-guide/dfs1.html#grid-1d",
    "href": "user-guide/dfs1.html#grid-1d",
    "title": "Dfs1",
    "section": "Grid 1D",
    "text": "Grid 1D\nThe spatial information is available in the geometry attribute (accessible from Dfs1, Dataset, and DataArray), which in the case of a dfs1 file is a Grid1D geometry.\n\nds.geometry\n\n&lt;mikeio.Grid1D&gt;\nx: [0, 0.06667, ..., 0.6] (nx=10, dx=0.06667)\n\n\nGrid1D’s primary properties and methods are:\n\nx\nnx\ndx\nfind_index()\nisel()\n\nSee API specification for details.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs1"
    ]
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "Design philosophy",
    "section": "",
    "text": "Common operations such as reading a file should only need a few lines of code.\nMake extensive use of existing standard libraries for scientific computing such as numpy, matplotlib and pandas.\n\n\n\nMIKE IO aims to use a syntax familiar to users of scientific computing libraries such as NumPy, Pandas and xarray.\n\n\n\n$ pip install mikeio\n\n\n\nBy providing many examples to cut/paste from.\nExamples are available in two forms:\n\nExample notebooks\nUnit tests\n\n\n\n\nMIKE IO is an open source project licensed under the BSD-3 license. The software is provided free of charge with the source code available for inspection and modification.\nContributions are welcome, more details can be found in our contribution guidelines.\n\n\n\nBy developing MIKE IO on GitHub along with a completely open discussion, we believe that the collaboration between developers and end-users results in a useful library.\n\n\n\nBy providing the historical versions of MIKE IO on PyPI it is possible to reproduce the behaviour of an older existing system, based on an older version.\nInstall specific version\npip install mikeio==1.4.0\n\n\n\nFeatures are being added all the time, by developers at DHI in offices all around the globe as well as external contributors using MIKE IO in their work. These new features are always available from the main branch on GitHub and thanks to automated testing, it is always possible to verify that the tests passes before downloading a new development version.\nInstall development version\n$ pip install https://github.com/DHI/mikeio/archive/main.zip",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#easy-to-use",
    "href": "design.html#easy-to-use",
    "title": "Design philosophy",
    "section": "",
    "text": "Common operations such as reading a file should only need a few lines of code.\nMake extensive use of existing standard libraries for scientific computing such as numpy, matplotlib and pandas.",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#familiar",
    "href": "design.html#familiar",
    "title": "Design philosophy",
    "section": "",
    "text": "MIKE IO aims to use a syntax familiar to users of scientific computing libraries such as NumPy, Pandas and xarray.",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#easy-to-install",
    "href": "design.html#easy-to-install",
    "title": "Design philosophy",
    "section": "",
    "text": "$ pip install mikeio",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#easy-to-get-started",
    "href": "design.html#easy-to-get-started",
    "title": "Design philosophy",
    "section": "",
    "text": "By providing many examples to cut/paste from.\nExamples are available in two forms:\n\nExample notebooks\nUnit tests",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#open-source",
    "href": "design.html#open-source",
    "title": "Design philosophy",
    "section": "",
    "text": "MIKE IO is an open source project licensed under the BSD-3 license. The software is provided free of charge with the source code available for inspection and modification.\nContributions are welcome, more details can be found in our contribution guidelines.",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#easy-to-collaborate",
    "href": "design.html#easy-to-collaborate",
    "title": "Design philosophy",
    "section": "",
    "text": "By developing MIKE IO on GitHub along with a completely open discussion, we believe that the collaboration between developers and end-users results in a useful library.",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#reproducible",
    "href": "design.html#reproducible",
    "title": "Design philosophy",
    "section": "",
    "text": "By providing the historical versions of MIKE IO on PyPI it is possible to reproduce the behaviour of an older existing system, based on an older version.\nInstall specific version\npip install mikeio==1.4.0",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "design.html#easy-access-to-new-features",
    "href": "design.html#easy-access-to-new-features",
    "title": "Design philosophy",
    "section": "",
    "text": "Features are being added all the time, by developers at DHI in offices all around the globe as well as external contributors using MIKE IO in their work. These new features are always available from the main branch on GitHub and thanks to automated testing, it is always possible to verify that the tests passes before downloading a new development version.\nInstall development version\n$ pip install https://github.com/DHI/mikeio/archive/main.zip",
    "crumbs": [
      "Home",
      "Design philosophy"
    ]
  },
  {
    "objectID": "user-guide/dfs2.html",
    "href": "user-guide/dfs2.html",
    "title": "Dfs2",
    "section": "",
    "text": "A dfs2 file is also called a grid series file. Values in a dfs2 file are ‘element based’, i.e. values are defined in the centre of each grid cell.\nimport mikeio\nds = mikeio.read(\"../data/gebco_sound.dfs2\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:1, y:264, x:216)\ntime: 2020-05-15 11:04:52 (time-invariant)\ngeometry: Grid2D (ny=264, nx=216)\nitems:\n  0:  Elevation &lt;Total Water Depth&gt; (meter)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs2"
    ]
  },
  {
    "objectID": "user-guide/dfs2.html#subset-in-space",
    "href": "user-guide/dfs2.html#subset-in-space",
    "title": "Dfs2",
    "section": "Subset in space",
    "text": "Subset in space\nThe most convenient way to subset in space is to use the sel method, which returns a new (smaller) dataset, which can be further processed or written to disk using the to_dfs method.\n\nds.geometry\n\n&lt;mikeio.Grid2D&gt;\nx: [12.2, 12.21, ..., 13.1] (nx=216, dx=0.004167)\ny: [55.2, 55.21, ..., 56.3] (ny=264, dy=0.004167)\nprojection: LONG/LAT\n\n\n\nds_aoi = ds.sel(x=slice(12.5, 13.0), y=slice(55.5, 56.0))\nds_aoi.geometry\n\n&lt;mikeio.Grid2D&gt;\nx: [12.5, 12.5, ..., 12.99] (nx=120, dx=0.004167)\ny: [55.5, 55.5, ..., 55.99] (ny=120, dy=0.004167)\nprojection: LONG/LAT\n\n\nIn order to specify an open-ended subset (i.e. where the end of the subset is the end of the domain), use None as the end of the slice.\n\nds.sel(x=slice(None, 13.0))\n\n&lt;mikeio.Dataset&gt;\ndims: (time:1, y:264, x:191)\ntime: 2020-05-15 11:04:52 (time-invariant)\ngeometry: Grid2D (ny=264, nx=191)\nitems:\n  0:  Elevation &lt;Total Water Depth&gt; (meter)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs2"
    ]
  },
  {
    "objectID": "user-guide/dfs2.html#grid2d",
    "href": "user-guide/dfs2.html#grid2d",
    "title": "Dfs2",
    "section": "Grid2D",
    "text": "Grid2D\nThe spatial information is available in the geometry attribute (accessible from Dfs2, Dataset, and DataArray), which in the case of a dfs2 file is a Grid2D geometry.\n\nds.geometry\n\n&lt;mikeio.Grid2D&gt;\nx: [12.2, 12.21, ..., 13.1] (nx=216, dx=0.004167)\ny: [55.2, 55.21, ..., 56.3] (ny=264, dy=0.004167)\nprojection: LONG/LAT\n\n\nGrid2D’s primary properties and methods are:\n\nx\nnx\ndx\ny\nny\ndy\norigin\nprojection\nxy\nbbox\ncontains()\nfind_index()\nisel()\nto_mesh()\n\nSee API specification for details.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs2"
    ]
  },
  {
    "objectID": "user-guide/dfs2.html#dfs2-resources",
    "href": "user-guide/dfs2.html#dfs2-resources",
    "title": "Dfs2",
    "section": "Dfs2 resources",
    "text": "Dfs2 resources\n\nDfs2 | getting-started-with-mikeio\nDfs2-Bathymetry - GEBCO NetCDF/xarray to dfs2\nDfs2-GFS - GFS NetCDF/xarray to dfs2",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs2"
    ]
  },
  {
    "objectID": "user-guide/dfs0.html",
    "href": "user-guide/dfs0.html",
    "title": "Dfs0",
    "section": "",
    "text": "A dfs0 file is also called a time series file.\nWorking with data from dfs0 files are conveniently done in one of two ways:",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs0"
    ]
  },
  {
    "objectID": "user-guide/dfs0.html#read-dfs0-to-dataset",
    "href": "user-guide/dfs0.html#read-dfs0-to-dataset",
    "title": "Dfs0",
    "section": "Read Dfs0 to Dataset",
    "text": "Read Dfs0 to Dataset\n\nimport mikeio\n\nds = mikeio.read(\"../data/da_diagnostic.dfs0\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:744)\ntime: 2017-10-27 00:00:00 - 2017-10-29 18:00:00 (744 non-equidistant records)\ngeometry: GeometryUndefined()\nitems:\n  0:  State 1Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  1:  State 2Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  2:  Mean StateSign. Wave Height &lt;Significant wave height&gt; (meter)\n  3:  MeasurementSign. Wave Height &lt;Significant wave height&gt; (meter)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs0"
    ]
  },
  {
    "objectID": "user-guide/dfs0.html#from-dfs0-to-pandas-dataframe",
    "href": "user-guide/dfs0.html#from-dfs0-to-pandas-dataframe",
    "title": "Dfs0",
    "section": "From Dfs0 to pandas DataFrame",
    "text": "From Dfs0 to pandas DataFrame\n\ndf = ds.to_dataframe()\ndf.head()\n\n\n\n\n\n\n\n\n\nState 1Sign. Wave Height\nState 2Sign. Wave Height\nMean StateSign. Wave Height\nMeasurementSign. Wave Height\n\n\n\n\n2017-10-27 00:00:00\n1.749465\n1.749465\n1.749465\n1.72\n\n\n2017-10-27 00:10:00\n1.811340\n1.796895\n1.807738\nNaN\n\n\n2017-10-27 00:20:00\n1.863424\n1.842759\n1.853422\nNaN\n\n\n2017-10-27 00:30:00\n1.922261\n1.889839\n1.897670\nNaN\n\n\n2017-10-27 00:40:00\n1.972455\n1.934886\n1.935281\nNaN",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs0"
    ]
  },
  {
    "objectID": "user-guide/dfs0.html#from-pandas-dataframe-to-dfs0",
    "href": "user-guide/dfs0.html#from-pandas-dataframe-to-dfs0",
    "title": "Dfs0",
    "section": "From pandas DataFrame to Dfs0",
    "text": "From pandas DataFrame to Dfs0\n\n\n\n\n\n\nNote\n\n\n\nMIKE IO adds a new method to the DataFrame called to_dfs0. This method is used to save the DataFrame to a dfs0 file. (This method becomes available after importing the mikeio module.)\n\n\n\nimport pandas as pd\n\ndf = pd.read_csv(\n    \"../data/co2-mm-mlo.csv\", parse_dates=True, index_col=\"Date\", na_values=-99.99\n)\ndf.to_dfs0(\"mauna_loa_co2.dfs0\")",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs0"
    ]
  },
  {
    "objectID": "user-guide/dfs0.html#dfs0-example-notebooks",
    "href": "user-guide/dfs0.html#dfs0-example-notebooks",
    "title": "Dfs0",
    "section": "Dfs0 example notebooks",
    "text": "Dfs0 example notebooks\n\nDfs0 - read, write, to_dataframe, non-equidistant, accumulated timestep, extrapolation\nDfs0 Relative-time - read file with relative time axis\nDfs0 | getting-started-with-mikeio - Course literature",
    "crumbs": [
      "Home",
      "User Guide",
      "Dfs0"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html",
    "href": "user-guide/dataarray.html",
    "title": "DataArray",
    "section": "",
    "text": "The DataArray is the common MIKE IO data structure for item data from dfs files. The mikeio.read methods returns a Dataset as a container of DataArrays (Dfs items)\nEach DataArray have the following properties:\nUse DataArray’s string representation to get an overview of the DataArray\nimport mikeio\n\nds = mikeio.read(\"../data/HD2D.dfsu\")\nda = ds[\"Surface elevation\"]\nda\n\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:9, element:884)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#temporal-selection",
    "href": "user-guide/dataarray.html#temporal-selection",
    "title": "DataArray",
    "section": " Temporal selection",
    "text": "Temporal selection\n\nda.sel(time=\"1985-08-06 12:00\")\n\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (element:884)\ntime: 1985-08-06 12:00:00 (time-invariant)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nvalues: [0.1012, 0.1012, ..., 0.105]\n\n\n\nda[\"1985-8-7\":]\n\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:2, element:884)\ntime: 1985-08-07 00:30:00 - 1985-08-07 03:00:00 (2 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#spatial-selection",
    "href": "user-guide/dataarray.html#spatial-selection",
    "title": "DataArray",
    "section": " Spatial selection",
    "text": "Spatial selection\nThe sel method finds the nearest element.\n\nda.sel(x=607002, y=6906734)\n\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:9)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: GeometryPoint2D(x=607002.7094112666, y=6906734.833048992)\nvalues: [0.4591, 0.8078, ..., -0.6311]",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#modifying-values",
    "href": "user-guide/dataarray.html#modifying-values",
    "title": "DataArray",
    "section": "Modifying values",
    "text": "Modifying values\nYou can modify the values of a DataArray by changing its values:\n\nda.values[0, 3] = 5.0\n\nIf you wish to change values of a subset of the DataArray you should be aware of the difference between a view and a copy of the data. Similar to NumPy, MIKE IO selection method will return a view of the data when using single index and slices, but a copy of the data using fancy indexing (a list of indicies or boolean indexing). Note that prior to release 1.3, MIKE IO would always return a copy.\nIt is recommended to change the values using values property directly on the original DataArray (like above), but it is also possible to change the values of the original DataArray by working on a subset DataArray if it is selected with single index or slice as explained above.\n\nda_sub = da.isel(time=0)\nda_sub.values[:] = 5.0    # will change da\n\nFancy indexing will return a copy and therefore not change the original:\n\nda_sub = da.isel(time=[0,1,2])\nda_sub.values[:] = 5.0    # will NOT change da",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#plotting",
    "href": "user-guide/dataarray.html#plotting",
    "title": "DataArray",
    "section": " Plotting",
    "text": "Plotting\nThe plotting of a DataArray is context-aware meaning that plotting behaviour depends on the geometry of the DataArray being plotted.\n\nda.plot()\n\n\n\n\n\n\n\n\n\nda.plot.contourf()\n\n\n\n\n\n\n\n\n\nda.plot.mesh()\n\n\n\n\n\n\n\n\nSee details in the API specification below and in the bottom of the relevant pages e.g. DataArray Plotter Grid2D API.",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#properties",
    "href": "user-guide/dataarray.html#properties",
    "title": "DataArray",
    "section": "Properties",
    "text": "Properties\nThe DataArray has several properties:\n\nn_items - Number of items\nn_timesteps - Number of timesteps\nn_elements - Number of elements\nstart_time - First time instance (as datetime)\nend_time - Last time instance (as datetime)\nis_equidistant - Is the time series equidistant in time\ntimestep - Time step in seconds (if is_equidistant)\nshape - Shape of each item\ndeletevalue - File delete value (NaN value)",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/dataarray.html#methods",
    "href": "user-guide/dataarray.html#methods",
    "title": "DataArray",
    "section": "Methods",
    "text": "Methods\nDataArray has several useful methods for working with data, including different ways of selecting data:\n\nsel() - Select subset along an axis\nisel() - Select subset along an axis with an integer\n\n\nAggregations along an axis\n\nmean() - Mean value along an axis\nnanmean() - Mean value along an axis (NaN removed)\nmax() - Max value along an axis\nnanmax() - Max value along an axis (NaN removed)\nmin() - Min value along an axis\nnanmin() - Min value along an axis (NaN removed)\naggregate() - Aggregate along an axis\nquantile() - Quantiles along an axis\n\n\n\n Mathematical operations\n\nds + value\nds - value\nds * value\n\nand + and - between two DataArrays (if number of items and shapes conform):\n\nds1 + ds2\nds1 - ds2\n\nOther methods that also return a DataArray:\n\ninterp_like - Spatio (temporal) interpolation (see example Dfsu interpolation)\ninterp_time() - Temporal interpolation (see example Time interpolation)\ndropna() - Remove time steps where all items are NaN\nsqueeze() - Remove axes of length 1\n\n\n\nConversion:\n\nto_xarray() - Convert DataArray to a xarray DataArray (great for Dfs2)\nto_dfs() - Write DataArray to a Dfs file",
    "crumbs": [
      "Home",
      "User Guide",
      "DataArray"
    ]
  },
  {
    "objectID": "user-guide/generic.html",
    "href": "user-guide/generic.html",
    "title": "Generic",
    "section": "",
    "text": "The generic module contains functionality that works for all types of dfs (dfs0, dfs1, dfs2, dfs3, dfsu) files:\n\nconcat() - Concatenates files along the time axis\nextract() - Extract timesteps and/or items to a new dfs file\ndiff() - Calculate difference between two dfs files with identical geometry\nsum() - Calculate the sum of two dfs files\nscale() - Apply scaling to any dfs file\navg_time() - Create a temporally averaged dfs file\nquantile() - Create a dfs file with temporal quantiles\n\n\n\n\nThe processing is not tied to the spatial dimension of the data\nWhen the files are large and you want to avoid reading the entire file into memory\n\n\n\n\n\nWhen you need processing depending on the spatial information in the file. For example, spatial interpolation, subsetting, etc.\nWhen you need more complex processing, not covered by the generic module\nWhen the input files data are not dfs files\nWhen the end result is not a dfs file\n\n\n\n\n&gt;&gt;&gt; from mikeio import generic\n&gt;&gt;&gt; generic.concat([\"fileA.dfs2\", \"fileB.dfs2\"], \"new_file.dfs2\")\n\n\n\nSee the Generic notebook for more examples.",
    "crumbs": [
      "Home",
      "User Guide",
      "Generic"
    ]
  },
  {
    "objectID": "user-guide/generic.html#when-to-use-the-generic-module",
    "href": "user-guide/generic.html#when-to-use-the-generic-module",
    "title": "Generic",
    "section": "",
    "text": "The processing is not tied to the spatial dimension of the data\nWhen the files are large and you want to avoid reading the entire file into memory",
    "crumbs": [
      "Home",
      "User Guide",
      "Generic"
    ]
  },
  {
    "objectID": "user-guide/generic.html#when-not-to-use-the-generic-module",
    "href": "user-guide/generic.html#when-not-to-use-the-generic-module",
    "title": "Generic",
    "section": "",
    "text": "When you need processing depending on the spatial information in the file. For example, spatial interpolation, subsetting, etc.\nWhen you need more complex processing, not covered by the generic module\nWhen the input files data are not dfs files\nWhen the end result is not a dfs file",
    "crumbs": [
      "Home",
      "User Guide",
      "Generic"
    ]
  },
  {
    "objectID": "user-guide/generic.html#example",
    "href": "user-guide/generic.html#example",
    "title": "Generic",
    "section": "",
    "text": "&gt;&gt;&gt; from mikeio import generic\n&gt;&gt;&gt; generic.concat([\"fileA.dfs2\", \"fileB.dfs2\"], \"new_file.dfs2\")",
    "crumbs": [
      "Home",
      "User Guide",
      "Generic"
    ]
  },
  {
    "objectID": "user-guide/generic.html#more-examples",
    "href": "user-guide/generic.html#more-examples",
    "title": "Generic",
    "section": "",
    "text": "See the Generic notebook for more examples.",
    "crumbs": [
      "Home",
      "User Guide",
      "Generic"
    ]
  },
  {
    "objectID": "user-guide/dataset.html",
    "href": "user-guide/dataset.html",
    "title": "Dataset",
    "section": "",
    "text": "The Dataset is the MIKE IO data structure for data from dfs files. The mikeio.read methods returns a Dataset as a container of DataArray (Dfs items). Each DataArray has the properties, item, time, geometry and values. The time and geometry are common to all DataArrays in the Dataset.\nThe Dataset has the following primary properties:\n\nitems - a list of mikeio.ItemInfo items for each dataarray\ntime - a pandas.DatetimeIndex with the time instances of the data\ngeometry - a Geometry object with the spatial description of the data\n\nUse Dataset’s string representation to get an overview of the Dataset\n&gt;&gt;&gt; import mikeio\n&gt;&gt;&gt; ds = mikeio.read(\"testdata/HD2D.dfsu\")\n&gt;&gt;&gt; ds\n&lt;mikeio.Dataset&gt;\ndims: (time:9, element:884)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)\n\n\nSelecting a specific item “itemA” (at position 0) from a Dataset ds can be done with:\n\nds[[\"itemA\"]] - returns a new Dataset with “itemA”\nds[\"itemA\"] - returns “itemA” DataArray\nds[[0]] - returns a new Dataset with “itemA”\nds[0] - returns “itemA” DataArray\nds.itemA - returns “itemA” DataArray\n\nWe recommend the use named items for readability.\n&gt;&gt;&gt; ds.Surface_elevation\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:9, element:884)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nNegative index e.g. ds[-1] can also be used to select from the end. Several items (“itemA” at 0 and “itemC” at 2) can be selected with the notation:\n\nds[[\"itemA\", \"itemC\"]]\nds[[0, 2]]\n\nNote that this behavior is similar to pandas and xarray.\n\n\n\nA time slice of a Dataset can be selected in several different ways.\n&gt;&gt;&gt; ds.sel(time=\"1985-08-06 12:00\")\n&lt;mikeio.Dataset&gt;\ndims: (element:884)\ntime: 1985-08-06 12:00:00 (time-invariant)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)\n\n&gt;&gt;&gt; ds[\"1985-8-7\":]\n&lt;mikeio.Dataset&gt;\ndims: (time:2, element:884)\ntime: 1985-08-07 00:30:00 - 1985-08-07 03:00:00 (2 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)\n\n\n\nThe sel method finds the nearest element.\n&gt;&gt;&gt; ds.sel(x=607002, y=6906734)\n&lt;mikeio.Dataset&gt;\ndims: (time:9)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: GeometryPoint2D(x=607002.7094112666, y=6906734.833048992)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)\n\n\n\nIn most cases, you will not plot the Dataset, but rather it’s DataArrays. But there are two exceptions:\n\ndfs0-Dataset : plot all items as timeseries with ds.plot()\nscatter : compare two items using ds.plot.scatter(x=“itemA”, y=“itemB”)\n\nSee details in the Dataset Plotter API.\n\n\n\nThe Dataset (and DataArray) has several properties:\n\nn_items - Number of items\nn_timesteps - Number of timesteps\nn_elements - Number of elements\nstart_time - First time instance (as datetime)\nend_time - Last time instance (as datetime)\nis_equidistant - Is the time series equidistant in time\ntimestep - Time step in seconds (if is_equidistant)\nshape - Shape of each item\ndeletevalue - File delete value (NaN value)\n\n\n\n\nDataset (and DataArray) has several useful methods for working with data, including different ways of selecting data:\n\nsel() - Select subset along an axis\nisel() - Select subset along an axis with an integer\n\nAggregations along an axis:\n\nmean() - Mean value along an axis\nnanmean() - Mean value along an axis (NaN removed)\nmax() - Max value along an axis\nnanmax() - Max value along an axis (NaN removed)\nmin() - Min value along an axis\nnanmin() - Min value along an axis (NaN removed)\naverage() - Compute the weighted average along the specified axis.\naggregate() - Aggregate along an axis\nquantile() - Quantiles along an axis\nnanquantile() - Quantiles along an axis (NaN ignored)\n\n\n\n\nds + value\nds - value\nds * value\n\nand + and - between two Datasets (if number of items and shapes conform):\n\nds1 + ds2\nds1 - ds2\n\nOther methods that also return a Dataset:\n\ninterp_like - Spatio (temporal) interpolation (see Dfsu interpolation notebook)\ninterp_time() - Temporal interpolation (see Time interpolation notebook)\ndropna() - Remove time steps where all items are NaN\nsqueeze() - Remove axes of length 1\n\n\n\n\n\nto_dataframe() - Convert Dataset to a pandas.DataFrame.\nto_xarray() - Convert Dataset to a xarray.Dataset (great for Dfs2, Dfs3).\nto_dfs() - Write Dataset to a Dfs file",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#selecting-items",
    "href": "user-guide/dataset.html#selecting-items",
    "title": "Dataset",
    "section": "",
    "text": "Selecting a specific item “itemA” (at position 0) from a Dataset ds can be done with:\n\nds[[\"itemA\"]] - returns a new Dataset with “itemA”\nds[\"itemA\"] - returns “itemA” DataArray\nds[[0]] - returns a new Dataset with “itemA”\nds[0] - returns “itemA” DataArray\nds.itemA - returns “itemA” DataArray\n\nWe recommend the use named items for readability.\n&gt;&gt;&gt; ds.Surface_elevation\n&lt;mikeio.DataArray&gt;\nname: Surface elevation\ndims: (time:9, element:884)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nNegative index e.g. ds[-1] can also be used to select from the end. Several items (“itemA” at 0 and “itemC” at 2) can be selected with the notation:\n\nds[[\"itemA\", \"itemC\"]]\nds[[0, 2]]\n\nNote that this behavior is similar to pandas and xarray.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#temporal-selection",
    "href": "user-guide/dataset.html#temporal-selection",
    "title": "Dataset",
    "section": "",
    "text": "A time slice of a Dataset can be selected in several different ways.\n&gt;&gt;&gt; ds.sel(time=\"1985-08-06 12:00\")\n&lt;mikeio.Dataset&gt;\ndims: (element:884)\ntime: 1985-08-06 12:00:00 (time-invariant)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)\n\n&gt;&gt;&gt; ds[\"1985-8-7\":]\n&lt;mikeio.Dataset&gt;\ndims: (time:2, element:884)\ntime: 1985-08-07 00:30:00 - 1985-08-07 03:00:00 (2 records)\ngeometry: Dfsu2D (884 elements, 529 nodes)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#spatial-selection",
    "href": "user-guide/dataset.html#spatial-selection",
    "title": "Dataset",
    "section": "",
    "text": "The sel method finds the nearest element.\n&gt;&gt;&gt; ds.sel(x=607002, y=6906734)\n&lt;mikeio.Dataset&gt;\ndims: (time:9)\ntime: 1985-08-06 07:00:00 - 1985-08-07 03:00:00 (9 records)\ngeometry: GeometryPoint2D(x=607002.7094112666, y=6906734.833048992)\nitems:\n  0:  Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  U velocity &lt;u velocity component&gt; (meter per sec)\n  2:  V velocity &lt;v velocity component&gt; (meter per sec)\n  3:  Current speed &lt;Current Speed&gt; (meter per sec)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#plotting",
    "href": "user-guide/dataset.html#plotting",
    "title": "Dataset",
    "section": "",
    "text": "In most cases, you will not plot the Dataset, but rather it’s DataArrays. But there are two exceptions:\n\ndfs0-Dataset : plot all items as timeseries with ds.plot()\nscatter : compare two items using ds.plot.scatter(x=“itemA”, y=“itemB”)\n\nSee details in the Dataset Plotter API.",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#properties",
    "href": "user-guide/dataset.html#properties",
    "title": "Dataset",
    "section": "",
    "text": "The Dataset (and DataArray) has several properties:\n\nn_items - Number of items\nn_timesteps - Number of timesteps\nn_elements - Number of elements\nstart_time - First time instance (as datetime)\nend_time - Last time instance (as datetime)\nis_equidistant - Is the time series equidistant in time\ntimestep - Time step in seconds (if is_equidistant)\nshape - Shape of each item\ndeletevalue - File delete value (NaN value)",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/dataset.html#methods",
    "href": "user-guide/dataset.html#methods",
    "title": "Dataset",
    "section": "",
    "text": "Dataset (and DataArray) has several useful methods for working with data, including different ways of selecting data:\n\nsel() - Select subset along an axis\nisel() - Select subset along an axis with an integer\n\nAggregations along an axis:\n\nmean() - Mean value along an axis\nnanmean() - Mean value along an axis (NaN removed)\nmax() - Max value along an axis\nnanmax() - Max value along an axis (NaN removed)\nmin() - Min value along an axis\nnanmin() - Min value along an axis (NaN removed)\naverage() - Compute the weighted average along the specified axis.\naggregate() - Aggregate along an axis\nquantile() - Quantiles along an axis\nnanquantile() - Quantiles along an axis (NaN ignored)\n\n\n\n\nds + value\nds - value\nds * value\n\nand + and - between two Datasets (if number of items and shapes conform):\n\nds1 + ds2\nds1 - ds2\n\nOther methods that also return a Dataset:\n\ninterp_like - Spatio (temporal) interpolation (see Dfsu interpolation notebook)\ninterp_time() - Temporal interpolation (see Time interpolation notebook)\ndropna() - Remove time steps where all items are NaN\nsqueeze() - Remove axes of length 1\n\n\n\n\n\nto_dataframe() - Convert Dataset to a pandas.DataFrame.\nto_xarray() - Convert Dataset to a xarray.Dataset (great for Dfs2, Dfs3).\nto_dfs() - Write Dataset to a Dfs file",
    "crumbs": [
      "Home",
      "User Guide",
      "Dataset"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html",
    "href": "user-guide/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "The Dataset is the common MIKE IO data structure for data read from dfs files. The mikeio.read method returns a Dataset with a DataArray for each item.\nEach DataArray have the following properties:\n\nitem - an mikeio.ItemInfo with name, type and unit\ntime - a pandas.DatetimeIndex with the time instances of the data\ngeometry - a Geometry object with the spatial description of the data\nvalues - a numpy.ndarray",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#dataset",
    "href": "user-guide/getting-started.html#dataset",
    "title": "Getting started",
    "section": "",
    "text": "The Dataset is the common MIKE IO data structure for data read from dfs files. The mikeio.read method returns a Dataset with a DataArray for each item.\nEach DataArray have the following properties:\n\nitem - an mikeio.ItemInfo with name, type and unit\ntime - a pandas.DatetimeIndex with the time instances of the data\ngeometry - a Geometry object with the spatial description of the data\nvalues - a numpy.ndarray",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#types-and-units",
    "href": "user-guide/getting-started.html#types-and-units",
    "title": "Getting started",
    "section": " Types and units",
    "text": "Types and units\nThe dfs items in MIKE IO are represented by the ItemInfo class. An ItemInfo consists of:\n\nname - a user-defined string\ntype - an EUMType\nunit - an EUMUnit\n\n\nimport mikeio\n\nmikeio.ItemInfo(\"Viken\", mikeio.EUMType.Water_Level)\n\nViken &lt;Water Level&gt; (meter)\n\n\n\nmikeio.ItemInfo(mikeio.EUMType.Wind_speed)\n\nWind speed &lt;Wind speed&gt; (meter per sec)",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#dfs0",
    "href": "user-guide/getting-started.html#dfs0",
    "title": "Getting started",
    "section": " Dfs0",
    "text": "Dfs0\nA dfs0 file is also called a time series file.\nRead Dfs0 to Dataset:\n\nds = mikeio.read(\"../data/da_diagnostic.dfs0\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:744)\ntime: 2017-10-27 00:00:00 - 2017-10-29 18:00:00 (744 non-equidistant records)\ngeometry: GeometryUndefined()\nitems:\n  0:  State 1Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  1:  State 2Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  2:  Mean StateSign. Wave Height &lt;Significant wave height&gt; (meter)\n  3:  MeasurementSign. Wave Height &lt;Significant wave height&gt; (meter)\n\n\nRead more on the Dfs0 page.\nConvert the timeseries dataset to a pandas DataFrame:\n\ndf = ds.to_dataframe()\ndf.head()\n\n\n\n\n\n\n\n\n\nState 1Sign. Wave Height\nState 2Sign. Wave Height\nMean StateSign. Wave Height\nMeasurementSign. Wave Height\n\n\n\n\n2017-10-27 00:00:00\n1.749465\n1.749465\n1.749465\n1.72\n\n\n2017-10-27 00:10:00\n1.811340\n1.796895\n1.807738\nNaN\n\n\n2017-10-27 00:20:00\n1.863424\n1.842759\n1.853422\nNaN\n\n\n2017-10-27 00:30:00\n1.922261\n1.889839\n1.897670\nNaN\n\n\n2017-10-27 00:40:00\n1.972455\n1.934886\n1.935281\nNaN",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#dfs2",
    "href": "user-guide/getting-started.html#dfs2",
    "title": "Getting started",
    "section": " Dfs2",
    "text": "Dfs2\nA dfs2 file is also called a grid series file. Values in a dfs2 file are ‘element based’, i.e. values are defined in the centre of each grid cell.\n\nds = mikeio.read(\"../data/gebco_sound.dfs2\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:1, y:264, x:216)\ntime: 2020-05-15 11:04:52 (time-invariant)\ngeometry: Grid2D (ny=264, nx=216)\nitems:\n  0:  Elevation &lt;Total Water Depth&gt; (meter)\n\n\nRead more on the Dfs2 page.",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#generic-dfs",
    "href": "user-guide/getting-started.html#generic-dfs",
    "title": "Getting started",
    "section": " Generic dfs",
    "text": "Generic dfs\nMIKE IO has generic functionality that works for all dfs files:\n\nconcat() - Concatenates files along the time axis\nextract() - Extract timesteps and/or items to a new dfs file\ndiff() - Calculate difference between two dfs files with identical geometry\nsum() - Calculate the sum of two dfs files\nscale() - Apply scaling to any dfs file\navg_time() - Create a temporally averaged dfs file\nquantile() - Create a dfs file with temporal quantiles\n\nAll generic methods creates a new dfs file.\nfrom mikeio import generic\ngeneric.concat([\"fileA.dfs2\", \"fileB.dfs2\"], \"new_file.dfs2\")",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#additional-resources",
    "href": "user-guide/getting-started.html#additional-resources",
    "title": "Getting started",
    "section": " Additional resources",
    "text": "Additional resources\n\nOnline book: Getting started with Dfs files in Python using MIKE IO\nOnline book: Python for marine modelers using MIKE IO and ModellSkill\nDFS file system specification",
    "crumbs": [
      "Home",
      "User Guide"
    ]
  },
  {
    "objectID": "examples/Time-interpolation.html",
    "href": "examples/Time-interpolation.html",
    "title": "Time interpolation",
    "section": "",
    "text": "import numpy as np\nimport mikeio\nds = mikeio.read(\"../data/waves.dfs2\")\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:3, y:31, x:31)\ntime: 2004-01-01 00:00:00 - 2004-01-03 00:00:00 (3 records)\ngeometry: Grid2D (ny=31, nx=31)\nitems:\n  0:  Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  1:  Peak Wave Period &lt;Wave period&gt; (second)\n  2:  Mean Wave Direction &lt;Mean Wave Direction&gt; (degree)",
    "crumbs": [
      "Home",
      "Examples",
      "Time interpolation"
    ]
  },
  {
    "objectID": "examples/Time-interpolation.html#interpolate-to-specific-timestep",
    "href": "examples/Time-interpolation.html#interpolate-to-specific-timestep",
    "title": "Time interpolation",
    "section": "Interpolate to specific timestep",
    "text": "Interpolate to specific timestep\nA common use case is to interpolate to a shorter timestep, in this case 1h.\n\nds_h = ds.interp_time(3600)\nds_h\n\n&lt;mikeio.Dataset&gt;\ndims: (time:49, y:31, x:31)\ntime: 2004-01-01 00:00:00 - 2004-01-03 00:00:00 (49 records)\ngeometry: Grid2D (ny=31, nx=31)\nitems:\n  0:  Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  1:  Peak Wave Period &lt;Wave period&gt; (second)\n  2:  Mean Wave Direction &lt;Mean Wave Direction&gt; (degree)\n\n\nAnd to store the interpolated data in a new file.\n\nds_h.to_dfs(\"waves_3h.dfs2\")",
    "crumbs": [
      "Home",
      "Examples",
      "Time interpolation"
    ]
  },
  {
    "objectID": "examples/Time-interpolation.html#interpolate-to-time-axis-of-another-dataset",
    "href": "examples/Time-interpolation.html#interpolate-to-time-axis-of-another-dataset",
    "title": "Time interpolation",
    "section": "Interpolate to time axis of another dataset",
    "text": "Interpolate to time axis of another dataset\nRead some non-equidistant data typically found in observed data.\n\nts = mikeio.read(\"../data/waves.dfs0\")\nts\n\n&lt;mikeio.Dataset&gt;\ndims: (time:24)\ntime: 2004-01-01 01:00:00 - 2004-01-03 12:00:10 (24 non-equidistant records)\ngeometry: GeometryUndefined()\nitems:\n  0:  Sign. Wave Height &lt;Undefined&gt; (undefined)\n  1:  Peak Wave Period &lt;Undefined&gt; (undefined)\n  2:  Mean Wave Direction &lt;Undefined&gt; (undefined)\n\n\nThe observed timeseries is longer than the modelled data. Default is to fill values with NaN.\n\ndsi = ds.interp_time(ts)\n\n\ndsi.time\n\nDatetimeIndex(['2004-01-01 01:00:00', '2004-01-01 02:00:00',\n               '2004-01-01 03:00:00', '2004-01-01 04:00:00',\n               '2004-01-01 05:00:00', '2004-01-01 06:00:00',\n               '2004-01-01 07:00:00', '2004-01-01 08:00:00',\n               '2004-01-01 23:00:00', '2004-01-02 00:00:00',\n               '2004-01-02 01:00:00', '2004-01-02 02:00:00',\n               '2004-01-02 03:00:00', '2004-01-02 04:00:00',\n               '2004-01-02 05:00:00', '2004-01-02 06:00:00',\n               '2004-01-02 07:00:00', '2004-01-02 08:00:00',\n               '2004-01-02 09:00:00', '2004-01-02 20:00:00',\n               '2004-01-02 21:00:00', '2004-01-02 23:00:00',\n               '2004-01-03 00:00:00', '2004-01-03 12:00:10'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\ndsi[\"Sign. Wave Height\"].shape\n\n(24, 31, 31)\n\n\n\nax = dsi[\"Sign. Wave Height\"].sel(x=250, y=1200).plot(marker='+')\nts[\"Sign. Wave Height\"].plot(ax=ax,marker='+')",
    "crumbs": [
      "Home",
      "Examples",
      "Time interpolation"
    ]
  },
  {
    "objectID": "examples/Time-interpolation.html#model-validation",
    "href": "examples/Time-interpolation.html#model-validation",
    "title": "Time interpolation",
    "section": "Model validation",
    "text": "Model validation\nA common metric for model validation is mean absolute error (MAE).\nIn the example below we calculate this metric using the model data interpolated to the observed times.\nFor a more elaborate model validation library which takes care of these things for you as well as calculating a number of relevant metrics, take a look at `ModelSkill.\nUse np.nanmean to skip NaN.\n\nts[\"Sign. Wave Height\"]\n\n&lt;mikeio.DataArray&gt;\nname: Sign. Wave Height\ndims: (time:24)\ntime: 2004-01-01 01:00:00 - 2004-01-03 12:00:10 (24 non-equidistant records)\ngeometry: GeometryUndefined()\nvalues: [0.06521, 0.06771, ..., 0.0576]\n\n\n\ndsi[\"Sign. Wave Height\"].sel(x=250, y=1200)\n\n&lt;mikeio.DataArray&gt;\nname: Sign. Wave Height\ndims: (time:24)\ntime: 2004-01-01 01:00:00 - 2004-01-03 12:00:10 (24 non-equidistant records)\ngeometry: GeometryPoint2D(x=275.0, y=1225.0)\nvalues: [0.0387, 0.03939, ..., nan]\n\n\n\ndiff = (ts[\"Sign. Wave Height\"]  - dsi[\"Sign. Wave Height\"].sel(x=250, y=1200))\ndiff.plot()\n\n\n\n\n\n\n\n\n\nmae = np.abs(diff).nanmean().to_numpy()\nmae\n\n0.030895043650399082",
    "crumbs": [
      "Home",
      "Examples",
      "Time interpolation"
    ]
  },
  {
    "objectID": "examples/Generic.html",
    "href": "examples/Generic.html",
    "title": "Generic dfs processing",
    "section": "",
    "text": "Tools and methods that applies to any type of dfs files.\nimport matplotlib.pyplot as plt\nimport mikeio\nimport mikeio.generic",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#concatenation",
    "href": "examples/Generic.html#concatenation",
    "title": "Generic dfs processing",
    "section": "Concatenation",
    "text": "Concatenation\nTake a look at these two files with overlapping timesteps.\n\nt1 = mikeio.read(\"../data/tide1.dfs1\")\nt1\n\n&lt;mikeio.Dataset&gt;\ndims: (time:97, x:10)\ntime: 2019-01-01 00:00:00 - 2019-01-03 00:00:00 (97 records)\ngeometry: Grid1D (n=10, dx=0.06667)\nitems:\n  0:  Level &lt;Water Level&gt; (meter)\n\n\n\nt2 = mikeio.read(\"../data/tide2.dfs1\")\nt2\n\n&lt;mikeio.Dataset&gt;\ndims: (time:97, x:10)\ntime: 2019-01-02 00:00:00 - 2019-01-04 00:00:00 (97 records)\ngeometry: Grid1D (n=10, dx=0.06667)\nitems:\n  0:  Level &lt;Water Level&gt; (meter)\n\n\nPlot one of the points along the line.\n\nplt.plot(t1.time,t1[0].isel(x=1).values, label=\"File 1\")\nplt.plot(t2.time,t2[0].isel(x=1).values,'k+', label=\"File 2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nmikeio.generic.concat(infilenames=[\"../data/tide1.dfs1\",\n                                   \"../data/tide2.dfs1\"],\n                     outfilename=\"concat.dfs1\")\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]100%|██████████| 2/2 [00:00&lt;00:00, 597.10it/s]\n\n\n\nc = mikeio.read(\"concat.dfs1\")\nc[0].isel(x=1).plot()\nc\n\n&lt;mikeio.Dataset&gt;\ndims: (time:145, x:10)\ntime: 2019-01-01 00:00:00 - 2019-01-04 00:00:00 (145 records)\ngeometry: Grid1D (n=10, dx=0.06667)\nitems:\n  0:  Level &lt;Water Level&gt; (meter)",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#difference-between-two-files",
    "href": "examples/Generic.html#difference-between-two-files",
    "title": "Generic dfs processing",
    "section": "Difference between two files",
    "text": "Difference between two files\nTake difference between two dfs files with same structure - e.g. to see the difference in result between two calibration runs\n\nfn1 = \"../data/oresundHD_run1.dfsu\"\nfn2 = \"../data/oresundHD_run2.dfsu\"\nfn_diff = \"oresundHD_difference.dfsu\"\nmikeio.generic.diff(fn1, fn2, fn_diff)\n\n  0%|          | 0/5 [00:00&lt;?, ?it/s]100%|██████████| 5/5 [00:00&lt;00:00, 2227.93it/s]\n\n\n\n_, ax = plt.subplots(1,3, sharey=True, figsize=(12,5))\nda = mikeio.read(fn1, time=-1)[0]\nda.plot(vmin=0.06, vmax=0.27, ax=ax[0], title='run 1')\nda = mikeio.read(fn2, time=-1)[0]\nda.plot(vmin=0.06, vmax=0.27, ax=ax[1], title='run 2')\nda = mikeio.read(fn_diff, time=-1)[0]\nda.plot(vmin=-0.1, vmax=0.1, cmap='coolwarm', ax=ax[2], title='difference');",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#extract-time-steps-or-items",
    "href": "examples/Generic.html#extract-time-steps-or-items",
    "title": "Generic dfs processing",
    "section": "Extract time steps or items",
    "text": "Extract time steps or items\nThe extract() method can extract a part of a file:\n\ntime slice by specifying start and/or end\nspecific items\n\n\ninfile = \"../data/tide1.dfs1\"\nmikeio.generic.extract(infile, \"extracted.dfs1\", start='2019-01-02')\n\n\ne = mikeio.read(\"extracted.dfs1\")\ne\n\n&lt;mikeio.Dataset&gt;\ndims: (time:49, x:10)\ntime: 2019-01-02 00:00:00 - 2019-01-03 00:00:00 (49 records)\ngeometry: Grid1D (n=10, dx=0.06667)\nitems:\n  0:  Level &lt;Water Level&gt; (meter)\n\n\n\ninfile = \"../data/oresund_vertical_slice.dfsu\"\nmikeio.generic.extract(infile, \"extracted.dfsu\", items='Salinity', end=-2)\n\n\ne = mikeio.read(\"extracted.dfsu\")\ne\n\n&lt;mikeio.Dataset&gt;\ndims: (time:2, element:441)\ntime: 1997-09-15 21:00:00 - 1997-09-16 00:00:00 (2 records)\ngeometry: Flexible Mesh Geometry: DfsuVerticalProfileSigmaZ\nnumber of nodes: 550\nnumber of elements: 441\nnumber of layers: 9\nnumber of sigma layers: 4\nprojection: UTM-33\nitems:\n  0:  Salinity &lt;Salinity&gt; (PSU)",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#scaling",
    "href": "examples/Generic.html#scaling",
    "title": "Generic dfs processing",
    "section": "Scaling",
    "text": "Scaling\nAdding a constant e.g to adjust datum\n\nds = mikeio.read(\"../data/gebco_sound.dfs2\")\nds.Elevation[0].plot();\n\n\n\n\n\n\n\n\n\nds['Elevation'][0,104,131].to_numpy()\n\n-1.0\n\n\nThis is the processing step.\n\nmikeio.generic.scale(\"../data/gebco_sound.dfs2\", \n                     \"gebco_sound_local_datum.dfs2\",\n                     offset=-2.1\n                     )\n\n  0%|          | 0/1 [00:00&lt;?, ?it/s]100%|██████████| 1/1 [00:00&lt;00:00, 1207.34it/s]\n\n\n\nds2 = mikeio.read(\"gebco_sound_local_datum.dfs2\")\nds2['Elevation'][0].plot()\n\n\n\n\n\n\n\n\n\nds2['Elevation'][0,104,131].to_numpy()\n\n-3.1\n\n\n\nSpatially varying correction\n\nimport numpy as np\nfactor = np.ones_like(ds['Elevation'][0].to_numpy())\nfactor.shape\n\n(264, 216)\n\n\nAdd some spatially varying factors, exaggerated values for educational purpose.\n\nfactor[:,0:100] = 5.3\nfactor[0:40,] = 0.1\nfactor[150:,150:] = 10.7\nplt.imshow(factor)\nplt.colorbar();\n\n\n\n\n\n\n\n\nThe 2d array must first be flipped upside down and then converted to a 1d vector using numpy.ndarray.flatten to match how data is stored in dfs files.\n\nfactor_ud = np.flipud(factor)\nfactor_vec  = factor_ud.flatten()\nmikeio.generic.scale(\"../data/gebco_sound.dfs2\", \n                     \"gebco_sound_spatial.dfs2\",\n                     factor=factor_vec\n                     )\n\n  0%|          | 0/1 [00:00&lt;?, ?it/s]100%|██████████| 1/1 [00:00&lt;00:00, 1217.15it/s]\n\n\n\nds3 = mikeio.read(\"gebco_sound_spatial.dfs2\")\nds3.Elevation[0].plot();",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#time-average",
    "href": "examples/Generic.html#time-average",
    "title": "Generic dfs processing",
    "section": "Time average",
    "text": "Time average\n\nfn = \"../data/NorthSea_HD_and_windspeed.dfsu\"\nfn_avg = \"Avg_NorthSea_HD_and_windspeed.dfsu\"\nmikeio.generic.avg_time(fn, fn_avg)\n\n  0%|          | 0/66 [00:00&lt;?, ?it/s]100%|██████████| 66/66 [00:00&lt;00:00, 17270.20it/s]\n\n\n\nds = mikeio.read(fn)\nds.mean(axis=0).describe()   # alternative way of getting the time average\n\n\n\n\n\n\n\n\n\nSurface elevation\nWind speed\n\n\n\n\ncount\n958.000000\n958.000000\n\n\nmean\n0.449857\n12.772706\n\n\nstd\n0.178127\n2.367667\n\n\nmin\n0.114355\n6.498364\n\n\n25%\n0.373691\n11.199439\n\n\n50%\n0.431747\n12.984060\n\n\n75%\n0.479224\n14.658077\n\n\nmax\n1.202888\n16.677952\n\n\n\n\n\n\n\n\n\nds_avg = mikeio.read(fn_avg)\nds_avg.describe()\n\n\n\n\n\n\n\n\n\nSurface elevation\nWind speed\n\n\n\n\ncount\n958.000000\n958.000000\n\n\nmean\n0.449857\n12.772706\n\n\nstd\n0.178127\n2.367667\n\n\nmin\n0.114355\n6.498364\n\n\n25%\n0.373691\n11.199439\n\n\n50%\n0.431747\n12.984060\n\n\n75%\n0.479224\n14.658077\n\n\nmax\n1.202888\n16.677952",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#quantile",
    "href": "examples/Generic.html#quantile",
    "title": "Generic dfs processing",
    "section": "Quantile",
    "text": "Quantile\nExample that calculates the 25%, 50% and 75% percentile for all items in a dfsu file.\n\nfn = \"../data/NorthSea_HD_and_windspeed.dfsu\"\nfn_q = \"Q_NorthSea_HD_and_windspeed.dfsu\"\nmikeio.generic.quantile(fn, fn_q, q=[0.25,0.5,0.75])\n\n\nds = mikeio.read(fn_q)\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:1, element:958)\ntime: 2017-10-27 00:00:00 (time-invariant)\ngeometry: Dfsu2D (958 elements, 570 nodes)\nitems:\n  0:  Quantile 0.25, Surface elevation &lt;Surface Elevation&gt; (meter)\n  1:  Quantile 0.5, Surface elevation &lt;Surface Elevation&gt; (meter)\n  2:  Quantile 0.75, Surface elevation &lt;Surface Elevation&gt; (meter)\n  3:  Quantile 0.25, Wind speed &lt;Wind speed&gt; (meter per sec)\n  4:  Quantile 0.5, Wind speed &lt;Wind speed&gt; (meter per sec)\n  5:  Quantile 0.75, Wind speed &lt;Wind speed&gt; (meter per sec)\n\n\n\nda_q75 = ds[\"Quantile 0.75, Wind speed\"]\nda_q75.plot(title=\"75th percentile, wind speed\", label=\"m/s\")",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/Generic.html#clean-up",
    "href": "examples/Generic.html#clean-up",
    "title": "Generic dfs processing",
    "section": "Clean up",
    "text": "Clean up\n\nimport os\nos.remove(\"concat.dfs1\")\nos.remove(\"oresundHD_difference.dfsu\")\nos.remove(\"extracted.dfs1\")\nos.remove(\"extracted.dfsu\")\nos.remove(\"gebco_sound_local_datum.dfs2\")\nos.remove(\"gebco_sound_spatial.dfs2\")\nos.remove(\"Avg_NorthSea_HD_and_windspeed.dfsu\")\nos.remove(fn_q)",
    "crumbs": [
      "Home",
      "Examples",
      "Generic dfs processing"
    ]
  },
  {
    "objectID": "examples/dfs2/gfs.html",
    "href": "examples/dfs2/gfs.html",
    "title": "Dfs2 - Meteo data",
    "section": "",
    "text": "import xarray\nimport pandas as pd\nimport mikeio\nThe file gfs_wind.nc contains a small sample of the GFS forecast data downloaded via their OpenDAP service\nds = xarray.open_dataset('../../data/gfs_wind.nc')\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 32kB\nDimensions:   (time: 3, lat: 41, lon: 21)\nCoordinates: (3)\nData variables:\n    msletmsl  (time, lat, lon) float32 10kB ...\n    ugrd10m   (time, lat, lon) float32 10kB ...\n    vgrd10m   (time, lat, lon) float32 10kB ...\nAttributes: (4)xarray.DatasetDimensions:time: 3lat: 41lon: 21Coordinates: (3)time(time)datetime64[ns]2021-09-02T12:00:00 ... 2021-09-...grads_dim :tgrads_mapping :lineargrads_size :129grads_min :12z02sep2021grads_step :3hrlong_name :timeminimum :12z02sep2021maximum :12z18sep2021resolution :0.125array(['2021-09-02T12:00:00.000000000', '2021-09-02T15:00:00.000000000',\n       '2021-09-02T18:00:00.000000000'], dtype='datetime64[ns]')lat(lat)float6430.0 30.25 30.5 ... 39.5 39.75 40.0grads_dim :ygrads_mapping :lineargrads_size :721units :degrees_northlong_name :latitudeminimum :-90.0maximum :90.0resolution :0.25array([30.  , 30.25, 30.5 , 30.75, 31.  , 31.25, 31.5 , 31.75, 32.  , 32.25,\n       32.5 , 32.75, 33.  , 33.25, 33.5 , 33.75, 34.  , 34.25, 34.5 , 34.75,\n       35.  , 35.25, 35.5 , 35.75, 36.  , 36.25, 36.5 , 36.75, 37.  , 37.25,\n       37.5 , 37.75, 38.  , 38.25, 38.5 , 38.75, 39.  , 39.25, 39.5 , 39.75,\n       40.  ])lon(lon)float6410.0 10.25 10.5 ... 14.5 14.75 15.0grads_dim :xgrads_mapping :lineargrads_size :1440units :degrees_eastlong_name :longitudeminimum :0.0maximum :359.75resolution :0.25array([10.  , 10.25, 10.5 , 10.75, 11.  , 11.25, 11.5 , 11.75, 12.  , 12.25,\n       12.5 , 12.75, 13.  , 13.25, 13.5 , 13.75, 14.  , 14.25, 14.5 , 14.75,\n       15.  ])Data variables: (3)msletmsl(time, lat, lon)float32...long_name :** mean sea level mslp (eta model reduction) [pa] [2583 values with dtype=float32]ugrd10m(time, lat, lon)float32...long_name :** 10 m above ground u-component of wind [m/s] [2583 values with dtype=float32]vgrd10m(time, lat, lon)float32...long_name :** 10 m above ground v-component of wind [m/s] [2583 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-09-02 12:00:00', '2021-09-02 15:00:00',\n               '2021-09-02 18:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latPandasIndexPandasIndex(Index([ 30.0, 30.25,  30.5, 30.75,  31.0, 31.25,  31.5, 31.75,  32.0, 32.25,\n        32.5, 32.75,  33.0, 33.25,  33.5, 33.75,  34.0, 34.25,  34.5, 34.75,\n        35.0, 35.25,  35.5, 35.75,  36.0, 36.25,  36.5, 36.75,  37.0, 37.25,\n        37.5, 37.75,  38.0, 38.25,  38.5, 38.75,  39.0, 39.25,  39.5, 39.75,\n        40.0],\n      dtype='float64', name='lat'))lonPandasIndexPandasIndex(Index([ 10.0, 10.25,  10.5, 10.75,  11.0, 11.25,  11.5, 11.75,  12.0, 12.25,\n        12.5, 12.75,  13.0, 13.25,  13.5, 13.75,  14.0, 14.25,  14.5, 14.75,\n        15.0],\n      dtype='float64', name='lon'))Attributes: (4)title :GFS 0.25 deg starting from 12Z02sep2021, downloaded Sep 02 17:14 UTCConventions :COARDS\nGrADSdataType :Gridhistory :Thu Sep 02 17:27:02 GMT 2021 : imported by GrADS Data Server 2.0\nRunning a Mike 21 HD model, needs at least three variables of meteorological forcing * Mean Sea Level Pressure * U 10m * V 10m\nLet’s take a look the U 10m\nds.ugrd10m.isel(time=0).plot();",
    "crumbs": [
      "Home",
      "Examples",
      "Dfs2",
      "Dfs2 - Meteo data"
    ]
  },
  {
    "objectID": "examples/dfs2/gfs.html#convert-to-dfs2",
    "href": "examples/dfs2/gfs.html#convert-to-dfs2",
    "title": "Dfs2 - Meteo data",
    "section": "Convert to dfs2",
    "text": "Convert to dfs2\n\nTime\n\ntime = pd.DatetimeIndex(ds.time)\ntime\n\nDatetimeIndex(['2021-09-02 12:00:00', '2021-09-02 15:00:00',\n               '2021-09-02 18:00:00'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\n\nVariable types\n\nmikeio.EUMType.Air_Pressure\n\nAir Pressure\n\n\n\nmikeio.EUMType.Air_Pressure.units\n\n[hectopascal, millibar]\n\n\n\nmikeio.EUMType.Wind_Velocity\n\nWind Velocity\n\n\n\nmikeio.EUMType.Wind_Velocity.units\n\n[meter per sec, feet per sec, miles per hour, km per hour, knot]\n\n\n\nmslp = ds.msletmsl.values / 100 # conversion from Pa to hPa\nu = ds.ugrd10m.values\nv = ds.vgrd10m.values\n\n\ngeometry = mikeio.Grid2D(x=ds.lon.values, y=ds.lat.values, projection=\"LONG/LAT\")\ngeometry\n\n&lt;mikeio.Grid2D&gt;\nx: [10, 10.25, ..., 15] (nx=21, dx=0.25)\ny: [30, 30.25, ..., 40] (ny=41, dy=0.25)\nprojection: LONG/LAT\n\n\n\nfrom mikeio import ItemInfo, EUMType, EUMUnit\n\nmslp_da = mikeio.DataArray(data=mslp,time=time, geometry=geometry, item=ItemInfo(\"Mean Sea Level Pressure\", EUMType.Air_Pressure, EUMUnit.hectopascal))\nu_da = mikeio.DataArray(data=u,time=time, geometry=geometry, item=ItemInfo(\"Wind U\", EUMType.Wind_Velocity, EUMUnit.meter_per_sec))\nv_da = mikeio.DataArray(data=v,time=time, geometry=geometry, item=ItemInfo(\"Wind V\", EUMType.Wind_Velocity, EUMUnit.meter_per_sec))\n\n\nmds = mikeio.Dataset([mslp_da, u_da, v_da])\nmds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:3, y:41, x:21)\ntime: 2021-09-02 12:00:00 - 2021-09-02 18:00:00 (3 records)\ngeometry: Grid2D (ny=41, nx=21)\nitems:\n  0:  Mean Sea Level Pressure &lt;Air Pressure&gt; (hectopascal)\n  1:  Wind U &lt;Wind Velocity&gt; (meter per sec)\n  2:  Wind V &lt;Wind Velocity&gt; (meter per sec)\n\n\n\nmds.to_dfs(\"gfs.dfs2\")\n\nClean up\n\nimport os\n\nos.remove(\"gfs.dfs2\")",
    "crumbs": [
      "Home",
      "Examples",
      "Dfs2",
      "Dfs2 - Meteo data"
    ]
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html",
    "href": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html",
    "title": "dataset._data_plot._DataArrayPlotterFMVerticalProfile",
    "section": "",
    "text": "dataset._data_plot._DataArrayPlotterFMVerticalProfile(self, da)\nPlot a DataArray with a 2DV GeometryFMVerticalProfile geometry\nIf DataArray has multiple time steps, the first step will be plotted.\n\n\n&gt;&gt;&gt; da = mikeio.read(\"oresund_vertical_slice.dfsu\")[\"Temperature\"]\n&gt;&gt;&gt; da.plot()\n&gt;&gt;&gt; da.plot.mesh()\n&gt;&gt;&gt; da.plot.hist()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html#examples",
    "href": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html#examples",
    "title": "dataset._data_plot._DataArrayPlotterFMVerticalProfile",
    "section": "",
    "text": "&gt;&gt;&gt; da = mikeio.read(\"oresund_vertical_slice.dfsu\")[\"Temperature\"]\n&gt;&gt;&gt; da.plot()\n&gt;&gt;&gt; da.plot.mesh()\n&gt;&gt;&gt; da.plot.hist()"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html#methods",
    "href": "api/dataset._data_plot._DataArrayPlotterFMVerticalProfile.html#methods",
    "title": "dataset._data_plot._DataArrayPlotterFMVerticalProfile",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)"
  },
  {
    "objectID": "api/generic.html",
    "href": "api/generic.html",
    "title": "generic",
    "section": "",
    "text": "generic\n\n\n\n\n\nName\nDescription\n\n\n\n\navg_time\nCreate a temporally averaged dfs file\n\n\nconcat\nConcatenates files along the time axis\n\n\ndiff\nCalculate difference between two dfs files (a-b)\n\n\nextract\nExtract timesteps and/or items to a new dfs file\n\n\nfill_corrupt\nReplace corrupt (unreadable) data with fill_value, default delete value.\n\n\nquantile\nCreate temporal quantiles of all items in dfs file\n\n\nscale\nApply scaling to any dfs file\n\n\nsum\nSum two dfs files (a+b)\n\n\n\n\n\ngeneric.avg_time(infilename, outfilename, skipna=True)\nCreate a temporally averaged dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\ninput filename\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\noutput filename\nrequired\n\n\nskipna\nbool\nexclude NaN/delete values when computing the result, default True\nTrue\n\n\n\n\n\n\n\ngeneric.concat(infilenames, outfilename, keep='last')\nConcatenates files along the time axis\nOverlap handling is defined by the keep argument, by default the last one will be used.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilenames\ncollections.abc.Sequence[str | pathlib.pathlib.Path]\nfilenames to concatenate\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfilename of output\nrequired\n\n\nkeep\nstr\neither ‘first’ (keep older), ‘last’ (keep newer) or ‘average’ can be selected. By default ‘last’\n'last'\n\n\n\n\n\n\nThe list of input files have to be sorted, i.e. in chronological order\n\n\n\n\ngeneric.diff(infilename_a, infilename_b, outfilename)\nCalculate difference between two dfs files (a-b)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename_a\nstr | pathlib.pathlib.Path\nfull path to the first input file\nrequired\n\n\ninfilename_b\nstr | pathlib.pathlib.Path\nfull path to the second input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\n\n\n\n\n\ngeneric.extract(infilename, outfilename, start=0, end=-1, step=1, items=None)\nExtract timesteps and/or items to a new dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\npath to input dfs file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\npath to output dfs file\nrequired\n\n\nstart\n(int, float, str or datetime.datetime)\nstart of extraction as either step, relative seconds or datetime/str, by default 0 (start of file)\n0\n\n\nend\n(int, float, str or datetime.datetime)\nend of extraction as either step, relative seconds or datetime/str, by default -1 (end of file)\n-1\n\n\nstep\nint\njump this many step, by default 1 (every step between start and end)\n1\n\n\nitems\n(int, list(int), str, list(str))\nitems to be extracted to new file\nNone\n\n\n\n\n\n\n&gt;&gt;&gt; extract('f_in.dfs0', 'f_out.dfs0', start='2018-1-1')\n&gt;&gt;&gt; extract('f_in.dfs2', 'f_out.dfs2', end=-3)\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', start=1800.0, end=3600.0)\n&gt;&gt;&gt; extract('f_hourly.dfsu', 'f_daily.dfsu', step=24)\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', items=[2, 0])\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', items=\"Salinity\")\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', end='2018-2-1 00:00', items=\"Salinity\")\n\n\n\n\ngeneric.fill_corrupt(infilename, outfilename, fill_value=np.nan, items=None)\nReplace corrupt (unreadable) data with fill_value, default delete value.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\nfull path to the input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\nfill_value\nfloat\nvalue to use where data is corrupt, default delete value\nnp.nan\n\n\nitems\ncollections.abc.Sequence[str | int] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\n\n\n\n\n\ngeneric.quantile(infilename, outfilename, q, *, items=None, skipna=True, buffer_size=1000000000.0)\nCreate temporal quantiles of all items in dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\ninput filename\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\noutput filename\nrequired\n\n\nq\nfloat | collections.abc.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\nitems\ncollections.abc.Sequence[int | str] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\nskipna\nbool\nexclude NaN/delete values when computing the result, default True\nTrue\n\n\nbuffer_size\nfloat\nfor huge files the quantiles need to be calculated for chunks of elements. buffer_size gives the maximum amount of memory available for the computation in bytes, by default 1e9 (=1GB)\n1000000000.0\n\n\n\n\n\n\n&gt;&gt;&gt; quantile(\"in.dfsu\", \"IQR.dfsu\", q=[0.25,0.75])\n&gt;&gt;&gt; quantile(\"huge.dfsu\", \"Q01.dfsu\", q=0.1, buffer_size=5.0e9)\n&gt;&gt;&gt; quantile(\"with_nans.dfsu\", \"Q05.dfsu\", q=0.5, skipna=False)\n\n\n\n\ngeneric.scale(infilename, outfilename, offset=0.0, factor=1.0, items=None)\nApply scaling to any dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\nfull path to the input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\noffset\nfloat\nvalue to add to all items, default 0.0\n0.0\n\n\nfactor\nfloat\nvalue to multiply to all items, default 1.0\n1.0\n\n\nitems\ncollections.abc.Sequence[int | str] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\n\n\n\n\n\ngeneric.sum(infilename_a, infilename_b, outfilename)\nSum two dfs files (a+b)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename_a\nstr | pathlib.pathlib.Path\nfull path to the first input file\nrequired\n\n\ninfilename_b\nstr | pathlib.pathlib.Path\nfull path to the second input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired"
  },
  {
    "objectID": "api/generic.html#functions",
    "href": "api/generic.html#functions",
    "title": "generic",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\navg_time\nCreate a temporally averaged dfs file\n\n\nconcat\nConcatenates files along the time axis\n\n\ndiff\nCalculate difference between two dfs files (a-b)\n\n\nextract\nExtract timesteps and/or items to a new dfs file\n\n\nfill_corrupt\nReplace corrupt (unreadable) data with fill_value, default delete value.\n\n\nquantile\nCreate temporal quantiles of all items in dfs file\n\n\nscale\nApply scaling to any dfs file\n\n\nsum\nSum two dfs files (a+b)\n\n\n\n\n\ngeneric.avg_time(infilename, outfilename, skipna=True)\nCreate a temporally averaged dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\ninput filename\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\noutput filename\nrequired\n\n\nskipna\nbool\nexclude NaN/delete values when computing the result, default True\nTrue\n\n\n\n\n\n\n\ngeneric.concat(infilenames, outfilename, keep='last')\nConcatenates files along the time axis\nOverlap handling is defined by the keep argument, by default the last one will be used.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilenames\ncollections.abc.Sequence[str | pathlib.pathlib.Path]\nfilenames to concatenate\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfilename of output\nrequired\n\n\nkeep\nstr\neither ‘first’ (keep older), ‘last’ (keep newer) or ‘average’ can be selected. By default ‘last’\n'last'\n\n\n\n\n\n\nThe list of input files have to be sorted, i.e. in chronological order\n\n\n\n\ngeneric.diff(infilename_a, infilename_b, outfilename)\nCalculate difference between two dfs files (a-b)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename_a\nstr | pathlib.pathlib.Path\nfull path to the first input file\nrequired\n\n\ninfilename_b\nstr | pathlib.pathlib.Path\nfull path to the second input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\n\n\n\n\n\ngeneric.extract(infilename, outfilename, start=0, end=-1, step=1, items=None)\nExtract timesteps and/or items to a new dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\npath to input dfs file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\npath to output dfs file\nrequired\n\n\nstart\n(int, float, str or datetime.datetime)\nstart of extraction as either step, relative seconds or datetime/str, by default 0 (start of file)\n0\n\n\nend\n(int, float, str or datetime.datetime)\nend of extraction as either step, relative seconds or datetime/str, by default -1 (end of file)\n-1\n\n\nstep\nint\njump this many step, by default 1 (every step between start and end)\n1\n\n\nitems\n(int, list(int), str, list(str))\nitems to be extracted to new file\nNone\n\n\n\n\n\n\n&gt;&gt;&gt; extract('f_in.dfs0', 'f_out.dfs0', start='2018-1-1')\n&gt;&gt;&gt; extract('f_in.dfs2', 'f_out.dfs2', end=-3)\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', start=1800.0, end=3600.0)\n&gt;&gt;&gt; extract('f_hourly.dfsu', 'f_daily.dfsu', step=24)\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', items=[2, 0])\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', items=\"Salinity\")\n&gt;&gt;&gt; extract('f_in.dfsu', 'f_out.dfsu', end='2018-2-1 00:00', items=\"Salinity\")\n\n\n\n\ngeneric.fill_corrupt(infilename, outfilename, fill_value=np.nan, items=None)\nReplace corrupt (unreadable) data with fill_value, default delete value.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\nfull path to the input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\nfill_value\nfloat\nvalue to use where data is corrupt, default delete value\nnp.nan\n\n\nitems\ncollections.abc.Sequence[str | int] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\n\n\n\n\n\ngeneric.quantile(infilename, outfilename, q, *, items=None, skipna=True, buffer_size=1000000000.0)\nCreate temporal quantiles of all items in dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\ninput filename\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\noutput filename\nrequired\n\n\nq\nfloat | collections.abc.Sequence[float]\nQuantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\nrequired\n\n\nitems\ncollections.abc.Sequence[int | str] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\nskipna\nbool\nexclude NaN/delete values when computing the result, default True\nTrue\n\n\nbuffer_size\nfloat\nfor huge files the quantiles need to be calculated for chunks of elements. buffer_size gives the maximum amount of memory available for the computation in bytes, by default 1e9 (=1GB)\n1000000000.0\n\n\n\n\n\n\n&gt;&gt;&gt; quantile(\"in.dfsu\", \"IQR.dfsu\", q=[0.25,0.75])\n&gt;&gt;&gt; quantile(\"huge.dfsu\", \"Q01.dfsu\", q=0.1, buffer_size=5.0e9)\n&gt;&gt;&gt; quantile(\"with_nans.dfsu\", \"Q05.dfsu\", q=0.5, skipna=False)\n\n\n\n\ngeneric.scale(infilename, outfilename, offset=0.0, factor=1.0, items=None)\nApply scaling to any dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename\nstr | pathlib.pathlib.Path\nfull path to the input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired\n\n\noffset\nfloat\nvalue to add to all items, default 0.0\n0.0\n\n\nfactor\nfloat\nvalue to multiply to all items, default 1.0\n1.0\n\n\nitems\ncollections.abc.Sequence[int | str] | None\nProcess only selected items, by number (0-based) or name, by default: all\nNone\n\n\n\n\n\n\n\ngeneric.sum(infilename_a, infilename_b, outfilename)\nSum two dfs files (a+b)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninfilename_a\nstr | pathlib.pathlib.Path\nfull path to the first input file\nrequired\n\n\ninfilename_b\nstr | pathlib.pathlib.Path\nfull path to the second input file\nrequired\n\n\noutfilename\nstr | pathlib.pathlib.Path\nfull path to the output file\nrequired"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFM.html",
    "href": "api/dataset._data_plot._DataArrayPlotterFM.html",
    "title": "dataset._data_plot._DataArrayPlotterFM",
    "section": "",
    "text": "dataset._data_plot._DataArrayPlotterFM(self, da)\nPlot a DataArray with a GeometryFM geometry\nIf DataArray has multiple time steps, the first step will be plotted.\nIf DataArray is 3D the surface layer will be plotted."
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFM.html#examples",
    "href": "api/dataset._data_plot._DataArrayPlotterFM.html#examples",
    "title": "dataset._data_plot._DataArrayPlotterFM",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot()"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterFM.html#methods",
    "href": "api/dataset._data_plot._DataArrayPlotterFM.html#methods",
    "title": "dataset._data_plot._DataArrayPlotterFM",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\ncontour\nPlot data as contour lines\n\n\ncontourf\nPlot data as filled contours\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\nmesh\nPlot mesh only\n\n\noutline\nPlot domain outline (using the boundary_polylines property)\n\n\npatch\nPlot data as coloured patches\n\n\n\n\ncontour\ndataset._data_plot._DataArrayPlotterFM.contour(ax=None, figsize=None, **kwargs)\nPlot data as contour lines\n\nExamples\n\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot.contour()\n\n\n\n\n\n\n\n\n\n\n\ncontourf\ndataset._data_plot._DataArrayPlotterFM.contourf(ax=None, figsize=None, **kwargs)\nPlot data as filled contours\n\nExamples\n\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot.contourf()\n\n\n\n\n\n\n\n\n\n\n\nhist\ndataset._data_plot._DataArrayPlotterFM.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\nSee Also\nmatplotlib.pyplot.hist\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\nline\ndataset._data_plot._DataArrayPlotterFM.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)\n\n\nmesh\ndataset._data_plot._DataArrayPlotterFM.mesh(ax=None, figsize=None, **kwargs)\nPlot mesh only\n\nExamples\n\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot.mesh()\n\n\n\n\n\n\n\n\n\n\n\noutline\ndataset._data_plot._DataArrayPlotterFM.outline(ax=None, figsize=None, **kwargs)\nPlot domain outline (using the boundary_polylines property)\n\nExamples\n\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot.outline()\n\n\n\n\n\n\n\n\n\n\n\npatch\ndataset._data_plot._DataArrayPlotterFM.patch(ax=None, figsize=None, **kwargs)\nPlot data as coloured patches\n\nExamples\n\nda = mikeio.read(\"../data/HD2D.dfsu\")[\"Surface elevation\"]\nda.plot.patch()"
  },
  {
    "objectID": "api/dataset._data_plot._DatasetPlotter.html",
    "href": "api/dataset._data_plot._DatasetPlotter.html",
    "title": "dataset._data_plot._DatasetPlotter",
    "section": "",
    "text": "dataset._data_plot._DatasetPlotter(self, ds)\n\n\n\n\n\nName\nDescription\n\n\n\n\nscatter\nPlot data from two DataArrays against each other in a scatter plot\n\n\n\n\n\ndataset._data_plot._DatasetPlotter.scatter(x, y, ax=None, figsize=None, **kwargs)\nPlot data from two DataArrays against each other in a scatter plot\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nstr or int\nIdentifier for first DataArray\nrequired\n\n\ny\nstr or int\nIdentifier for second DataArray\nrequired\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\n\nspecify size of figure\nNone\n\n\ntitle\n\naxes title\nrequired\n\n\n**kwargs\n\n\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n&gt;&gt;&gt; ds = mikeio.read(\"oresund_sigma_z.dfsu\")\n&gt;&gt;&gt; ds.plot.scatter(x=\"Salinity\", y=\"Temperature\", title=\"S-vs-T\")\n&gt;&gt;&gt; ds.plot.scatter(x=0, y=1, figsize=(9,9), marker='*')"
  },
  {
    "objectID": "api/dataset._data_plot._DatasetPlotter.html#methods",
    "href": "api/dataset._data_plot._DatasetPlotter.html#methods",
    "title": "dataset._data_plot._DatasetPlotter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nscatter\nPlot data from two DataArrays against each other in a scatter plot\n\n\n\n\n\ndataset._data_plot._DatasetPlotter.scatter(x, y, ax=None, figsize=None, **kwargs)\nPlot data from two DataArrays against each other in a scatter plot\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nstr or int\nIdentifier for first DataArray\nrequired\n\n\ny\nstr or int\nIdentifier for second DataArray\nrequired\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\n\nspecify size of figure\nNone\n\n\ntitle\n\naxes title\nrequired\n\n\n**kwargs\n\n\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n&gt;&gt;&gt; ds = mikeio.read(\"oresund_sigma_z.dfsu\")\n&gt;&gt;&gt; ds.plot.scatter(x=\"Salinity\", y=\"Temperature\", title=\"S-vs-T\")\n&gt;&gt;&gt; ds.plot.scatter(x=0, y=1, figsize=(9,9), marker='*')"
  },
  {
    "objectID": "api/Grid2D.html",
    "href": "api/Grid2D.html",
    "title": "Grid2D",
    "section": "",
    "text": "Grid2D(self, *, x=None, x0=0.0, dx=None, nx=None, y=None, y0=0.0, dy=None, ny=None, bbox=None, projection='LONG/LAT', origin=None, orientation=0.0, axis_names=('x', 'y'), is_spectral=False, is_vertical=False)\n2D grid Origin in the center of cell in lower-left corner x and y axes are increasing and equidistant\n\n\n\n\n\nName\nDescription\n\n\n\n\nbbox\nbounding box (left, bottom, right, top)\n\n\ndx\nx grid spacing\n\n\ndy\ny grid spacing\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nnx\nnumber of x grid points\n\n\nny\nnumber of y grid points\n\n\norientation\nGrid orientation\n\n\norigin\nCoordinates of grid origo (in projection)\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\nx\narray of x coordinates (element center)\n\n\nxy\nn-by-2 array of x- and y-coordinates\n\n\ny\narray of y coordinates (element center)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncontains\ntest if a list of points are inside grid\n\n\nfind_index\nFind nearest index (i,j) of point(s)\n\n\nget_node_coordinates\nnode coordinates for this grid\n\n\nisel\nReturn a new geometry as a subset of Grid2D along the given axis.\n\n\nto_geometryFM\nconvert Grid2D to GeometryFM2D\n\n\nto_mesh\nexport grid to mesh file\n\n\n\n\n\nGrid2D.contains(coords)\ntest if a list of points are inside grid\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncoords\narray(float)\nxy-coordinate of points given as n-by-2 array\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nGrid2D.find_index(x=None, y=None, coords=None, area=None)\nFind nearest index (i,j) of point(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat\nx-coordinate of point\nNone\n\n\ny\nfloat\ny-coordinate of point\nNone\n\n\ncoords\narray(float)\nxy-coordinate of points given as n-by-2 array\nNone\n\n\narea\narray(float)\nxy-coordinates of bounding box\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(array(int), array(int))\ni- and j-index of nearest cell\n\n\n\n\n\n\n\nGrid2D.get_node_coordinates()\nnode coordinates for this grid\n\n\n\n\n\nType\nDescription\n\n\n\n\narray(float)\n2d array with x,y-coordinates, length=(nx+1)*(ny+1)\n\n\n\n\n\n\n\nGrid2D.isel(idx, axis)\nReturn a new geometry as a subset of Grid2D along the given axis.\n\n\n\nGrid2D.to_geometryFM(z=None, west=2, east=4, north=5, south=3)\nconvert Grid2D to GeometryFM2D\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nz\nfloat\nbathymetry values for each node, by default 0\nNone\n\n\nwest\nint\ncode value for west boundary\n2\n\n\neast\nint\ncode value for east boundary\n4\n\n\nnorth\nint\ncode value for north boundary\n5\n\n\nsouth\nint\ncode value for south boundary\n3\n\n\n\n\n\n\n\nGrid2D.to_mesh(outfilename, z=None)\nexport grid to mesh file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath of new mesh file\nrequired\n\n\nz\nfloat or array(float)\nbathymetry values for each node, by default 0 if array: must have length=(nx+1)*(ny+1)\nNone"
  },
  {
    "objectID": "api/Grid2D.html#attributes",
    "href": "api/Grid2D.html#attributes",
    "title": "Grid2D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbbox\nbounding box (left, bottom, right, top)\n\n\ndx\nx grid spacing\n\n\ndy\ny grid spacing\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nnx\nnumber of x grid points\n\n\nny\nnumber of y grid points\n\n\norientation\nGrid orientation\n\n\norigin\nCoordinates of grid origo (in projection)\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\nx\narray of x coordinates (element center)\n\n\nxy\nn-by-2 array of x- and y-coordinates\n\n\ny\narray of y coordinates (element center)"
  },
  {
    "objectID": "api/Grid2D.html#methods",
    "href": "api/Grid2D.html#methods",
    "title": "Grid2D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncontains\ntest if a list of points are inside grid\n\n\nfind_index\nFind nearest index (i,j) of point(s)\n\n\nget_node_coordinates\nnode coordinates for this grid\n\n\nisel\nReturn a new geometry as a subset of Grid2D along the given axis.\n\n\nto_geometryFM\nconvert Grid2D to GeometryFM2D\n\n\nto_mesh\nexport grid to mesh file\n\n\n\n\n\nGrid2D.contains(coords)\ntest if a list of points are inside grid\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncoords\narray(float)\nxy-coordinate of points given as n-by-2 array\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool array\nTrue for points inside, False otherwise\n\n\n\n\n\n\n\nGrid2D.find_index(x=None, y=None, coords=None, area=None)\nFind nearest index (i,j) of point(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat\nx-coordinate of point\nNone\n\n\ny\nfloat\ny-coordinate of point\nNone\n\n\ncoords\narray(float)\nxy-coordinate of points given as n-by-2 array\nNone\n\n\narea\narray(float)\nxy-coordinates of bounding box\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n(array(int), array(int))\ni- and j-index of nearest cell\n\n\n\n\n\n\n\nGrid2D.get_node_coordinates()\nnode coordinates for this grid\n\n\n\n\n\nType\nDescription\n\n\n\n\narray(float)\n2d array with x,y-coordinates, length=(nx+1)*(ny+1)\n\n\n\n\n\n\n\nGrid2D.isel(idx, axis)\nReturn a new geometry as a subset of Grid2D along the given axis.\n\n\n\nGrid2D.to_geometryFM(z=None, west=2, east=4, north=5, south=3)\nconvert Grid2D to GeometryFM2D\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nz\nfloat\nbathymetry values for each node, by default 0\nNone\n\n\nwest\nint\ncode value for west boundary\n2\n\n\neast\nint\ncode value for east boundary\n4\n\n\nnorth\nint\ncode value for north boundary\n5\n\n\nsouth\nint\ncode value for south boundary\n3\n\n\n\n\n\n\n\nGrid2D.to_mesh(outfilename, z=None)\nexport grid to mesh file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath of new mesh file\nrequired\n\n\nz\nfloat or array(float)\nbathymetry values for each node, by default 0 if array: must have length=(nx+1)*(ny+1)\nNone"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalColumn.html",
    "href": "api/spatial.GeometryFMVerticalColumn.html",
    "title": "spatial.GeometryFMVerticalColumn",
    "section": "",
    "text": "spatial.GeometryFMVerticalColumn(self, *, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=DfsuFileType.Dfsu3DSigma, element_ids=None, node_ids=None, n_layers=1, n_sigma=None, validate=True, reindex=False)\nA 3d geometry with consisting of a single vertical column\n\n\n\n\n\nName\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFMVerticalColumn.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalColumn.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalColumn.html#attributes",
    "href": "api/spatial.GeometryFMVerticalColumn.html#attributes",
    "title": "spatial.GeometryFMVerticalColumn",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalColumn.html#methods",
    "href": "api/spatial.GeometryFMVerticalColumn.html#methods",
    "title": "spatial.GeometryFMVerticalColumn",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFMVerticalColumn.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalColumn.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/EUMType.html",
    "href": "api/EUMType.html",
    "title": "EUMType",
    "section": "",
    "text": "EUMType(self, code)\nEUM type"
  },
  {
    "objectID": "api/EUMType.html#examples",
    "href": "api/EUMType.html#examples",
    "title": "EUMType",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.EUMType.Temperature\n\nTemperature\n\n\n\nmikeio.EUMType.Temperature.units\n\n[degree Celsius, degree Fahrenheit, degree Kelvin]"
  },
  {
    "objectID": "api/EUMType.html#attributes",
    "href": "api/EUMType.html#attributes",
    "title": "EUMType",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\ndisplay_name\nDisplay friendly name\n\n\nunits\nList valid units for this EUM type"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid1D.html",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid1D.html",
    "title": "dataset._data_plot._DataArrayPlotterGrid1D",
    "section": "",
    "text": "dataset._data_plot._DataArrayPlotterGrid1D(self, da)\nPlot a DataArray with a Grid1D geometry\n\n\n&gt;&gt;&gt; da = mikeio.read(\"tide1.dfs1\")[\"Level\"]\n&gt;&gt;&gt; da.plot()\n&gt;&gt;&gt; da.plot.line()\n&gt;&gt;&gt; da.plot.timeseries()\n&gt;&gt;&gt; da.plot.imshow()\n&gt;&gt;&gt; da.plot.pcolormesh()\n&gt;&gt;&gt; da.plot.hist()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nimshow\nPlot as 2d\n\n\nline\nPlot as spatial lines\n\n\npcolormesh\nPlot multiple lines as 2d color plot\n\n\ntimeseries\nPlot as timeseries\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.imshow(ax=None, figsize=None, **kwargs)\nPlot as 2d\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.line(ax=None, figsize=None, **kwargs)\nPlot as spatial lines\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.pcolormesh(ax=None, figsize=None, title=None, **kwargs)\nPlot multiple lines as 2d color plot\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.timeseries(ax=None, figsize=None, **kwargs)\nPlot as timeseries"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid1D.html#examples",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid1D.html#examples",
    "title": "dataset._data_plot._DataArrayPlotterGrid1D",
    "section": "",
    "text": "&gt;&gt;&gt; da = mikeio.read(\"tide1.dfs1\")[\"Level\"]\n&gt;&gt;&gt; da.plot()\n&gt;&gt;&gt; da.plot.line()\n&gt;&gt;&gt; da.plot.timeseries()\n&gt;&gt;&gt; da.plot.imshow()\n&gt;&gt;&gt; da.plot.pcolormesh()\n&gt;&gt;&gt; da.plot.hist()"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid1D.html#methods",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid1D.html#methods",
    "title": "dataset._data_plot._DataArrayPlotterGrid1D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nimshow\nPlot as 2d\n\n\nline\nPlot as spatial lines\n\n\npcolormesh\nPlot multiple lines as 2d color plot\n\n\ntimeseries\nPlot as timeseries\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.imshow(ax=None, figsize=None, **kwargs)\nPlot as 2d\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.line(ax=None, figsize=None, **kwargs)\nPlot as spatial lines\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.pcolormesh(ax=None, figsize=None, title=None, **kwargs)\nPlot multiple lines as 2d color plot\n\n\n\ndataset._data_plot._DataArrayPlotterGrid1D.timeseries(ax=None, figsize=None, **kwargs)\nPlot as timeseries"
  },
  {
    "objectID": "api/Dfs1.html",
    "href": "api/Dfs1.html",
    "title": "Dfs1",
    "section": "",
    "text": "Dfs1(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nnx\nNumber of node values\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nshape\nShape of the data array\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\nx0\nStart point of x values (often 0)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nread\nRead data from a dfs file\n\n\n\n\n\nDfs1.read(items=None, time=None, keepdims=False, dtype=np.float32)\nRead data from a dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/Dfs1.html#attributes",
    "href": "api/Dfs1.html#attributes",
    "title": "Dfs1",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\nend_time\nFile end time\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nnx\nNumber of node values\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nshape\nShape of the data array\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\nx0\nStart point of x values (often 0)"
  },
  {
    "objectID": "api/Dfs1.html#methods",
    "href": "api/Dfs1.html#methods",
    "title": "Dfs1",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nread\nRead data from a dfs file\n\n\n\n\n\nDfs1.read(items=None, time=None, keepdims=False, dtype=np.float32)\nRead data from a dfs file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/Dfsu.html",
    "href": "api/Dfsu.html",
    "title": "Dfsu",
    "section": "",
    "text": "Dfsu\nDfsu()"
  },
  {
    "objectID": "api/Dfs2.html",
    "href": "api/Dfs2.html",
    "title": "Dfs2",
    "section": "",
    "text": "Dfs2(self, filename, type='horizontal')\n\n\n\n\n\nName\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\ndy\nStep size in y direction\n\n\nend_time\nFile end time\n\n\ngeometry\nSpatial information\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nnx\nNumber of values in the x-direction\n\n\nny\nNumber of values in the y-direction\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nshape\nTuple with number of values in the t-, y-, x-direction\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\nx0\nStart point of x values (often 0)\n\n\ny0\nStart point of y values (often 0)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nread\nRead data from a dfs2 file\n\n\n\n\n\nDfs2.read(items=None, time=None, area=None, keepdims=False, dtype=np.float32)\nRead data from a dfs2 file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) coordinates\nNone\n\n\ndtype\ntyping.Any\nDefine the dtype of the returned dataset (default = np.float32)\nnp.float32\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/Dfs2.html#attributes",
    "href": "api/Dfs2.html#attributes",
    "title": "Dfs2",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndeletevalue\nFile delete value\n\n\ndx\nStep size in x direction\n\n\ndy\nStep size in y direction\n\n\nend_time\nFile end time\n\n\ngeometry\nSpatial information\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nitems\nList of items\n\n\nlatitude\nOrigin latitude\n\n\nlongitude\nOrigin longitude\n\n\nn_items\nNumber of items\n\n\nn_timesteps\nNumber of time steps\n\n\nnx\nNumber of values in the x-direction\n\n\nny\nNumber of values in the y-direction\n\n\norientation\nOrientation (in own CRS)\n\n\norigin\nOrigin (in own CRS)\n\n\nshape\nTuple with number of values in the t-, y-, x-direction\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\nx0\nStart point of x values (often 0)\n\n\ny0\nStart point of y values (often 0)"
  },
  {
    "objectID": "api/Dfs2.html#methods",
    "href": "api/Dfs2.html#methods",
    "title": "Dfs2",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nread\nRead data from a dfs2 file\n\n\n\n\n\nDfs2.read(items=None, time=None, area=None, keepdims=False, dtype=np.float32)\nRead data from a dfs2 file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | collections.abc.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) coordinates\nNone\n\n\ndtype\ntyping.Any\nDefine the dtype of the returned dataset (default = np.float32)\nnp.float32\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotter.html",
    "href": "api/dataset._data_plot._DataArrayPlotter.html",
    "title": "dataset._data_plot._DataArrayPlotter",
    "section": "",
    "text": "dataset._data_plot._DataArrayPlotter(self, da)\nContext aware plotter (sensible plotting according to geometry)\n\n\n\n\n\nName\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\n\n\n\ndataset._data_plot._DataArrayPlotter.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotter.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotter.html#methods",
    "href": "api/dataset._data_plot._DataArrayPlotter.html#methods",
    "title": "dataset._data_plot._DataArrayPlotter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\n\n\n\ndataset._data_plot._DataArrayPlotter.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\n\nmatplotlib.pyplot.hist\n\n\n\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\n\ndataset._data_plot._DataArrayPlotter.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)"
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API Reference",
    "section": "",
    "text": "open\nOpen a dfs/mesh file (and read the header)\n\n\nread\nRead all or a subset of the data from a dfs file\n\n\nread_pfs\nRead a pfs file to a Pfs object for further analysis/manipulation\n\n\n\n\n\n\n\n\n\nDataArray\nDataArray with data and metadata for a single item in a dfs file\n\n\nDataset\nDataset containing one or more DataArrays with common geometry and time\n\n\ndataset._data_plot._DatasetPlotter\n\n\n\ndataset._data_plot._DataArrayPlotter\nContext aware plotter (sensible plotting according to geometry)\n\n\ndataset._data_plot._DataArrayPlotterGrid1D\nPlot a DataArray with a Grid1D geometry\n\n\ndataset._data_plot._DataArrayPlotterGrid2D\nPlot a DataArray with a Grid2D geometry\n\n\ndataset._data_plot._DataArrayPlotterFM\nPlot a DataArray with a GeometryFM geometry\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile\nPlot a DataArray with a 2DV GeometryFMVerticalProfile geometry\n\n\n\n\n\n\n\n\n\nGrid1D\n1D grid (node-based)\n\n\nGrid2D\n2D grid\n\n\nGrid3D\n3D grid\n\n\nMesh\nThe Mesh class is initialized with a mesh file.\n\n\nspatial.GeometryFM2D\n\n\n\nspatial.GeometryFM3D\n\n\n\nspatial.GeometryFMVerticalProfile\n\n\n\nspatial.GeometryFMVerticalColumn\nA 3d geometry with consisting of a single vertical column\n\n\nspatial._FM_geometry._GeometryFMPlotter\nPlot GeometryFM\n\n\n\n\n\n\n\n\n\ndfsu.DfsuSpectral\n\n\n\nspatial.GeometryFMPointSpectrum\n\n\n\nspatial.GeometryFMLineSpectrum\n\n\n\nspatial.GeometryFMAreaSpectrum\n\n\n\n\n\n\n\n\n\n\nItemInfo\nItemInfo\n\n\nEUMType\nEUM type\n\n\nEUMUnit\nEUM unit\n\n\n\n\n\n\n\n\n\nDfs0\n\n\n\nDfs1\n\n\n\nDfs2\n\n\n\nDfs3\n\n\n\nDfsu\n\n\n\ndfsu.Dfsu2DH\n\n\n\ndfsu.Dfsu2DV\n\n\n\ndfsu.Dfsu3D\n\n\n\n\n\n\n\n\n\n\ngeneric\n\n\n\n\n\n\n\n\n\n\nPfsDocument\nCreate a PfsDocument object for reading, writing and manipulating pfs files\n\n\nPfsSection",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#main",
    "href": "api/index.html#main",
    "title": "API Reference",
    "section": "",
    "text": "open\nOpen a dfs/mesh file (and read the header)\n\n\nread\nRead all or a subset of the data from a dfs file\n\n\nread_pfs\nRead a pfs file to a Pfs object for further analysis/manipulation",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#dataset",
    "href": "api/index.html#dataset",
    "title": "API Reference",
    "section": "",
    "text": "DataArray\nDataArray with data and metadata for a single item in a dfs file\n\n\nDataset\nDataset containing one or more DataArrays with common geometry and time\n\n\ndataset._data_plot._DatasetPlotter\n\n\n\ndataset._data_plot._DataArrayPlotter\nContext aware plotter (sensible plotting according to geometry)\n\n\ndataset._data_plot._DataArrayPlotterGrid1D\nPlot a DataArray with a Grid1D geometry\n\n\ndataset._data_plot._DataArrayPlotterGrid2D\nPlot a DataArray with a Grid2D geometry\n\n\ndataset._data_plot._DataArrayPlotterFM\nPlot a DataArray with a GeometryFM geometry\n\n\ndataset._data_plot._DataArrayPlotterFMVerticalProfile\nPlot a DataArray with a 2DV GeometryFMVerticalProfile geometry",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#geometry",
    "href": "api/index.html#geometry",
    "title": "API Reference",
    "section": "",
    "text": "Grid1D\n1D grid (node-based)\n\n\nGrid2D\n2D grid\n\n\nGrid3D\n3D grid\n\n\nMesh\nThe Mesh class is initialized with a mesh file.\n\n\nspatial.GeometryFM2D\n\n\n\nspatial.GeometryFM3D\n\n\n\nspatial.GeometryFMVerticalProfile\n\n\n\nspatial.GeometryFMVerticalColumn\nA 3d geometry with consisting of a single vertical column\n\n\nspatial._FM_geometry._GeometryFMPlotter\nPlot GeometryFM",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#spectral",
    "href": "api/index.html#spectral",
    "title": "API Reference",
    "section": "",
    "text": "dfsu.DfsuSpectral\n\n\n\nspatial.GeometryFMPointSpectrum\n\n\n\nspatial.GeometryFMLineSpectrum\n\n\n\nspatial.GeometryFMAreaSpectrum",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#eum",
    "href": "api/index.html#eum",
    "title": "API Reference",
    "section": "",
    "text": "ItemInfo\nItemInfo\n\n\nEUMType\nEUM type\n\n\nEUMUnit\nEUM unit",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#dfs",
    "href": "api/index.html#dfs",
    "title": "API Reference",
    "section": "",
    "text": "Dfs0\n\n\n\nDfs1\n\n\n\nDfs2\n\n\n\nDfs3\n\n\n\nDfsu\n\n\n\ndfsu.Dfsu2DH\n\n\n\ndfsu.Dfsu2DV\n\n\n\ndfsu.Dfsu3D",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#generic",
    "href": "api/index.html#generic",
    "title": "API Reference",
    "section": "",
    "text": "generic",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#pfs",
    "href": "api/index.html#pfs",
    "title": "API Reference",
    "section": "",
    "text": "PfsDocument\nCreate a PfsDocument object for reading, writing and manipulating pfs files\n\n\nPfsSection",
    "crumbs": [
      "Home",
      "API Reference"
    ]
  },
  {
    "objectID": "api/Grid1D.html",
    "href": "api/Grid1D.html",
    "title": "Grid1D",
    "section": "",
    "text": "Grid1D(self, x=None, *, x0=0.0, dx=None, nx=None, projection='NON-UTM', origin=(0.0, 0.0), orientation=0.0, node_coordinates=None, axis_name='x')\n1D grid (node-based) axis is increasing and equidistant"
  },
  {
    "objectID": "api/Grid1D.html#parameters",
    "href": "api/Grid1D.html#parameters",
    "title": "Grid1D",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\narray_like\nnode coordinates\nNone\n\n\nx0\nfloat\nfirst node coordinate\n0.0\n\n\ndx\nfloat\ngrid spacing\nNone\n\n\nnx\nint\nnumber of nodes\nNone\n\n\nprojection\nstr\nprojection string\n'NON-UTM'\n\n\norigin\ntuple\nnot commonly used\n(0.0, 0.0)\n\n\norientation\nfloat\nnot commonly used\n0.0\n\n\nnode_coordinates\narray_like\ncoordinates of nodes in 2D or 3D space\nNone\n\n\naxis_name\nstr\nname of axis, by default “x”\n'x'"
  },
  {
    "objectID": "api/Grid1D.html#examples",
    "href": "api/Grid1D.html#examples",
    "title": "Grid1D",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.Grid1D(nx=3,dx=0.1)\n\n&lt;mikeio.Grid1D&gt;\nx: [0, 0.1, 0.2] (nx=3, dx=0.1)\n\n\n\nmikeio.Grid1D(x=[0.1, 0.5, 0.9])\n\n&lt;mikeio.Grid1D&gt;\nx: [0.1, 0.5, 0.9] (nx=3, dx=0.4)"
  },
  {
    "objectID": "api/Grid1D.html#attributes",
    "href": "api/Grid1D.html#attributes",
    "title": "Grid1D",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\ndx\ngrid spacing\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nnx\nnumber of grid points\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\nx\narray of node coordinates"
  },
  {
    "objectID": "api/Grid1D.html#methods",
    "href": "api/Grid1D.html#methods",
    "title": "Grid1D",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfind_index\nFind nearest point\n\n\nisel\nGet a subset geometry from this geometry\n\n\n\n\nfind_index\nGrid1D.find_index(x, **kwargs)\nFind nearest point\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nfloat\nx-coordinate of point\nrequired\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nint\nindex of nearest point\n\n\ntyping.Any\nNot used\n\n\n\n\n\nSee Also\nmikeio.Dataset.sel\n\n\n\nisel\nGrid1D.isel(idx, axis=None)\nGet a subset geometry from this geometry\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nidx\nint or slice\nindex or slice\nrequired\n\n\naxis\nint\nNot used for Grid1D, by default None\nNone\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.spatial._geometry.GeometryPoint2D or mikeio.spatial._geometry.GeometryPoint3D or mikeio.spatial._geometry.GeometryUndefined\nThe geometry of the selected point\n\n\n\n\n\nExamples\n\nimport mikeio\ng = mikeio.Grid1D(nx=3,dx=0.1)\ng\n\n&lt;mikeio.Grid1D&gt;\nx: [0, 0.1, 0.2] (nx=3, dx=0.1)\n\n\n\ng.isel([1,2])\n\n&lt;mikeio.Grid1D&gt;\nx: [0.1, 0.2] (nx=2, dx=0.1)\n\n\n\ng.isel(1)\n\nGeometryUndefined()"
  },
  {
    "objectID": "api/PfsSection.html",
    "href": "api/PfsSection.html",
    "title": "PfsSection",
    "section": "",
    "text": "PfsSection(self, dictionary, **kwargs)"
  },
  {
    "objectID": "api/PfsSection.html#methods",
    "href": "api/PfsSection.html#methods",
    "title": "PfsSection",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nclear\nRemove all items from the PfsSection.\n\n\ncopy\nReturn a copy of the PfsSection.\n\n\nfind_replace\nUpdate recursively all old_value with new_value\n\n\nfrom_dataframe\nCreate a PfsSection from a DataFrame\n\n\nget\nReturn the value for key if key is in the PfsSection,\n\n\nitems\nReturn a new view of the PfsSection’s items ((key, value) pairs)\n\n\nkeys\nReturn a new view of the PfsSection’s keys\n\n\npop\nIf key is in the dictionary, remove it and return its\n\n\nsearch\nFind recursively all keys, sections or parameters\n\n\nto_dataframe\nOutput enumerated subsections to a DataFrame\n\n\nto_dict\nConvert to (nested) dict (as a copy)\n\n\nupdate_recursive\nUpdate recursively all matches of key with value\n\n\nvalues\nReturn a new view of the PfsSection’s values.\n\n\n\n\nclear\nPfsSection.clear()\nRemove all items from the PfsSection.\n\n\ncopy\nPfsSection.copy()\nReturn a copy of the PfsSection.\n\n\nfind_replace\nPfsSection.find_replace(old_value, new_value)\nUpdate recursively all old_value with new_value\n\n\nfrom_dataframe\nPfsSection.from_dataframe(df, prefix)\nCreate a PfsSection from a DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.pandas.DataFrame\ndata\nrequired\n\n\nprefix\nstr\nsection header prefix\nrequired\n\n\n\n\n\nExamples\n\nimport pandas as pd\nimport mikeio\ndf = pd.DataFrame(dict(station=[\"Foo\", \"Bar\"],include=[0,1]), index=[1,2])\ndf\n\n\n\n\n\n\n\n\n\nstation\ninclude\n\n\n\n\n1\nFoo\n0\n\n\n2\nBar\n1\n\n\n\n\n\n\n\n\n\nmikeio.PfsSection.from_dataframe(df,\"STATION_\")\n\n[STATION_1]\n   station = 'Foo'\n   include = 0\nEndSect  // STATION_1\n[STATION_2]\n   station = 'Bar'\n   include = 1\nEndSect  // STATION_2\n\n\n\n\n\nget\nPfsSection.get(key, *args)\nReturn the value for key if key is in the PfsSection, else default. If default is not given, it defaults to None, so that this method never raises a KeyError.\n\n\nitems\nPfsSection.items()\nReturn a new view of the PfsSection’s items ((key, value) pairs)\n\n\nkeys\nPfsSection.keys()\nReturn a new view of the PfsSection’s keys\n\n\npop\nPfsSection.pop(key, *args)\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and key is not in the dictionary, a KeyError is raised.\n\n\nsearch\nPfsSection.search(text=None, *, key=None, section=None, param=None, case=False)\nFind recursively all keys, sections or parameters matching a pattern\nNOTE: logical OR between multiple conditions\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntext\nstr\nSearch for text in either key, section or parameter, by default None\nNone\n\n\nkey\nstr\ntext pattern to seach for in keywords, by default None\nNone\n\n\nsection\nstr\ntext pattern to seach for in sections, by default None\nNone\n\n\nparam\n(str, bool, float, int)\ntext or value in a parameter, by default None\nNone\n\n\ncase\nbool\nshould the text search be case-sensitive?, by default False\nFalse\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.pfs._pfssection.PfsSection\nSearch result as a nested PfsSection\n\n\n\n\n\n\nto_dataframe\nPfsSection.to_dataframe(prefix=None)\nOutput enumerated subsections to a DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprefix\nstr\nThe prefix of the enumerated sections, e.g. “File_”, which can be supplied if it fails without this argument, by default None (will try to “guess” the prefix)\nNone\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame\nThe enumerated subsections as a DataFrame\n\n\n\n\n\nExamples\n\npfs = mikeio.read_pfs(\"../data/pfs/lake.sw\")\npfs.SW.OUTPUTS.to_dataframe(prefix=\"OUTPUT_\")\n\n\n\n\n\n\n\n\n\nTouched\ninclude\ntitle\nfile_name\ntype\nformat\nflood_and_dry\ncoordinate_type\nzone\ninput_file_name\n...\nlast_time_step\ntime_step_frequency\nnumber_of_points\nPOINT_1\nLINE\nAREA\nINTEGRAL_WAVE_PARAMETERS\nINPUT_PARAMETERS\nMODEL_PARAMETERS\nSPECTRAL_PARAMETERS\n\n\n\n\n1\n1\n1\nWave parameters in domain\nWave_parameters.dfsu\n1\n2\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 20000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n2\n1\n0\nWave parameters along line\nWave_line.dfs1\n1\n1\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 20000.0, 'y': 20000.0}\n{'npoints': 41, 'x_first': 0.0, 'y_first': 200...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n3\n1\n1\nWave parameters in a point\nWaves_x20km_y20km.dfs0\n1\n0\n2\nUTM-32\n0\n||\n...\n450\n1\n1\n{'name': 'POINT_1', 'x': 38000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n4\n1\n1\nSpectrum in a point\nspectrum_x20km_y20km.dfsu\n4\n0\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 38000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n\n\n4 rows × 24 columns\n\n\n\n\n\n\n\nto_dict\nPfsSection.to_dict()\nConvert to (nested) dict (as a copy)\n\n\nupdate_recursive\nPfsSection.update_recursive(key, value)\nUpdate recursively all matches of key with value\n\n\nvalues\nPfsSection.values()\nReturn a new view of the PfsSection’s values."
  },
  {
    "objectID": "api/ItemInfo.html",
    "href": "api/ItemInfo.html",
    "title": "ItemInfo",
    "section": "",
    "text": "ItemInfo(self, name=None, itemtype=None, unit=None, data_value_type='Instantaneous')\nItemInfo"
  },
  {
    "objectID": "api/ItemInfo.html#parameters",
    "href": "api/ItemInfo.html#parameters",
    "title": "ItemInfo",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr | mikeio.eum._eum.EUMType | None\n\nNone\n\n\ntype\n\nDefault EUMType.Undefined\nrequired\n\n\nunit\nmikeio.eum._eum.EUMUnit | None\nDefault unit matching EUMType\nNone\n\n\ndata_value_type\ntyping.Literal[‘Instantaneous’, ‘Accumulated’, ‘StepAccumulated’, ‘MeanStepBackWard’]\nOne of the following strings: ‘Instantaneous’, ‘Accumulated’, ‘StepAccumulated’, ‘MeanStepBackward’, ‘MeanStepForward’. Default: ‘Instantaneous’\n'Instantaneous'"
  },
  {
    "objectID": "api/ItemInfo.html#examples",
    "href": "api/ItemInfo.html#examples",
    "title": "ItemInfo",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nmikeio.ItemInfo(\"Viken\", mikeio.EUMType.Water_Level)\n\nViken &lt;Water Level&gt; (meter)\n\n\n\nmikeio.ItemInfo(mikeio.EUMType.Wind_speed)\n\nWind speed &lt;Wind speed&gt; (meter per sec)"
  },
  {
    "objectID": "api/ItemInfo.html#methods",
    "href": "api/ItemInfo.html#methods",
    "title": "ItemInfo",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfrom_mikecore_dynamic_item_info\nCreate ItemInfo from a mikecore.DfsDynamicItemInfo object\n\n\n\n\nfrom_mikecore_dynamic_item_info\nItemInfo.from_mikecore_dynamic_item_info(dfsItemInfo)\nCreate ItemInfo from a mikecore.DfsDynamicItemInfo object"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid2D.html",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid2D.html",
    "title": "dataset._data_plot._DataArrayPlotterGrid2D",
    "section": "",
    "text": "dataset._data_plot._DataArrayPlotterGrid2D(self, da)\nPlot a DataArray with a Grid2D geometry\nIf DataArray has multiple time steps, the first step will be plotted."
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid2D.html#examples",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid2D.html#examples",
    "title": "dataset._data_plot._DataArrayPlotterGrid2D",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nda = mikeio.read(\"../data/gebco_sound.dfs2\")[\"Elevation\"]\nda.plot()"
  },
  {
    "objectID": "api/dataset._data_plot._DataArrayPlotterGrid2D.html#methods",
    "href": "api/dataset._data_plot._DataArrayPlotterGrid2D.html#methods",
    "title": "dataset._data_plot._DataArrayPlotterGrid2D",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\ncontour\nPlot data as contour lines\n\n\ncontourf\nPlot data as filled contours\n\n\nhist\nPlot DataArray as histogram (using ax.hist)\n\n\nline\nPlot data as lines (timeseries if time is present)\n\n\npcolormesh\nPlot data as coloured patches\n\n\n\n\ncontour\ndataset._data_plot._DataArrayPlotterGrid2D.contour(ax=None, figsize=None, title=None, **kwargs)\nPlot data as contour lines\n\nExamples\n\nda = mikeio.read(\"../data/gebco_sound.dfs2\")[\"Elevation\"]\nda.plot.contour()\n\n\n\n\n\n\n\n\n\n\n\ncontourf\ndataset._data_plot._DataArrayPlotterGrid2D.contourf(ax=None, figsize=None, label=None, title=None, **kwargs)\nPlot data as filled contours\n\nExamples\n\nda = mikeio.read(\"../data/gebco_sound.dfs2\")[\"Elevation\"]\nda.plot.contourf()\n\n\n\n\n\n\n\n\n\n\n\nhist\ndataset._data_plot._DataArrayPlotterGrid2D.hist(ax=None, figsize=None, title=None, **kwargs)\nPlot DataArray as histogram (using ax.hist)\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\n(int or sequence or str)\nIf bins is an integer, it defines the number of equal-width bins in the range. If bins is a sequence, it defines the bin edges, including the left edge of the first bin and the right edge of the last bin. by default: rcParams[“hist.bins”] (default: 10)\nrequired\n\n\nax\nmatplotlib.axes.Axes | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\ntyping.Tuple[float, float] | None\nspecify size of figure\nNone\n\n\ntitle\nstr | None\naxes title\nNone\n\n\n\n\n\nSee Also\nmatplotlib.pyplot.hist\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\n&lt;matplotlib.axes&gt;\n\n\n\n\n\n\n\nline\ndataset._data_plot._DataArrayPlotterGrid2D.line(ax=None, figsize=None, **kwargs)\nPlot data as lines (timeseries if time is present)\n\n\npcolormesh\ndataset._data_plot._DataArrayPlotterGrid2D.pcolormesh(ax=None, figsize=None, label=None, title=None, **kwargs)\nPlot data as coloured patches\n\nExamples\n\nda = mikeio.read(\"../data/gebco_sound.dfs2\")[\"Elevation\"]\nda.plot.pcolormesh()"
  },
  {
    "objectID": "api/dfsu.Dfsu3D.html",
    "href": "api/dfsu.Dfsu3D.html",
    "title": "dfsu.Dfsu3D",
    "section": "",
    "text": "dfsu.Dfsu3D(self, filename)\n\n\n\n\n\nName\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\ngeometry2d\nThe 2d geometry for a 3d object\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_layers\nMaximum number of layers\n\n\nn_nodes\nNumber of nodes\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_timesteps\nNumber of time steps\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nextract_surface_elevation_from_3d\nExtract surface elevation from a 3d dfsu file (based on zn)\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu3D.extract_surface_elevation_from_3d(n_nearest=4)\nExtract surface elevation from a 3d dfsu file (based on zn) to a new 2d dfsu file with a surface elevation item.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_nearest\nint\nnumber of points for spatial interpolation (inverse_distance), default=4\n4\n\n\n\n\n\n\n\ndfsu.Dfsu3D.read(items=None, time=None, elements=None, area=None, x=None, y=None, z=None, layers=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nz\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nlayers\nint | str | typing.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu3D.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/dfsu.Dfsu3D.html#attributes",
    "href": "api/dfsu.Dfsu3D.html#attributes",
    "title": "dfsu.Dfsu3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nboundary_codes\nUnique list of boundary codes\n\n\nboundary_polylines\nLists of closed polylines defining domain outline\n\n\ndeletevalue\nFile delete value\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nelement_table\nElement to node connectivity\n\n\nend_time\nFile end time\n\n\ngeometry2d\nThe 2d geometry for a 3d object\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_layered\nType is layered dfsu (3d, vertical profile or vertical column)\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nis_spectral\nType is spectral dfsu (point, line or area spectrum)\n\n\nis_tri_only\nDoes the mesh consist of triangles only?\n\n\nitems\nList of items\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of elements\n\n\nn_items\nNumber of items\n\n\nn_layers\nMaximum number of layers\n\n\nn_nodes\nNumber of nodes\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_timesteps\nNumber of time steps\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nnode_coordinates\nCoordinates (x,y,z) of all nodes\n\n\nprojection_string\nThe projection string\n\n\nstart_time\nFile start time\n\n\ntimestep\nTime step size in seconds\n\n\ntype_name\nType name, e.g. Mesh, Dfsu2D\n\n\nvalid_codes\nUnique list of node codes"
  },
  {
    "objectID": "api/dfsu.Dfsu3D.html#methods",
    "href": "api/dfsu.Dfsu3D.html#methods",
    "title": "dfsu.Dfsu3D",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nextract_surface_elevation_from_3d\nExtract surface elevation from a 3d dfsu file (based on zn)\n\n\nread\nRead data from a dfsu file\n\n\nto_mesh\nwrite object to mesh file\n\n\n\n\n\ndfsu.Dfsu3D.extract_surface_elevation_from_3d(n_nearest=4)\nExtract surface elevation from a 3d dfsu file (based on zn) to a new 2d dfsu file with a surface elevation item.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_nearest\nint\nnumber of points for spatial interpolation (inverse_distance), default=4\n4\n\n\n\n\n\n\n\ndfsu.Dfsu3D.read(items=None, time=None, elements=None, area=None, x=None, y=None, z=None, layers=None, keepdims=False, dtype=np.float32, error_bad_data=True, fill_bad_data_value=np.nan)\nRead data from a dfsu file\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nitems\nstr | int | typing.Sequence[str | int] | None\nRead only selected items, by number (0-based), or by name\nNone\n\n\ntime\nint | str | slice | None\nRead only selected time steps, by default None (=all)\nNone\n\n\nkeepdims\nbool\nWhen reading a single time step only, should the time-dimension be kept in the returned Dataset? by default: False\nFalse\n\n\narea\ntyping.Tuple[float, float, float, float] | None\nRead only data inside (horizontal) area given as a bounding box (tuple with left, lower, right, upper) or as list of coordinates for a polygon, by default None\nNone\n\n\nx\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\ny\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nz\nfloat | None\nRead only data for elements containing the (x,y,z) points(s)\nNone\n\n\nlayers\nint | str | typing.Sequence[int] | None\nRead only data for specific layers, by default None\nNone\n\n\nelements\ntyping.Collection[int] | None\nRead only selected element ids, by default None\nNone\n\n\nerror_bad_data\nbool\nraise error if data is corrupt, by default True,\nTrue\n\n\nfill_bad_data_value\nfloat\nfill value for to impute corrupt data, used in conjunction with error_bad_data=False default np.nan\nnp.nan\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.dataset.Dataset\nA Dataset with data dimensions [t,elements]\n\n\n\n\n\n\n\ndfsu.Dfsu3D.to_mesh(outfilename)\nwrite object to mesh file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutfilename\nstr\npath to file to be written\nrequired"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalProfile.html",
    "href": "api/spatial.GeometryFMVerticalProfile.html",
    "title": "spatial.GeometryFMVerticalProfile",
    "section": "",
    "text": "spatial.GeometryFMVerticalProfile(self, node_coordinates, element_table, codes=None, projection='LONG/LAT', dfsu_type=DfsuFileType.Dfsu3DSigma, element_ids=None, node_ids=None, n_layers=1, n_sigma=None, validate=True, reindex=False)\n\n\n\n\n\nName\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nget_nearest_relative_distance\nFor a point near a transect, find the nearest relative distance\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.get_nearest_relative_distance(coords)\nFor a point near a transect, find the nearest relative distance for showing position on transect plot.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncoords\n[float, float]\nx,y-coordinate of point\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nfloat\nrelative distance in meters from start of transect\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalProfile.html#attributes",
    "href": "api/spatial.GeometryFMVerticalProfile.html#attributes",
    "title": "spatial.GeometryFMVerticalProfile",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbottom_elements\nList of 3d element ids of bottom layer\n\n\ncodes\nNode codes of all nodes (0=water, 1=land, 2…=open boundaries)\n\n\ne2_e3_table\nThe 2d-to-3d element connectivity table for a 3d object\n\n\nelem2d_ids\nThe associated 2d element id for each 3d element\n\n\nelement_coordinates\nCenter coordinates of each element\n\n\nis_geo\nAre coordinates geographical (LONG/LAT)?\n\n\nis_local_coordinates\nAre coordinates relative (NON-UTM)?\n\n\nlayer_ids\nThe layer number (0=bottom, 1, 2, …) for each 3d element\n\n\nmax_nodes_per_element\nThe maximum number of nodes for an element\n\n\nn_elements\nNumber of 3d elements\n\n\nn_layers\nMaximum number of layers\n\n\nn_layers_per_column\nList of number of layers for each column\n\n\nn_sigma_layers\nNumber of sigma layers\n\n\nn_z_layers\nMaximum number of z-layers\n\n\nprojection\nThe projection\n\n\nprojection_string\nThe projection string\n\n\ntop_elements\nList of 3d element ids of surface layer"
  },
  {
    "objectID": "api/spatial.GeometryFMVerticalProfile.html#methods",
    "href": "api/spatial.GeometryFMVerticalProfile.html#methods",
    "title": "spatial.GeometryFMVerticalProfile",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_layer_elements\n3d element ids for one (or more) specific layer(s)\n\n\nget_nearest_relative_distance\nFor a point near a transect, find the nearest relative distance\n\n\nto_2d_geometry\nextract 2d geometry from 3d geometry\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.get_layer_elements(layers)\n3d element ids for one (or more) specific layer(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlayers\nint or list(int)\nlayer between 0 (bottom) and n_layers-1 (top) (can also be negative counting from -1 at the top layer)\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.array(int)\nelement ids\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.get_nearest_relative_distance(coords)\nFor a point near a transect, find the nearest relative distance for showing position on transect plot.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncoords\n[float, float]\nx,y-coordinate of point\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nfloat\nrelative distance in meters from start of transect\n\n\n\n\n\n\n\nspatial.GeometryFMVerticalProfile.to_2d_geometry()\nextract 2d geometry from 3d geometry\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnstructuredGeometry\n2d geometry (bottom nodes)"
  },
  {
    "objectID": "api/PfsDocument.html",
    "href": "api/PfsDocument.html",
    "title": "PfsDocument",
    "section": "",
    "text": "PfsDocument(self, data, *, encoding='cp1252', names=None, unique_keywords=False)\nCreate a PfsDocument object for reading, writing and manipulating pfs files"
  },
  {
    "objectID": "api/PfsDocument.html#parameters",
    "href": "api/PfsDocument.html#parameters",
    "title": "PfsDocument",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\ntyping.TextIO | mikeio.pfs._pfssection.PfsSection | typing.Dict | str | pathlib.Path\nEither a file name (including full path) to the pfs file to be read or dictionary-like structure.\nrequired\n\n\nencoding\n\nHow is the pfs file encoded? By default cp1252\n'cp1252'\n\n\nunique_keywords\n\nShould the keywords in a section be unique? Some tools e.g. the MIKE Plot Composer allows non-unique keywords. If True: warnings will be issued if non-unique keywords are present and the first occurence will be used by default False\nFalse"
  },
  {
    "objectID": "api/PfsDocument.html#attributes",
    "href": "api/PfsDocument.html#attributes",
    "title": "PfsDocument",
    "section": "Attributes",
    "text": "Attributes\n\n\n\nName\nDescription\n\n\n\n\nis_unique\nAre the target (root) names unique?\n\n\nn_targets\nNumber of targets (root sections)\n\n\nnames\nNames of the targets (root sections) as a list\n\n\ntargets\nList of targets (root sections)"
  },
  {
    "objectID": "api/PfsDocument.html#methods",
    "href": "api/PfsDocument.html#methods",
    "title": "PfsDocument",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nclear\nRemove all items from the PfsSection.\n\n\ncopy\nReturn a deep copy of the PfsDocument\n\n\nfind_replace\nUpdate recursively all old_value with new_value\n\n\nfrom_dataframe\nCreate a PfsSection from a DataFrame\n\n\nfrom_text\nCreate a PfsDocument from a string\n\n\nget\nReturn the value for key if key is in the PfsSection,\n\n\nitems\nReturn a new view of the PfsDocument’s items ((key, value) pairs)\n\n\nkeys\nReturn a list of the PfsDocument’s keys (target names)\n\n\npop\nIf key is in the dictionary, remove it and return its\n\n\nsearch\nFind recursively all keys, sections or parameters\n\n\nto_dataframe\nOutput enumerated subsections to a DataFrame\n\n\nto_dict\nConvert to (nested) dict (as a copy)\n\n\nupdate_recursive\nUpdate recursively all matches of key with value\n\n\nvalues\nReturn a list of the PfsDocument’s values (targets).\n\n\nwrite\nWrite object to a pfs file\n\n\n\n\nclear\nPfsDocument.clear()\nRemove all items from the PfsSection.\n\n\ncopy\nPfsDocument.copy()\nReturn a deep copy of the PfsDocument\n\n\nfind_replace\nPfsDocument.find_replace(old_value, new_value)\nUpdate recursively all old_value with new_value\n\n\nfrom_dataframe\nPfsDocument.from_dataframe(df, prefix)\nCreate a PfsSection from a DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.pandas.DataFrame\ndata\nrequired\n\n\nprefix\nstr\nsection header prefix\nrequired\n\n\n\n\n\nExamples\n\nimport pandas as pd\nimport mikeio\ndf = pd.DataFrame(dict(station=[\"Foo\", \"Bar\"],include=[0,1]), index=[1,2])\ndf\n\n\n\n\n\n\n\n\n\nstation\ninclude\n\n\n\n\n1\nFoo\n0\n\n\n2\nBar\n1\n\n\n\n\n\n\n\n\n\nmikeio.PfsSection.from_dataframe(df,\"STATION_\")\n\n[STATION_1]\n   station = 'Foo'\n   include = 0\nEndSect  // STATION_1\n[STATION_2]\n   station = 'Bar'\n   include = 1\nEndSect  // STATION_2\n\n\n\n\n\nfrom_text\nPfsDocument.from_text(text)\nCreate a PfsDocument from a string\n\n\nget\nPfsDocument.get(key, *args)\nReturn the value for key if key is in the PfsSection, else default. If default is not given, it defaults to None, so that this method never raises a KeyError.\n\n\nitems\nPfsDocument.items()\nReturn a new view of the PfsDocument’s items ((key, value) pairs)\n\n\nkeys\nPfsDocument.keys()\nReturn a list of the PfsDocument’s keys (target names)\n\n\npop\nPfsDocument.pop(key, *args)\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and key is not in the dictionary, a KeyError is raised.\n\n\nsearch\nPfsDocument.search(text=None, *, key=None, section=None, param=None, case=False)\nFind recursively all keys, sections or parameters matching a pattern\nNOTE: logical OR between multiple conditions\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntext\nstr\nSearch for text in either key, section or parameter, by default None\nNone\n\n\nkey\nstr\ntext pattern to seach for in keywords, by default None\nNone\n\n\nsection\nstr\ntext pattern to seach for in sections, by default None\nNone\n\n\nparam\n(str, bool, float, int)\ntext or value in a parameter, by default None\nNone\n\n\ncase\nbool\nshould the text search be case-sensitive?, by default False\nFalse\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nmikeio.pfs._pfssection.PfsSection\nSearch result as a nested PfsSection\n\n\n\n\n\n\nto_dataframe\nPfsDocument.to_dataframe(prefix=None)\nOutput enumerated subsections to a DataFrame\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprefix\nstr\nThe prefix of the enumerated sections, e.g. “File_”, which can be supplied if it fails without this argument, by default None (will try to “guess” the prefix)\nNone\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\npandas.pandas.DataFrame\nThe enumerated subsections as a DataFrame\n\n\n\n\n\nExamples\n\npfs = mikeio.read_pfs(\"../data/pfs/lake.sw\")\npfs.SW.OUTPUTS.to_dataframe(prefix=\"OUTPUT_\")\n\n\n\n\n\n\n\n\n\nTouched\ninclude\ntitle\nfile_name\ntype\nformat\nflood_and_dry\ncoordinate_type\nzone\ninput_file_name\n...\nlast_time_step\ntime_step_frequency\nnumber_of_points\nPOINT_1\nLINE\nAREA\nINTEGRAL_WAVE_PARAMETERS\nINPUT_PARAMETERS\nMODEL_PARAMETERS\nSPECTRAL_PARAMETERS\n\n\n\n\n1\n1\n1\nWave parameters in domain\nWave_parameters.dfsu\n1\n2\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 20000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n2\n1\n0\nWave parameters along line\nWave_line.dfs1\n1\n1\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 20000.0, 'y': 20000.0}\n{'npoints': 41, 'x_first': 0.0, 'y_first': 200...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n3\n1\n1\nWave parameters in a point\nWaves_x20km_y20km.dfs0\n1\n0\n2\nUTM-32\n0\n||\n...\n450\n1\n1\n{'name': 'POINT_1', 'x': 38000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n4\n1\n1\nSpectrum in a point\nspectrum_x20km_y20km.dfsu\n4\n0\n2\nUTM-32\n0\n||\n...\n450\n10\n1\n{'name': 'POINT_1', 'x': 38000.0, 'y': 20000.0}\n{'npoints': 3, 'x_first': 0.0, 'y_first': 0.0,...\n{'number_of_points': 4, 'POINT_1': {'x': -400....\n{'Touched': 1, 'type_of_spectrum': 1, 'minimum...\n{'Touched': 1, 'Surface_elevation': 0, 'Water_...\n{'Touched': 1, 'Wind_friction_speed': 0, 'Roug...\n{'Touched': 1, 'separation_of_wind_sea_and_swe...\n\n\n\n\n4 rows × 24 columns\n\n\n\n\n\n\n\nto_dict\nPfsDocument.to_dict()\nConvert to (nested) dict (as a copy)\n\n\nupdate_recursive\nPfsDocument.update_recursive(key, value)\nUpdate recursively all matches of key with value\n\n\nvalues\nPfsDocument.values()\nReturn a list of the PfsDocument’s values (targets).\n\n\nwrite\nPfsDocument.write(filename=None)\nWrite object to a pfs file\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr | None\nFull path and filename of pfs to be created. If None, the content will be returned as a list of strings.\nNone"
  }
]